<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>业精于勤，行成于思</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-10-21T03:07:49.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Yangguang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在 Swift 中使用 OpenCV</title>
    <link href="http://yoursite.com/2017/10/16/programming/use-opencv-in-swift/"/>
    <id>http://yoursite.com/2017/10/16/programming/use-opencv-in-swift/</id>
    <published>2017-10-16T12:00:17.000Z</published>
    <updated>2017-10-21T03:07:49.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/10/16/programming/use-opencv-in-swift/0.gif" alt="0.gif" title=""> <br>通过阅读本篇内容您将了解到：<br>- 如何在 iOS 项目项目中添加 OpenCV 库；<br>- Objective-C++ 与 Swift 的结合使用，及桥接文件的添加；<br>- Swift 中对摄像头图像的获取方法及展现；<br>- Swift 与 OpenCV 的交互；<br><a id="more"></a>
<h1 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h1><ol>
<li>Xcode 9.0;</li>
<li>Swift 4.0;</li>
<li>OpenCV iOS pack 3.3.0;</li>
</ol>
<h1 id="OpenCV-Package-添加"><a href="#OpenCV-Package-添加" class="headerlink" title="OpenCV Package 添加"></a>OpenCV Package 添加</h1><p>OpenCV Package 可以通过以下两种方式添加到 iOS 项目当中：</p>
<ol>
<li><p>使用 <a href="https://cocoapods.org/" target="_blank" rel="external">CocoaPods</a> 添加<br>Profile 中添加 OpenCV：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">target &apos;UseOpenCVInSwiftDemo&apos; do</div><div class="line">  use_frameworks!</div><div class="line">  pod &apos;OpenCV&apos;</div><div class="line">end</div></pre></td></tr></table></figure>
</li>
<li><p>直接下载<br>在官网的 <a href="https://opencv.org/releases.html" target="_blank" rel="external">Releases</a> 列表中直接下载相应版本的 iOS pack。<br>解压下载后的 zip 文件，得到一个 opencv2.framework 库，右键点击项目选择添加文件，进行添加即可：</p>
<img src="/2017/10/16/programming/use-opencv-in-swift/1.png" alt="1.png" title="">
<p>同时在 <code>Project／General／Linked Frameworks and Libraies</code> 中也请添加一份 opencv2.framework。<br>这里需要注意的是请不要以直接拖拽的方式添加，容易产生找不到<code>opencv2/opencv.hpp file not found</code>的错误。<br>以上是两种简单的添加 OpenCV 的方法。</p>
</li>
</ol>
<p>需要注意的是如果在编译时产生如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Undefined symbols for architecture arm64:</div><div class="line">  &quot;_OBJC_CLASS_$_ALAssetsLibrary&quot;, referenced from:</div><div class="line">      objc-class-ref in opencv2(cap_ios_video_camera.o)</div><div class="line">  &quot;_CMSampleBufferGetPresentationTimeStamp&quot;, referenced from:</div><div class="line">      -[CvVideoCamera captureOutput:didOutputSampleBuffer:fromConnection:] in opencv2(cap_ios_video_camera.o)</div><div class="line">  &quot;_CMTimeMake&quot;, referenced from:</div><div class="line">      -[CvVideoCamera createVideoDataOutput] in opencv2(cap_ios_video_camera.o)</div><div class="line">  &quot;_CMSampleBufferGetImageBuffer&quot;, referenced from:</div><div class="line">      -[CaptureDelegate captureOutput:didOutputSampleBuffer:fromConnection:] in opencv2(cap_avfoundation.o)</div><div class="line">      -[CvVideoCamera captureOutput:didOutputSampleBuffer:fromConnection:] in opencv2(cap_ios_video_camera.o)</div><div class="line">ld: symbol(s) not found for architecture arm64</div><div class="line">clang: error: linker command failed with exit code 1 (use -v to see invocation)</div></pre></td></tr></table></figure></p>
<p>请在项目中再添加以下 framework 即可解决：<br><code>AssetsLibrary.framework</code>、<code>CoreMedia.framework</code>、<code>CoreVideo.framework</code>。<br>具体添加方法：<code>Project／General／Linked Frameworks and Libraies</code>：<img src="/2017/10/16/programming/use-opencv-in-swift/2.png" alt="2.png" title=""></p>
<h1 id="OpenCV-使用准备"><a href="#OpenCV-使用准备" class="headerlink" title="OpenCV 使用准备"></a>OpenCV 使用准备</h1><p>我们添加的 OpenCV 是由 C++ 编码的，在 Swift 中可以通过添加 Objective-C++ 文件实现对 OpenCV 的使用。<br>原理示意如下：<br><img src="/2017/10/16/programming/use-opencv-in-swift/3.png" alt="3.png" title=""><br>具体步骤：</p>
<ol>
<li>添加一个 Objective-C 文件到项目中，这里命名为 OpenCVMethods（如果有自动提示是否添加 Bridging-Header 文件的话，选择添加。如果没有提示，则由第2步进行手动添加），将文件扩展名“m”改为“mm”。</li>
<li>手动添加一个 Bridging-Header 文件：在添加一个头文件（Header file），重命名为“项目名-Bridging-Header.h”（本例中为：UseOpenCVInSwiftDemo-Bridging-Header.h）。</li>
</ol>
<h1 id="视频获取"><a href="#视频获取" class="headerlink" title="视频获取"></a>视频获取</h1><p>我们将在 <code>ViewController.swift</code> 中实现视频获取及展现的主要功能逻辑，视频处理主要在 <code>OpenCVMethods.mm</code> 由 OpenCV 完成。<br>下面是 <code>ViewController.swift</code> 中对视频获取及展现的实现代码：<br><figure class="highlight swift"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// ViewController.swift</span></div><div class="line"><span class="keyword">import</span> UIKit</div><div class="line"><span class="keyword">import</span> AVFoundation</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ViewController</span>: <span class="title">UIViewController</span>, <span class="title">AVCaptureVideoDataOutputSampleBufferDelegate</span> </span>&#123;</div><div class="line">    </div><div class="line">    <span class="keyword">var</span> session = <span class="type">AVCaptureSession</span>()</div><div class="line">    <span class="keyword">var</span> previewImage = <span class="type">UIImage</span>()</div><div class="line">    <span class="meta">@IBOutlet</span> <span class="keyword">weak</span> <span class="keyword">var</span> imageView: <span class="type">UIImageView</span>!</div><div class="line"></div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">func</span> <span class="title">viewDidLoad</span><span class="params">()</span></span> &#123;</div><div class="line">        <span class="keyword">super</span>.viewDidLoad()</div><div class="line">        </div><div class="line">        startLiveVideo()</div><div class="line">        <span class="number">_</span> = <span class="type">Timer</span>.scheduledTimer(timeInterval: <span class="number">0.1</span>, target: <span class="keyword">self</span>, selector: #selector(<span class="keyword">self</span>.setPreviewImage), userInfo: <span class="literal">nil</span>, repeats: <span class="literal">true</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">func</span> <span class="title">didReceiveMemoryWarning</span><span class="params">()</span></span> &#123;</div><div class="line">        <span class="keyword">super</span>.didReceiveMemoryWarning()</div><div class="line">        <span class="comment">// Dispose of any resources that can be recreated.</span></div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">func</span> <span class="title">startLiveVideo</span><span class="params">()</span></span> &#123;</div><div class="line">        session.sessionPreset = <span class="type">AVCaptureSession</span>.<span class="type">Preset</span>.photo</div><div class="line">        <span class="keyword">let</span> captureDevice = <span class="type">AVCaptureDevice</span>.<span class="keyword">default</span>(<span class="keyword">for</span>: <span class="type">AVMediaType</span>.video)</div><div class="line">        </div><div class="line">        <span class="keyword">let</span> deviceInput = <span class="keyword">try</span>! <span class="type">AVCaptureDeviceInput</span>(device: captureDevice!)</div><div class="line">        <span class="keyword">let</span> deviceOutput = <span class="type">AVCaptureVideoDataOutput</span>()</div><div class="line">        deviceOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey <span class="keyword">as</span> <span class="type">String</span>: <span class="type">Int</span>(kCVPixelFormatType_32BGRA)]</div><div class="line">        deviceOutput.setSampleBufferDelegate(<span class="keyword">self</span>, queue: <span class="type">DispatchQueue</span>.global(qos: <span class="type">DispatchQoS</span>.<span class="type">QoSClass</span>.<span class="keyword">default</span>))</div><div class="line">        session.addInput(deviceInput)</div><div class="line">        session.addOutput(deviceOutput)</div><div class="line">        session.startRunning()</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">func</span> <span class="title">captureOutput</span><span class="params">(<span class="number">_</span> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span> &#123;</div><div class="line">    </div><div class="line">        connection.videoOrientation = <span class="type">AVCaptureVideoOrientation</span>.portrait;</div><div class="line">        updatePreviewImage(sampleBuffer:sampleBuffer)</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">func</span> <span class="title">updatePreviewImage</span><span class="params">(sampleBuffer: CMSampleBuffer)</span></span>&#123;</div><div class="line">        <span class="keyword">let</span> imageBuffer: <span class="type">CVPixelBuffer</span> = <span class="type">CMSampleBufferGetImageBuffer</span>(sampleBuffer)!</div><div class="line">        <span class="keyword">let</span> ciimage : <span class="type">CIImage</span> = <span class="type">CIImage</span>(cvPixelBuffer: imageBuffer)</div><div class="line">        previewImage = <span class="keyword">self</span>.convertCIImageToUIImage(cmage: ciimage)</div><div class="line"></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">func</span> <span class="title">convertCIImageToUIImage</span><span class="params">(cmage:CIImage)</span></span> -&gt; <span class="type">UIImage</span> &#123;</div><div class="line">        <span class="keyword">let</span> context:<span class="type">CIContext</span> = <span class="type">CIContext</span>.<span class="keyword">init</span>(options: <span class="literal">nil</span>)</div><div class="line">        <span class="keyword">let</span> cgImage:<span class="type">CGImage</span> = context.createCGImage(cmage, from: cmage.extent)!</div><div class="line">        <span class="keyword">let</span> image:<span class="type">UIImage</span> = <span class="type">UIImage</span>.<span class="keyword">init</span>(cgImage: cgImage, scale: <span class="number">1.0</span>, orientation: <span class="type">UIImageOrientation</span>.<span class="keyword">right</span>)</div><div class="line">        <span class="keyword">return</span> image</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="meta">@objc</span> <span class="function"><span class="keyword">func</span> <span class="title">setPreviewImage</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">let</span> image = <span class="type">ImageConverter</span>.getBinaryImage(previewImage)</div><div class="line">        imageView.image = image</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><code>session</code>：主要用于处理摄像头的视频流；<br><code>previewImage</code>：用于存储由视频帧（frame）转换得到的 UIImage；<br><code>imageView</code>：用于展示视频的处理结果，这里需要您在 storyboard 中创建一个 UIImageView 控件并与 <code>imageView</code> 建立连接；<br><code>startLiveVideo</code>: 建立并开始摄像头视频流；<br><code>Timer.scheduledTimer</code>：循环调用 <code>setPreviewImage</code> 函数，更新输入图像；<br><code>captureOutput</code>：当摄像头每输出每一帧图像时，该函数即会被调用一次；<br><code>connection.videoOrientation</code>：用于调整视频图像的朝向，我们这里是定为“竖直”方向；<br><code>updatePreviewImage</code>：将获取的 <code>sampleBuffer</code> 转换为 UIImage，保存在 <code>previewImage</code> 中；<br><code>setPreviewImage</code>：将获取的图像经 <code>ImageConverter.convert</code> 二值化处理后，更新到 <code>imageView</code> 中；</p>
<h1 id="视频处理"><a href="#视频处理" class="headerlink" title="视频处理"></a>视频处理</h1><p>视频图像的处理工作我们主要交由 <code>OpenCVMethods.mm</code> 来完成，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">// UseOpenCVInSwiftDemo-Bridging-Header.h</div><div class="line">#import &lt;Foundation/Foundation.h&gt;</div><div class="line">#import &lt;UIKit/UIKit.h&gt;</div><div class="line"></div><div class="line">@interface ImageConverter : NSObject</div><div class="line">+(UIImage *)getBinaryImage:(UIImage *)image;</div><div class="line">@end</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">// OpenCVMethods.mm</div><div class="line">#import &lt;opencv2/opencv.hpp&gt;</div><div class="line">#import &lt;opencv2/imgcodecs/ios.h&gt;</div><div class="line">#import &quot;UseOpenCVInSwiftDemo-Bridging-Header.h&quot;</div><div class="line"></div><div class="line">@implementation ImageConverter : NSObject</div><div class="line"></div><div class="line">+(UIImage *)getBinaryImage:(UIImage *)image &#123;</div><div class="line">    cv::Mat mat;</div><div class="line">    UIImageToMat(image, mat);</div><div class="line">    </div><div class="line">    cv::Mat gray;</div><div class="line">    cv::cvtColor(mat, gray, CV_RGB2GRAY);</div><div class="line">    </div><div class="line">    cv::Mat bin;</div><div class="line">    cv::threshold(gray, bin, 0, 255, cv::THRESH_BINARY | cv::THRESH_OTSU);</div><div class="line">    </div><div class="line">    UIImage *binImg = MatToUIImage(bin);</div><div class="line">    return binImg;</div><div class="line">&#125;</div><div class="line">@end</div></pre></td></tr></table></figure>
<p><code>UseOpenCVInSwiftDemo-Bridging-Header.h</code>：是对 Objective-C++ 类及方法进行定义；<br><code>OpenCVMethods.mm</code>：用于对具体定义的类及方法实现；<br><code>getBinaryImage</code>：实现了对输入图像的二值化处理，方法与 OpenCV 在 C++ 中的使用时一样的，需要注意的是 Mat 与 UIImage 数据类型的转换；  </p>
<p>至此我们便完成了 OpenCV 在 Swift 中的简单实用过程，接下来 OpenCV 如何在 Swift 中大显身手就任由您的自由发挥了：）</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过阅读本篇文章，您应该已经掌握了如何在 Swift 中使用 OpenCV，主要包括：</p>
<ol>
<li>OpenCV 载入；</li>
<li>Objective-C++ 文件及桥接文件添加；</li>
<li>Swift 中对摄像头图像的获取；</li>
<li>Swift 中图像处理时与 OpenCV 的交互；</li>
<li>处理后的图像的简单展示； </li>
</ol>
<p>文章使用的项目代码可以在<a href="https://github.com/yangguang2009/opencv_in_swift" target="_blank" rel="external">这里</a>下载。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ol>
<li><a href="https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html" target="_blank" rel="external">Swift and Objective-C in the Same Project</a></li>
<li><a href="https://opencv.org/releases.html" target="_blank" rel="external">OpenCV Releases</a></li>
<li><a href="https://docs.opencv.org/master/" target="_blank" rel="external">OpenCV 示例文档</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/10/16/programming/use-opencv-in-swift/0.gif&quot; alt=&quot;0.gif&quot; title=&quot;&quot;&gt; &lt;br&gt;通过阅读本篇内容您将了解到：&lt;br&gt;- 如何在 iOS 项目项目中添加 OpenCV 库；&lt;br&gt;- Objective-C++ 与 Swift 的结合使用，及桥接文件的添加；&lt;br&gt;- Swift 中对摄像头图像的获取方法及展现；&lt;br&gt;- Swift 与 OpenCV 的交互；&lt;br&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://yoursite.com/categories/Programming/"/>
    
    
      <category term="OpenCV" scheme="http://yoursite.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>W3 App</title>
    <link href="http://yoursite.com/2017/09/27/others/W3school-App/"/>
    <id>http://yoursite.com/2017/09/27/others/W3school-App/</id>
    <published>2017-09-27T02:27:31.000Z</published>
    <updated>2017-09-27T13:15:02.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/09/27/others/W3school-App/0.png" alt="0.png" title=""> <br>W3 是一款简明编程学习应用，包含了Web，App，Server等应用开发主流教程。<br><a id="more"></a>
<h1 id="W3"><a href="#W3" class="headerlink" title="W3"></a>W3</h1><p>主要功能包括：</p>
<ul>
<li>代码示例</li>
<li>进度标示</li>
<li>文章收藏</li>
<li>薪资统计</li>
<li>…</li>
</ul>
<p>W3 当前已推出 iOS 和 Android 两个版本的支持，你可以在以下链接免费下载使用。<br>希望 W3 能为您的工作学习带来帮助，同时也期待您的使用反馈以及对 W3 进一步完善的建议！</p>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><p>iOS 版本下载：<br><a href="https://itunes.apple.com/cn/app/w3/id987493634?mt=8" target="_blank" rel="external"><img src="/2017/09/27/others/W3school-App/download_icon_ios.png" alt="download_icon_ios.png" title=""></a></p>
<p>Android 版本下载：<br><a href="https://pan.baidu.com/s/1hrXuD2O" target="_blank" rel="external"><img src="/2017/09/27/others/W3school-App/download_icon_android.png" alt="download_icon_android.png" title=""></a></p>
<h1 id="Update-2017-09-27"><a href="#Update-2017-09-27" class="headerlink" title="Update (2017-09-27)"></a>Update (2017-09-27)</h1><p>很高兴 W3 的用户数已经增加到了10万+，从发布到现在几乎都是通过用户间的口头推荐而被越来越多的程序员小伙伴们所熟知的。从当初的一个想法到 App 的发布再到今天能够帮助10万+程序员们共同学习进步，其中最要感谢的是大家的支持！可以说每一次版本的迭代更新都包含了小伙伴们热情的反馈和建议，大家的赞许和鼓励不知不觉中已经成为了 W3 不断更新的动力，在此对大家的支持再次一并表示感谢！也希望 W3 为大家的学习生活带来更多的帮助。<br>圣人说：“知之者不如好之者，好之者不如乐之者。”希望喜欢编程的小伙伴们能够在程序的编码和调试中发现更多乐趣！<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">CODING FOR FUN, CODING FOR DREAM!</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/09/27/others/W3school-App/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br/&gt;W3 是一款简明编程学习应用，包含了Web，App，Server等应用开发主流教程。&lt;br&gt;
    
    </summary>
    
      <category term="Others" scheme="http://yoursite.com/categories/Others/"/>
    
    
      <category term="App" scheme="http://yoursite.com/tags/App/"/>
    
  </entry>
  
  <entry>
    <title>Choir3 App</title>
    <link href="http://yoursite.com/2017/09/10/others/choir3/"/>
    <id>http://yoursite.com/2017/09/10/others/choir3/</id>
    <published>2017-09-10T02:27:31.000Z</published>
    <updated>2017-09-10T14:27:13.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/09/10/others/choir3/0.png" alt="0.png" title=""> <br>Choir3 is an easy App for creating a harmonized song just by one person, which often been called “One Person Choir” or “One Man Choir”.<br>The design is inspired by the videos that harmonize a song just by one singer, which are very wonderful. But creating a harmonized song like that often needs professional video editing softwares and corresponding skills on them. To make it easy for most people who want to have a try, Choir3 is created!<br><a id="more"></a>
<p>With Choir3 you can easily enjoy the following features:</p>
<ul>
<li>Recording current track while playing preceding recordings, so you can harmonize with yourselves. With earphone connecting will make it more better.</li>
<li>Harmonizing just with the selected recordings.</li>
<li>Deleting the selected recordings.</li>
<li>Combining all recordings into one video, which you can then save on phone or share with friends.</li>
</ul>
<p>I hope you will enjoy it, and enjoy singing : )</p>
<h1 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h1><p>iOS：<br><a href="https://itunes.apple.com/us/app/choir3/id1275995274?ls=1&amp;mt=8" target="_blank" rel="external"><img src="/2017/09/10/others/choir3/download_icon_ios.png" alt="download_icon_ios.png" title=""></a></p>
<h1 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h1><p>Thanks <a href="https://www.flaticon.com/" target="_blank" rel="external">flaticon</a> provide the free icons:</p>
<div>Icons made by <a href="https://www.flaticon.com/authors/madebyoliver" title="Madebyoliver" target="_blank" rel="external">Madebyoliver</a> from <a href="https://www.flaticon.com/" title="Flaticon" target="_blank" rel="external">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>

<div>Icons made by <a href="http://www.freepik.com" title="Freepik" target="_blank" rel="external">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon" target="_blank" rel="external">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>

<div>Icons made by <a href="https://www.flaticon.com/authors/pixel-perfect" title="Pixel perfect" target="_blank" rel="external">Pixel perfect</a> from <a href="https://www.flaticon.com/" title="Flaticon" target="_blank" rel="external">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>

<div>Icons made by <a href="http://www.freepik.com" title="Freepik" target="_blank" rel="external">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon" target="_blank" rel="external">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>

<div>Icons made by <a href="https://www.flaticon.com/authors/eleonor-wang" title="Eleonor Wang" target="_blank" rel="external">Eleonor Wang</a> from <a href="https://www.flaticon.com/" title="Flaticon" target="_blank" rel="external">www.flaticon.com</a> is licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></div>

]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/09/10/others/choir3/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br/&gt;Choir3 is an easy App for creating a harmonized song just by one person, which often been called “One Person Choir” or “One Man Choir”.&lt;br&gt;The design is inspired by the videos that harmonize a song just by one singer, which are very wonderful. But creating a harmonized song like that often needs professional video editing softwares and corresponding skills on them. To make it easy for most people who want to have a try, Choir3 is created!&lt;br&gt;
    
    </summary>
    
      <category term="Others" scheme="http://yoursite.com/categories/Others/"/>
    
    
      <category term="App" scheme="http://yoursite.com/tags/App/"/>
    
  </entry>
  
  <entry>
    <title>读《人类简史》</title>
    <link href="http://yoursite.com/2017/06/25/reading/sapiens-a-brief-history-of-humankind/"/>
    <id>http://yoursite.com/2017/06/25/reading/sapiens-a-brief-history-of-humankind/</id>
    <published>2017-06-25T14:09:09.000Z</published>
    <updated>2017-06-25T14:35:41.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/06/25/reading/sapiens-a-brief-history-of-humankind/0.jpg" alt="0.jpg" title=""> <br>很早就了解到这本书，这周终于有机会读了一遍，书中论述的很多观点不仅让人读起来深感作者的睿智，同时更是发人深省。下面是就书中部分观点的一些思考，在这里与大家一同分享探讨。<br><a id="more"></a>
<h1 id="认知革命"><a href="#认知革命" class="headerlink" title="认知革命"></a>认知革命</h1><p>据考古推测地球上人属（属：动物学中对生物进行分类的一个级别）的演化出现可以追溯到大概250万年前，那时人类已经开始学会了使用石头制造石刀，石锤等基本器械，即人们所称的石器时代。之后的200多万年间人类的生活没有发生太大的变化，不过是这个部落这个月又抓到了几只猎物，或是那个部落又发现了几颗颗满是果实的果树。人类在地球上只不过是丛林中众多物种中的一员，时常还要警惕和躲避大型肉食性动物的猎食。在食物链（食物链：大鱼吃小鱼，小鱼吃虾米）上人类勉强算是排在中间的位置，并没有什么绝对的优势。直到大约7万年前左右，发生了一件特殊的事情，之后人类一跃达到了食物链的顶端，并且从此在动物界中便再未逢敌手。这段时间所发生的特殊事件人类学家普遍称之为认知革命。<br>认知革命发生的具体原因我们至今还不清楚，但所带来的影响却使整个自然界发上了翻天覆地的变化。经历了认知革命的人类拥有了普遍觉醒的智能意识，逐渐演化发展成了今天的我们。</p>
<h1 id="会讲故事"><a href="#会讲故事" class="headerlink" title="会讲故事"></a>会讲故事</h1><p>要说认知革命为人类带来的众多变化中，不得不提到了一项便是人类懂得了如何讲故事，无论是真实的还是虚拟的，过去的还是未来的。会讲故事表面看起来无足轻重，但在促进大范围内人类合作上所扮演的角色却意义非凡。在一个共同认可，崇拜，或是向往的故事基础上，众多人类成员间的合作有了共识，有了导向，有了一致的目标。这不仅提高了最初人类部落的捕猎效率，更是极大的提高了人类在动物界中的竞争力。人类也由此随着一个又一个故事不断发展壮大，组建了帝国，形成了文化，创立了宗教，实现了一个又一个看似不可能完成的神话。<br>举个很有意思的例子，刚上映过的一部电影叫《金刚》，假设金刚和现代人一对一放到原始森林里单挑，毋庸置疑金刚完胜，就算金刚让你一只手都毫无悬念。再者，先别说和金刚单挑，在大森林里怎么生存下来都成问题，可能不等金刚出手人已经饿的只能扶大树站着了。再假设如果金刚和现代人是10对10结果会怎样？可能会多演几集。100对100呢？剧情估计要逆转。1000对1000呢？等等！为啥？金刚们好像自己打起来了，真有这种事？看不起我们人类咋滴？不是，金刚们正忙着自己选头领呢。人类有组织的合作随着成员数量的增加效率会不断的递增，别说是1000人的规模，几十万人的合作同样可以照常进行秩序井然，要看现在的超级大国，更是上亿成员合作的典范。这就是故事的力量，无论两个人是否相互熟悉，只要相信共同的故事很容易就可以达成共识，同心协力，同舟共济。<br>再举个大家更熟悉的例子-公司。开始组建时包括Leader在内不过十几人，这时不需要什么故事，Leader有想法大家就跟着干，朝夕相处耳濡目染，Leader的理想就是大家行动的指南。当公司小有成绩时，人数不觉已过百人，Leader的理想依然远大，但对新入职的同事很少有能直接认出对方名字的了，朝夕相处已成奢侈，耳濡目染更为奢谈。这时大家虽然不常听到Leader的理想，但心中已经有了共同坚信的故事-公司愿景，不管是为了让世界变得更美好，还是早日上市财务自由，或者是争取卖掉尽快套现。不可能指望百十来号人（甚至上万人）都相信兄弟情谊，即使相信也未必认可，但只要大家相信共同的故事，多一名成员的加入，公司的力量就会壮大一分，有时还不止一分。<br>相信共同的故事，小了说是大家三观的一致，大了说是彼此信仰的共鸣。也正是因为人类会讲故事，同时也对故事有着笃信不疑的执着，才有了人类辉煌的历史和灿烂的文化。</p>
<h1 id="我们想要啥"><a href="#我们想要啥" class="headerlink" title="我们想要啥"></a>我们想要啥</h1><p>古人说：“仓廪实而知礼节，衣食足而知荣辱”，“仓廪”、“衣食”指的是物质满足，“礼节”和“荣辱”强调的是精神的追求。通俗的说就是只有吃饱喝足了才会去想玩儿点啥，怎么玩儿。如果我们继续追问如果有东西可玩儿了那之后我们又想要什么呢？如果这样一直追问下去你会发现这个答案对于人类来说大多都是同一样东西：快乐，或者说是幸福感。答案虽然只有一个，但不同的人有不同的理解。有的人认为快乐是来自外界的刺激而产生的一种好的感受。有的人则认为快乐是内心所抱持的一种知足、平和的精神状态。相信大多数是认可这两种理解的，实际生活中我们所感受到的也确实如此，快乐或者是来自外在或者是源自内心，无论是贫穷还是富有其实对快乐的感受是相同的。对大多数人来说如果要问人生的意义是什么，应该也不过如此了吧。<br>但让我们再仔细想一想，这两种所谓的快乐是真正的快乐吗？没有了外界的刺激怎们办，我们就不快乐了吗？何况如果外界刺激一直存在的情况下人类的感受也会产生适应性，就是说如果刺激不增强，人类对这种刺激的感觉就会逐渐减小以至于被忽略。这也可以简单的理解为为什么第一口西瓜总是特别甜，而吃到最后总是有种在嚼水的感觉（如果是无籽西瓜）。即便是外界刺激可以保持不断增强，又有多少人可以维持这样的外界环境呢？就算是外界环境是无条件提供的，又有多少人能够承受的了这种快乐所带来的破坏力呢？答案是没有人，因为这种所谓的快乐与人类的进化结构本身就是不相符的，对人类来说不是真正的快乐。再说内心知足与平和的精神状态，相比而言这更接近于真正的快乐，但也不是，为什么？请大家想一想上一次你内心曾处于知足与平和的状态是什么时候？难道当内心万马奔腾的时候就不能感到快乐吗？要不然人类的语言中就不会有那么多的 dirty words 了（最起码会比现在少）。<br>对于追求真正快乐的方法，简单的说就是不去刻意执著于对快乐的追求，当你身临其境的时候也就自然获得了属于自己的答案。</p>
<h1 id="我们要去哪"><a href="#我们要去哪" class="headerlink" title="我们要去哪"></a>我们要去哪</h1><p>对于人类未来的发展，曾经做过的预测实际证明都是不太靠谱的，主要原因就在于有太多的因素和偶然事件是无法预知的，往往又在发展的进程中起着决定性的作用。从当前的情况来看，人类最有可能的发展方向一个是以基因工程为主导的方向，另一个则是由人工智能为主导的方向。<br>为什么这么推测？先来看基因工程。人类历史真正实现跳跃式发展的阶段应该是始于认知革命，后期的农业革命、工业革命以及近代的科技革命可以说都是认知革命在时间上积累的自然进程，也可以统称为第一次认知革命。基因工程很有可能为人类揭开第二次认知革命的新历程，经过第二次认知革命的人类到那时是否还将自己称为人类我们确定不了（就像我们现代人类不再认为自己是猿一样），我们能确定的只是至少他们的第一代是由人类所设计的。生物发展的任何可能性归根结底都存储在了基因中，我们现在还不知道在第一次认知革命前夕人类的基因到底发生了哪些变化，而基因工程的发展恰是为人类提供了操作这接近无限可能性的发挥空间。同时，人工智能的发展也为人类未来的走向提供了无限的遐想。如果计算机有一天完成了人类意识的模拟，其实也就相当于宣布了无机生命的诞生。无机生命是否会自我进化，是否依然会服务于人类等等当前都是还无法确定的。<br>两种可能所开启的新篇章我们现在都是无法想象的，就像我们无法想象宇宙大爆炸之前的景象一样。那时再看我们人类，到底应该算是成功完成了新的进化，还是应该认为从此人类就退出了进化的舞台？我想还是王维平老师有句话说的对：“时代是时代的超越者，命运是命运的终结者”。</p>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/06/25/reading/sapiens-a-brief-history-of-humankind/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt; &lt;br/&gt;很早就了解到这本书，这周终于有机会读了一遍，书中论述的很多观点不仅让人读起来深感作者的睿智，同时更是发人深省。下面是就书中部分观点的一些思考，在这里与大家一同分享探讨。&lt;br&gt;
    
    </summary>
    
      <category term="Reading" scheme="http://yoursite.com/categories/Reading/"/>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
  </entry>
  
  <entry>
    <title>基于卷积神经网络的系统日志分类</title>
    <link href="http://yoursite.com/2017/02/01/deeplearning/sys-log-classification-by-CNN/"/>
    <id>http://yoursite.com/2017/02/01/deeplearning/sys-log-classification-by-CNN/</id>
    <published>2017-02-01T12:11:22.000Z</published>
    <updated>2017-02-02T14:19:25.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/02/01/deeplearning/sys-log-classification-by-CNN/0.png" alt="0.png" title=""> <br>卷积神经网络（CNN）是当前广泛应用的深度学习神经网络类型之一，特点是可以自动对数据特征进行提取学习。CNN 在图片识别，语义分析等领域已经取得了非常令人振奋的成绩，本篇将介绍使用 CNN 对系统日志进行识别分类的具体方法。在通过阅读本篇内容您将了解到：<br>- 文本数据进行 CNN 分析的相关预处理方法；<br>- CNN 一维卷积网络的具体构建和用法；<br>- CNN 对系统日志进行分类的具体应用；<br><a id="more"></a>
<h1 id="系统日志"><a href="#系统日志" class="headerlink" title="系统日志"></a>系统日志</h1><p>系统日志泛指运行于计算机上的软件系统所产生的相关记录信息，通常以文本文件的形式存在。系统日志包含了大量的关于系统运行、操作使用等相关情况的原始记录，对于一家企业来说是非常宝贵的数据资产。如何更好的分析挖掘海量系统日志中包含的有意信息，近年来人们的关注度也是在不断升温。海量日志分析是一个系统性的工程，包含了从原始数据采集到终端可视化的展示交互等一系列的环节，我们这里将介绍的是在日志采集中使用 CNN 神经网络对日志类型进行自动分类的具体应用。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>在海量系统日志数据采集的过程中经常需要对日志数据进行分类，这些分类工作通常是需要工程师或用户来事先设置指定的。但在实际应用中经常会出现日志类型指定错误或不知道所属类型的情况，经常导致需要对日志进行重新采集，或分析挖掘达不到预期的效果等问题。本篇所介绍的基于 CNN 神经网络的日志类型识别将有效的解决类似问题。</p>
<h1 id="CNN-日志分类"><a href="#CNN-日志分类" class="headerlink" title="CNN 日志分类"></a>CNN 日志分类</h1><p>用于本示例的数据样本来自于 <a href="http://www.monitorware.com/en/logsamples/index.php" target="_blank" rel="external">MonitorWare Log Samples</a>，一共17种日志类型，为示例简化每种日志只选取5条记录，数据内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line">Log Samples---Name</div><div class="line">Mar 29 2004 09:55:23: %PIX-6-302005: Built UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53---Cisco PIX</div><div class="line">Mar 29 2004 09:55:23: %PIX-6-302006: Teardown UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53---Cisco PIX</div><div class="line">Mar 29 2004 09:55:23: %PIX-6-302005: Built UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53---Cisco PIX</div><div class="line">Mar 29 2004 09:55:25: %PIX-6-302005: Built UDP connection for faddr 66.196.65.40/51250 gaddr 10.0.0.187/53 laddr 192.168.0.2/53---Cisco PIX</div><div class="line">Mar 29 2004 09:55:31: %PIX-6-302001: Built outbound TCP connection 152017 for faddr 212.56.240.37/9200 gaddr 10.0.0.187/2795 laddr 192.168.0.2/2795 ()---Cisco PIX</div><div class="line"></div><div class="line">Sun, 2004-03-28 15:30:45 - TCP packet - Source:172.21.0.1,4662 ,LAN - Destination:80.142.227.227,4662 ,WAN [Drop] - [TCP preconnect traffic dropped]---NetGear FWG114P</div><div class="line">Sun, 2004-03-28 15:31:34 - TCP packet - Source:82.82.111.67,4662 ,WAN - Destination:217.224.147.21,4762 ,LAN [Drop] - [TCP preconnect traffic dropped]---NetGear FWG114P</div><div class="line">Sun, 2004-03-28 15:31:39 - TCP packet - Source:80.5.99.100,4662 ,WAN - Destination:217.224.147.21,4788 ,LAN [Drop] - [TCP preconnect traffic dropped]---NetGear FWG114P</div><div class="line">Sun, 2004-03-28 15:36:10 - TCP packet - Source:140.112.243.228,5442 ,WAN - Destination:217.224.147.21,3283 ,LAN [Drop] - [TCP preconnect traffic dropped]---NetGear FWG114P</div><div class="line">Sun, 2004-03-28 15:39:54 - TCP packet - Source:217.234.212.2,0 ,WAN - Destination:217.224.147.21,0 ,LAN [Drop] - [Fragment Attack]---NetGear FWG114P</div><div class="line"></div><div class="line">Mar 12 12:00:08 server2 rcd[308]: Loaded 12 packages in &apos;ximian-red-carpet|351&apos; (0.01878 seconds)---SuSE SLES 8 </div><div class="line">Mar 12 12:00:08 server2 rcd[308]: id=304 COMPLETE &apos;Downloading https://server2/data/red-carpet.rdf&apos; time=0s (failed)---SuSE SLES 8 </div><div class="line">Mar 12 12:00:08 server2 rcd[308]: Unable to downloaded licenses info: Unable to authenticate - Authorization Required (https://server2/data/red-carpet.rdf)---SuSE SLES 8</div><div class="line">Mar 12 12:10:00 server2 /USR/SBIN/CRON[6808]: (root) CMD ( /usr/lib/sa/sa1 )---SuSE SLES 8</div><div class="line">Mar 12 12:20:00 server2 /USR/SBIN/CRON[6837]: (root) CMD ( /usr/lib/sa/sa1 )---SuSE SLES 8</div><div class="line"></div><div class="line">Mar 12 12:01:02 server4 snort: alert_multiple_requests: ACTIVE---RedHat Enterprise Linux</div><div class="line">Mar 12 12:01:02 server4 snort: telnet_decode arguments:---RedHat Enterprise Linux</div><div class="line">Mar 12 12:01:02 server4 snort: snort startup succeeded---RedHat Enterprise Linux</div><div class="line">Mar 12 12:01:02 server4 snort: Ports to decode telnet on: 21 23 25 119---RedHat Enterprise Linux</div><div class="line">Mar 12 12:01:03 server4 snort: Snort initialization completed successfully---RedHat Enterprise Linux</div><div class="line"></div><div class="line">Mar 10 03:19:48 server5 syslog: su : + tty?? root-informix---HP-UX B.10.20 </div><div class="line">Mar 11 03:19:54 server5 syslog: su : + tty?? root-informix---HP-UX B.10.20</div><div class="line">Mar 12 03:19:51 server5 syslog: su : + tty?? root-informix---HP-UX B.10.20 </div><div class="line">Mar 12 09:27:20 server5 syslog: su : - ttyp1 user-informix---HP-UX B.10.20 </div><div class="line">Mar 12 09:27:35 server5 syslog: su : + ttyp1 user-informix---HP-UX B.10.20</div><div class="line"></div><div class="line">Mar 12 08:24:51 server6 sshd[24742]: Accepted password for netscape from 111.222.333.444 port 1420 ssh2---HP UX B.11.00 </div><div class="line">Mar 12 08:25:15 server6 tftpd[24241]: Timeout (no requests in 10 minutes)---HP UX B.11.00</div><div class="line">Mar 12 08:49:53 server6 ftpd[27281]: FTP LOGIN FROM 111.222.333.444 [111.222.333.444], netscape---HP UX B.11.00 </div><div class="line">Mar 12 09:05:22 server6 ftpd[27281]: exiting on signal 14---HP UX B.11.00 </div><div class="line">Mar 12 12:32:24 server6 sshd[11187]: Accepted password for jfalgout from 111.222.333.444 port 34138 ssh2---HP UX B.11.00</div><div class="line"></div><div class="line">Mar 12 11:44:20 server7 ftpd[25306]: Goodbye.---HP UX B.11.11</div><div class="line">Mar 12 11:44:35 server7 tftpd[24955]: Timeout (no requests in 10 minutes)---HP UX B.11.11</div><div class="line">Mar 12 12:17:03 server7 sshd[26501]: pam_authenticate: error Authentication failed---HP UX B.11.11 </div><div class="line">Mar 12 12:17:03 server7 sshd[26501]: Accepted publickey for user from 111.222.333.444 port 32774 ssh2---HP UX B.11.11</div><div class="line">Mar 12 12:34:23 server7 sshd[27393]: pam_authenticate: error Authentication failed---HP UX B.11.11</div><div class="line"></div><div class="line">Mar 16 00:00:08 evita postfix/smtpd[1713]: connect from dialpool-210-214-5-215.maa.sify.net[210.214.5.215]---Postfix</div><div class="line">Mar 16 00:00:09 evita postfix/smtpd[1713]: NOQUEUE: reject: RCPT from dialpool-210-214-5-215.maa.sify.net[210.214.5.215]: 554 Service unavailable; Client host [210.214.5.215] blocked using dnsbl.sorbs.net; Dynamic IP Address See: http://www.dnsbl.sorbs.net/cgi-bin/lookup?IP=210.214.5.215; from= to= proto=SMTP helo=---Postfix </div><div class="line">Mar 16 00:00:11 evita postfix/smtpd[1713]: disconnect from dialpool-210-214-5-215.maa.sify.net[210.214.5.215]---Postfix</div><div class="line">Mar 16 00:01:25 evita postfix/smtpd[1713]: connect from camomile.cloud9.net[168.100.1.3]---Postfix </div><div class="line">Mar 16 00:01:28 evita postfix/smtpd[1713]: EA11834022: client=camomile.cloud9.net[168.100.1.3]---Postfix</div><div class="line"></div><div class="line">64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] &quot;GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1&quot; 401 12846---Apache</div><div class="line">64.242.88.10 - - [07/Mar/2004:16:06:51 -0800] &quot;GET /twiki/bin/rdiff/TWiki/NewUserTemplate?rev1=1.3&amp;rev2=1.2 HTTP/1.1&quot; 200 4523---Apache</div><div class="line">64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] &quot;GET /mailman/listinfo/hsdivision HTTP/1.1&quot; 200 6291---Apache</div><div class="line">64.242.88.10 - - [07/Mar/2004:16:11:58 -0800] &quot;GET /twiki/bin/view/TWiki/WikiSyntax HTTP/1.1&quot; 200 7352---Apache</div><div class="line">64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] &quot;GET /twiki/bin/view/Main/DCCAndPostFix HTTP/1.1&quot; 200 5253---Apache</div><div class="line"></div><div class="line">Feb 2 09:00:14 avas.example.com amavisd[11568]: Perl version 5.008001---Amavis-New</div><div class="line">Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Amavis::Conf 1.15---Amavis-New</div><div class="line">Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Tar 1.07---Amavis-New</div><div class="line">Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Zip 1.08---Amavis-New</div><div class="line">Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Compress::Zlib 1.31---Amavis-New</div><div class="line"></div><div class="line">Mar 7 04:05:00 avas CROND[11233]: (cronjob) CMD (/usr/bin/mrtg /etc/mrtg/mrtg.cfg)---Cron Daemon </div><div class="line">Mar 7 04:05:00 avas CROND[11234]: (mailman) CMD (/usr/local/bin/python -S /usr/local/mailman/cron/gate_news)---Cron Daemon </div><div class="line">Mar 7 04:10:00 avas CROND[11253]: (cronjob) CMD (/usr/bin/mrtg /etc/mrtg/mrtg.cfg)---Cron Daemon </div><div class="line">Mar 7 04:10:00 avas CROND[11254]: (cronjob) CMD (/usr/lib/sa/sa1 1 1)---Cron Daemon </div><div class="line">Mar 7 04:10:00 avas CROND[11257]: (cronjob) CMD (/sbin/dcccollect.sh)---Cron Daemon</div><div class="line"></div><div class="line">Mar 6 03:52:07 avas dccd[13284]: 1.2.32 database /home/dcc/dcc_db reopened with 997 MByte window---Distributed Checksum Clearinghouse Server</div><div class="line">Mar 6 04:12:03 avas dccd[13284]: &quot;packet length 44 too small for REPORT&quot; sent to client 1 at 80.8.131.68,41000---Distributed Checksum Clearinghouse Server</div><div class="line">Mar 6 19:01:12 avas dccd[13284]: no incoming flood connection from dcc1.example.no, server-ID XXXX---Distributed Checksum Clearinghouse Server</div><div class="line">Mar 6 19:01:42 avas dccd[13284]: no outgoing flood connection to dcc1.example.no, server-ID XXXX---Distributed Checksum Clearinghouse Server</div><div class="line">Mar 6 20:06:37 avas dccd[13284]: &quot;packet length 44 too small for REPORT&quot; sent to client 1 at 194.63.250.215,56007---Distributed Checksum Clearinghouse Server</div><div class="line"></div><div class="line">Mar 12 13:23:58 avas sshd[23510]: Failed none for illegal user phil from 10.0.0.153 port 2006 ssh2---Red Hat Linux Server</div><div class="line">Mar 12 13:23:58 avas sshd[23510]: Failed keyboard-interactive for illegal user phil from 10.0.0.153 port 2006 ssh2---Red Hat Linux Server</div><div class="line">Mar 12 13:23:58 avas sshd[23510]: Disconnecting: Too many authentication failures for avas.cnc.bc.ca---Red Hat Linux Server</div><div class="line">Mar 12 13:24:17 avas sshd[23522]: Could not reverse map address 10.0.0.153.---Red Hat Linux Server</div><div class="line">Mar 12 13:24:17 avas sshd[23522]: Accepted password for tom from 10.0.0.153 port 2007 ssh2---Red Hat Linux Server</div><div class="line"></div><div class="line">[13:35:15] [13:35:15] Scanning for directory /usr/lib/...... [13:35:15] OK. Not found.---RK Hunter</div><div class="line">[13:35:15] [13:35:15] Scanning for directory /usr/lib/.../bkit-ssh... [13:35:15] OK. Not found.---RK Hunter</div><div class="line">[13:35:15] [13:35:15] Scanning for directory /usr/lib/.bkit-... [13:35:15] OK. Not found.---RK Hunter</div><div class="line">[13:35:15] [13:35:15] Scanning for directory /tmp/.bkp... [13:35:15] OK. Not found.---RK Hunter</div><div class="line">[13:35:15] [13:35:15] *** Start scan CiNIK Worm (Slapper.B variant) ***---RK Hunter</div><div class="line"></div><div class="line">[Sun Mar 7 05:39:40 2004] up2date new up2date run started---Up 2 Date</div><div class="line">[Sun Mar 7 05:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0---Up 2 Date</div><div class="line">[Sun Mar 7 05:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0---Up 2 Date</div><div class="line">[Sun Mar 7 09:39:40 2004] up2date new up2date run started---Up 2 Date</div><div class="line">[Sun Mar 7 09:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0---Up 2 Date</div><div class="line"></div><div class="line">[11-29-2002 - 15:22:37] Client at 24.69.73.3: URL contains high bit character. Request will be rejected. Site Instance=&apos;1&apos;, Raw URL=&apos;/scripts/mail.exe/2001���.jpg&apos;---URL Scan</div><div class="line">[11-29-2002 - 15:22:47] Client at 24.69.73.3: URL contains high bit character. Request will be rejected. Site Instance=&apos;1&apos;, Raw URL=&apos;/scripts/mail.exe/2001���.jpg&apos;---URL Scan</div><div class="line">[11-29-2002 - 21:15:17] Client at 24.67.253.204: URL contains extension &apos;.com&apos;, which is disallowed. Request will be rejected. Site Instance=&apos;1&apos;, Raw URL=&apos;/scripts/www.the5yearjournal.com&apos;---URL Scan</div><div class="line">[12-02-2002 - 09:52:33] Client at 142.27.68.15: URL contains high bit character. Request will be rejected. Site Instance=&apos;1&apos;, Raw URL=&apos;/scripts/mail.exe/2001%C2%A4%C3%AB%C2%BE%C3%A4.jpg&apos;---URL Scan</div><div class="line">[12-02-2002 - 09:52:43] Client at 142.27.68.15: URL contains high bit character. Request will be rejected. Site Instance=&apos;1&apos;, Raw URL=&apos;/scripts/mail.exe/2001%C2%A4%C3%AB%C2%BE%C3%A4.jpg&apos;---URL Scan</div><div class="line"></div><div class="line">(II) PCI: 00:00:0: chip 8086,2560 card 174b,174b rev 03 class 06,00,00 hdr 00---X Free 86</div><div class="line">(II) PCI: 00:02:0: chip 8086,2562 card 174b,174b rev 03 class 03,00,00 hdr 00---X Free 86</div><div class="line">(II) PCI: 00:1d:0: chip 8086,24c2 card 174b,174b rev 02 class 0c,03,00 hdr 80---X Free 86</div><div class="line">(II) PCI: 00:1d:1: chip 8086,24c4 card 174b,174b rev 02 class 0c,03,00 hdr 00---X Free 86</div><div class="line">(II) PCI: 00:1d:2: chip 8086,24c7 card 174b,174b rev 02 class 0c,03,00 hdr 00---X Free 86</div></pre></td></tr></table></figure>
<p>为避免与日志文本内容冲突，本 CSV 的列分隔符选用的是3个“-”。<br>本示例的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># CNN for the logs classificaton</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution1D</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling1D</div><div class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</div><div class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"></div><div class="line"><span class="comment"># utils functions define</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">str2numbers</span><span class="params">(strs)</span>:</span></div><div class="line">	res = []</div><div class="line">	<span class="keyword">for</span> str <span class="keyword">in</span> strs:</div><div class="line">		wArr = []</div><div class="line">		words = re.split(<span class="string">"[\s\/]"</span>,str)</div><div class="line">		<span class="keyword">for</span> word <span class="keyword">in</span> words:</div><div class="line">			wArr.append(sum([ord(c) <span class="keyword">for</span> c <span class="keyword">in</span> word]))</div><div class="line">		res.append(wArr)</div><div class="line">	<span class="keyword">return</span> res</div><div class="line">	</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictions2className</span><span class="params">(classes,predictions)</span>:</span></div><div class="line">	res = []</div><div class="line">	<span class="keyword">for</span> prediction <span class="keyword">in</span> predictions:</div><div class="line">		index = numpy.argmax(prediction)</div><div class="line">		res.append(classes[index])</div><div class="line">	<span class="keyword">return</span> res</div><div class="line"></div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"></div><div class="line">dataframe = pandas.read_csv(<span class="string">'sys-log.csv'</span>, sep=<span class="string">'---'</span>, engine=<span class="string">'python'</span>)</div><div class="line">dataset = dataframe.values</div><div class="line">numpy.random.shuffle(dataset)</div><div class="line">X_str = dataset[:,<span class="number">0</span>]</div><div class="line">y_str = dataset[:,<span class="number">1</span>]</div><div class="line"></div><div class="line">train_size = int(len(X_str) * <span class="number">0.8</span>)</div><div class="line">test_size = len(X_str) - train_size</div><div class="line"></div><div class="line">X_num = str2numbers(X_str)</div><div class="line">X_train = X_num[:train_size]</div><div class="line">X_test = X_num[train_size:]</div><div class="line"></div><div class="line">classes, y_num = numpy.unique(y_str, return_inverse=<span class="keyword">True</span>)</div><div class="line">y_oneHot = np_utils.to_categorical(y_num)</div><div class="line">y_train = y_oneHot[:train_size]</div><div class="line">y_test = y_oneHot[train_size:]</div><div class="line"></div><div class="line"><span class="comment"># pad dataset to a maximum review length in words</span></div><div class="line">max_words = <span class="number">100</span></div><div class="line">X_train = sequence.pad_sequences(X_train, maxlen=max_words)</div><div class="line">X_test = sequence.pad_sequences(X_test, maxlen=max_words)</div><div class="line"></div><div class="line"><span class="comment"># create the model</span></div><div class="line">top_words = <span class="number">10000</span></div><div class="line">outputs = len(classes)</div><div class="line">model = Sequential()</div><div class="line">model.add(Embedding(top_words, <span class="number">32</span>, input_length=max_words))</div><div class="line">model.add(Convolution1D(nb_filter=<span class="number">32</span>, filter_length=<span class="number">3</span>, border_mode=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling1D(pool_length=<span class="number">2</span>))</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">250</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(outputs, activation=<span class="string">'softmax'</span>))</div><div class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">print(model.summary())</div><div class="line"></div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">30</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">1</span>)</div><div class="line"><span class="comment"># Final evaluation of the model</span></div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"Accuracy: %.2f%%"</span> % (scores[<span class="number">1</span>]*<span class="number">100</span>))</div><div class="line"></div><div class="line">predictions = model.predict(X_test, verbose=<span class="number">0</span>)</div><div class="line">result = predictions2className(classes, predictions)</div><div class="line"><span class="keyword">print</span> <span class="string">"############## Test logs: "</span>,X_str[train_size:]</div><div class="line"><span class="keyword">print</span> <span class="string">"############## Log types: "</span>,y_str[train_size:]</div><div class="line"><span class="keyword">print</span> <span class="string">"############## Prediction types: "</span>,result</div></pre></td></tr></table></figure>
<p>运行示例前，请先保存上文样本数据到本示例代码相同目录下，文件名为“sys-log.csv”。接下来我们将对上例关键代码部分进行详细讲解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dataframe = pandas.read_csv(<span class="string">'sys-log.csv'</span>, sep=<span class="string">'---'</span>, engine=<span class="string">'python'</span>)</div></pre></td></tr></table></figure>
<p>通过 <a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a> 库对 CSV 数据进行加载，以“—”为列分隔符。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numpy.random.shuffle(dataset)</div></pre></td></tr></table></figure>
<p>我们的样本数据是按日志类型进行编辑整理的，这里对加载后数据进行了顺序随机重排，以使样本数据更好的用于模型训练和测试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">train_size = int(len(X_str) * <span class="number">0.8</span>)</div><div class="line">test_size = len(X_str) - train_size</div></pre></td></tr></table></figure>
<p>我们划分样本数据的80%用于训练，20%用于测试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">X_num = str2numbers(X_str)</div></pre></td></tr></table></figure>
<p>这里我们对日志文本内容进行了形式上的转换，将每个单词转换成了相应的整数，具体方法请参见<code>str2numbers()</code>函数内容。将单词转换为整数的作用是为后文的单词嵌入（word embedding）做准备，后面会详细介绍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">classes, y_num = numpy.unique(y_str, return_inverse=<span class="keyword">True</span>)</div><div class="line">y_oneHot = np_utils.to_categorical(y_num)</div></pre></td></tr></table></figure>
<p>将日志类型的目标输出转换为 <a href="https://en.wikipedia.org/wiki/One-hot" target="_blank" rel="external">One-hot</a> 的表示形式，主要由 Keras 工具类 <code>np_utils</code> 所提供的 <code>to_categorical</code> 方法来完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">max_words = <span class="number">100</span></div><div class="line">X_train = sequence.pad_sequences(X_train, maxlen=max_words)</div><div class="line">X_test = sequence.pad_sequences(X_test, maxlen=max_words)</div></pre></td></tr></table></figure>
<p>进行模型处理前，我们将每组数据标准化为统一的长度，本例设置的是100，具体根据数据的大小而定。<code>sequence</code>类的<code>pad_sequences</code>方法可以根据<code>maxlen</code>参数指定的长度对传入数据的每一项进行处理。当数据长度小于<code>maxlen</code>时，自动左添0补全；当数据长度大于<code>maxlen</code>时，则从数据的右端开始进行<code>maxlen</code>长度保留。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(Embedding(top_words, <span class="number">32</span>, input_length=max_words))</div></pre></td></tr></table></figure>
<p>Embedding 层添加。单词嵌入<a href="https://en.wikipedia.org/wiki/Word_embedding" target="_blank" rel="external">（word embedding）</a>是机器学习自然语言处理（NLP）中所使用的一种词汇处理方法，实现的是将单词转换为高维空间的实向量，单词间在语义上越接近，在向量空间中的距离就越近，同时也使转换后的词汇矩阵维度更低。我们在此添加 Embedding 层的作用是将每条维度为1x100的日志数据转换为32x100矩阵形式，之后输入给卷积层进行特征提取。<br><code>top_words</code>：输入数据的最大表示数值，也称为词汇容量（vocabulary size），输入数据词汇的最大数值要小于该值；<br><code>32</code>：输出矩阵的行数；<br><code>input_length</code>：输入数据长度。当模型后续有 Flatten 层时，该参数必须提供，以为其提供数据维度信息；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">model.add(Convolution1D(nb_filter=<span class="number">32</span>, filter_length=<span class="number">3</span>, border_mode=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling1D(pool_length=<span class="number">2</span>))</div></pre></td></tr></table></figure>
<p>Convolution1D 层具体实现的是一维卷积计算，功能原理与 Convolution2D 相同。这里设置的过滤器数量为<code>32</code>，过滤器大小为<code>3</code>，边缘处理模式为<code>same</code>，激活函数类型为<code>relu</code>；<br>卷积层之后我们添加的是 MaxPooling1D 层，对上一层提取到的特征图谱进行取最大汇集操作，汇集长度为<code>2</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">250</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(outputs, activation=<span class="string">'softmax'</span>))</div></pre></td></tr></table></figure>
<p>数据有卷积结构汇集层输出后，我们添加了 Flatten 层将2维矩阵转换为1维向量，之后传递给全连接神经网络结构（隐含层：250个隐含神经元，输出层：<code>outputs</code>个神经元）。因为我们这里是要对输入结果做分类判断，所以输出的激活函数类型选择的是<code>softmax</code>。<br>下面是运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">Epoch <span class="number">28</span>/<span class="number">30</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">5.9754e-04</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.3522</span> - val_acc: <span class="number">0.8824</span></div><div class="line">Epoch <span class="number">29</span>/<span class="number">30</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">5.4314e-04</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.3508</span> - val_acc: <span class="number">0.8824</span></div><div class="line">Epoch <span class="number">30</span>/<span class="number">30</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">5.0137e-04</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.3527</span> - val_acc: <span class="number">0.8824</span></div><div class="line">Accuracy: <span class="number">88.24</span>%</div><div class="line"><span class="comment">############## Test logs:  [ 'Mar 29 2004 09:55:23: %PIX-6-302005: Built UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53'</span></div><div class="line"> <span class="string">'64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] "GET /twiki/bin/view/Main/DCCAndPostFix HTTP/1.1" 200 5253'</span></div><div class="line"> <span class="string">'Sun, 2004-03-28 15:31:39 - TCP packet - Source:80.5.99.100,4662 ,WAN - Destination:217.224.147.21,4788 ,LAN [Drop] - [TCP preconnect traffic dropped]'</span></div><div class="line"> <span class="string">'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Zip 1.08'</span></div><div class="line"> <span class="string">'(II) PCI: 00:1d:1: chip 8086,24c4 card 174b,174b rev 02 class 0c,03,00 hdr 00'</span></div><div class="line"> <span class="string">'Mar 16 00:01:28 evita postfix/smtpd[1713]: EA11834022: client=camomile.cloud9.net[168.100.1.3]'</span></div><div class="line"> <span class="string">'Sun, 2004-03-28 15:36:10 - TCP packet - Source:140.112.243.228,5442 ,WAN - Destination:217.224.147.21,3283 ,LAN [Drop] - [TCP preconnect traffic dropped]'</span></div><div class="line"> <span class="string">'64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] "GET /mailman/listinfo/hsdivision HTTP/1.1" 200 6291'</span></div><div class="line"> <span class="string">'[Sun Mar 7 05:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0'</span></div><div class="line"> <span class="string">'(II) PCI: 00:00:0: chip 8086,2560 card 174b,174b rev 03 class 06,00,00 hdr 00'</span></div><div class="line"> <span class="string">'Mar 12 12:20:00 server2 /USR/SBIN/CRON[6837]: (root) CMD ( /usr/lib/sa/sa1 )'</span></div><div class="line"> <span class="string">'Mar 6 19:01:12 avas dccd[13284]: no incoming flood connection from dcc1.example.no, server-ID XXXX'</span></div><div class="line"> <span class="string">'Mar 12 09:27:20 server5 syslog: su : - ttyp1 user-informix'</span></div><div class="line"> <span class="string">'[13:35:15] [13:35:15] Scanning for directory /usr/lib/.bkit-... [13:35:15] OK. Not found.'</span></div><div class="line"> <span class="string">'Mar 12 08:24:51 server6 sshd[24742]: Accepted password for netscape from 111.222.333.444 port 1420 ssh2'</span></div><div class="line"> <span class="string">'[13:35:15] [13:35:15] Scanning for directory /tmp/.bkp... [13:35:15] OK. Not found.'</span></div><div class="line"> <span class="string">'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Tar 1.07'</span>]</div><div class="line"><span class="comment">############## Log types:  ['Cisco PIX' 'Apache' 'NetGear FWG114P' 'Amavis-New' 'X Free 86' 'Postfix'</span></div><div class="line"> <span class="string">'NetGear FWG114P'</span> <span class="string">'Apache'</span> <span class="string">'Up 2 Date'</span> <span class="string">'X Free 86'</span> <span class="string">'SuSE SLES 8'</span></div><div class="line"> <span class="string">'Distributed Checksum Clearinghouse Server'</span> <span class="string">'HP-UX B.10.20'</span> <span class="string">'RK Hunter'</span></div><div class="line"> <span class="string">'HP UX B.11.00'</span> <span class="string">'RK Hunter'</span> <span class="string">'Amavis-New'</span>]</div><div class="line"><span class="comment">############## Prediction types:  ['Cisco PIX', 'Apache', 'NetGear FWG114P', 'Amavis-New', 'X Free 86', 'RedHat Enterprise Linux', 'NetGear FWG114P', 'SuSE SLES 8', 'Up 2 Date', 'X Free 86', 'SuSE SLES 8', 'Distributed Checksum Clearinghouse Server', 'HP-UX B.10.20', 'RK Hunter', 'HP UX B.11.00', 'RK Hunter', 'Amavis-New']</span></div></pre></td></tr></table></figure>
<p>测评的识别准确率为88.24%，结下来我们将对本模型进行扩展，看一下多层卷积结构模型的表现如何。</p>
<h1 id="多层卷积结构"><a href="#多层卷积结构" class="headerlink" title="多层卷积结构"></a>多层卷积结构</h1><p>多层卷积结构模型扩展代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(Embedding(top_words, <span class="number">32</span>, input_length=max_words))</div><div class="line">model.add(Convolution1D(nb_filter=<span class="number">32</span>, filter_length=<span class="number">3</span>, border_mode=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling1D(pool_length=<span class="number">2</span>))</div><div class="line">model.add(Convolution1D(nb_filter=<span class="number">32</span>, filter_length=<span class="number">3</span>, border_mode=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling1D(pool_length=<span class="number">2</span>))</div><div class="line">model.add(Flatten())</div><div class="line">model.add(Dense(<span class="number">250</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(outputs, activation=<span class="string">'softmax'</span>))</div></pre></td></tr></table></figure>
<p>我们在上例的基础上又增添了一层 Convolution1D 层和 MaxPooling1D 层。<br>下面是运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">Epoch <span class="number">18</span>/<span class="number">20</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.0143</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.6617</span> - val_acc: <span class="number">0.9412</span></div><div class="line">Epoch <span class="number">19</span>/<span class="number">20</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.0095</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.6646</span> - val_acc: <span class="number">0.8824</span></div><div class="line">Epoch <span class="number">20</span>/<span class="number">20</span></div><div class="line"><span class="number">68</span>/<span class="number">68</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.0045</span> - acc: <span class="number">1.0000</span> - val_loss: <span class="number">0.6602</span> - val_acc: <span class="number">0.9412</span></div><div class="line">Accuracy: <span class="number">94.12</span>%</div><div class="line"><span class="comment">############## Test logs:  [ 'Mar 29 2004 09:55:23: %PIX-6-302005: Built UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53'</span></div><div class="line"> <span class="string">'64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] "GET /twiki/bin/view/Main/DCCAndPostFix HTTP/1.1" 200 5253'</span></div><div class="line"> <span class="string">'Sun, 2004-03-28 15:31:39 - TCP packet - Source:80.5.99.100,4662 ,WAN - Destination:217.224.147.21,4788 ,LAN [Drop] - [TCP preconnect traffic dropped]'</span></div><div class="line"> <span class="string">'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Zip 1.08'</span></div><div class="line"> <span class="string">'(II) PCI: 00:1d:1: chip 8086,24c4 card 174b,174b rev 02 class 0c,03,00 hdr 00'</span></div><div class="line"> <span class="string">'Mar 16 00:01:28 evita postfix/smtpd[1713]: EA11834022: client=camomile.cloud9.net[168.100.1.3]'</span></div><div class="line"> <span class="string">'Sun, 2004-03-28 15:36:10 - TCP packet - Source:140.112.243.228,5442 ,WAN - Destination:217.224.147.21,3283 ,LAN [Drop] - [TCP preconnect traffic dropped]'</span></div><div class="line"> <span class="string">'64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] "GET /mailman/listinfo/hsdivision HTTP/1.1" 200 6291'</span></div><div class="line"> <span class="string">'[Sun Mar 7 05:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0'</span></div><div class="line"> <span class="string">'(II) PCI: 00:00:0: chip 8086,2560 card 174b,174b rev 03 class 06,00,00 hdr 00'</span></div><div class="line"> <span class="string">'Mar 12 12:20:00 server2 /USR/SBIN/CRON[6837]: (root) CMD ( /usr/lib/sa/sa1 )'</span></div><div class="line"> <span class="string">'Mar 6 19:01:12 avas dccd[13284]: no incoming flood connection from dcc1.example.no, server-ID XXXX'</span></div><div class="line"> <span class="string">'Mar 12 09:27:20 server5 syslog: su : - ttyp1 user-informix'</span></div><div class="line"> <span class="string">'[13:35:15] [13:35:15] Scanning for directory /usr/lib/.bkit-... [13:35:15] OK. Not found.'</span></div><div class="line"> <span class="string">'Mar 12 08:24:51 server6 sshd[24742]: Accepted password for netscape from 111.222.333.444 port 1420 ssh2'</span></div><div class="line"> <span class="string">'[13:35:15] [13:35:15] Scanning for directory /tmp/.bkp... [13:35:15] OK. Not found.'</span></div><div class="line"> <span class="string">'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Tar 1.07'</span>]</div><div class="line"><span class="comment">############## Log types:  ['Cisco PIX' 'Apache' 'NetGear FWG114P' 'Amavis-New' 'X Free 86' 'Postfix'</span></div><div class="line"> <span class="string">'NetGear FWG114P'</span> <span class="string">'Apache'</span> <span class="string">'Up 2 Date'</span> <span class="string">'X Free 86'</span> <span class="string">'SuSE SLES 8'</span></div><div class="line"> <span class="string">'Distributed Checksum Clearinghouse Server'</span> <span class="string">'HP-UX B.10.20'</span> <span class="string">'RK Hunter'</span></div><div class="line"> <span class="string">'HP UX B.11.00'</span> <span class="string">'RK Hunter'</span> <span class="string">'Amavis-New'</span>]</div><div class="line"><span class="comment">############## Prediction types:  ['Cisco PIX', 'Apache', 'NetGear FWG114P', 'Amavis-New', 'X Free 86', 'Up 2 Date', 'NetGear FWG114P', 'Apache', 'Up 2 Date', 'X Free 86', 'SuSE SLES 8', 'Distributed Checksum Clearinghouse Server', 'HP-UX B.10.20', 'RK Hunter', 'HP UX B.11.00', 'RK Hunter', 'Amavis-New']</span></div></pre></td></tr></table></figure>
<p>本例中多层卷积模型的测试准确率相对有所提高。需要注意的是我们这里主要是用于介绍多层卷积结构的构建方法，至于具体测试结果是否相对单层结构有所改进还是要具体问题具体分析。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过本篇的阅读，您知道了 CNN 在系统日志识别分类上的具体实现方法。本篇的示例代码还有很大的改进空间，希望您可以在此基础上继续改进取得更好的效果。同时也希望本篇所介绍的方法能应用到您的具体工作中去，让我们一同向世界展示深度学习的魅力：）</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/predict-sentiment-movie-reviews-using-deep-learning/" target="_blank" rel="external">Predict Sentiment From Movie Reviews Using Deep Learning</a></li>
<li><a href="https://arxiv.org/pdf/1602.00367v1.pdf" target="_blank" rel="external">Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers</a></li>
<li><a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/" target="_blank" rel="external">Deep Learning, NLP, and Representations</a></li>
<li><a href="https://keras.io/layers/embeddings/" target="_blank" rel="external">Docs » Layers » Embedding Layers</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/02/01/deeplearning/sys-log-classification-by-CNN/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br&gt;卷积神经网络（CNN）是当前广泛应用的深度学习神经网络类型之一，特点是可以自动对数据特征进行提取学习。CNN 在图片识别，语义分析等领域已经取得了非常令人振奋的成绩，本篇将介绍使用 CNN 对系统日志进行识别分类的具体方法。在通过阅读本篇内容您将了解到：&lt;br&gt;- 文本数据进行 CNN 分析的相关预处理方法；&lt;br&gt;- CNN 一维卷积网络的具体构建和用法；&lt;br&gt;- CNN 对系统日志进行分类的具体应用；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>基于 LSTM RNN 的序列数据预测</title>
    <link href="http://yoursite.com/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/"/>
    <id>http://yoursite.com/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/</id>
    <published>2017-01-15T13:32:01.000Z</published>
    <updated>2017-06-04T00:44:18.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/0.jpg" alt="0.jpg" title=""> <br>循环神经网络（RNN）是当前广泛应用的深度学习神经网络类型之一，特点是对训练数据具有记忆特性，在处理序列数据预测问题上相对优势明显。本篇将结合示例介绍 LSTM RNN 模型的具体构建和使用。在通过阅读本篇内容您将了解到：<br>- LSTM 网络的构建与使用；<br>- 序列数据预测的具体实现方法；<br><a id="more"></a>
<h1 id="LSTM-介绍"><a href="#LSTM-介绍" class="headerlink" title="LSTM 介绍"></a>LSTM 介绍</h1><p>短时记忆循环神经网络（Long Short-Term Memory network，LSTM）是经过改进的 RNN 神经网络。在网络训练中 LSTM 有效的解决了梯度消失问题，因此常被用于大型 RNN 网络构建，也是当前应用最广的 RNN 网络类型之一。LSTM 对结果的预测可以根据前序输入数据（前文环境）的基础上进行判断输出。<br>我们接下来将结合具体示例对 LSTM 网络模型的具体构建和使用进行介绍。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>我们本次示例所处理的数据样本是模拟网络服务每秒接到 HTTP 请求的次数，时长为100s。我们将构建 LSTM 网络模型对这100s范围内的请求数据进行训练学习，然后对紧接着后续时间内的 HTTP 请求情况进行预测。<br>样本数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line">timestamp,count</div><div class="line">1485773733123,1139</div><div class="line">1485773734123,1760</div><div class="line">1485773735123,1888</div><div class="line">1485773736123,1880</div><div class="line">1485773737123,1601</div><div class="line">1485773738123,1317</div><div class="line">1485773739123,1097</div><div class="line">1485773740123,1526</div><div class="line">1485773741123,1413</div><div class="line">1485773742123,1211</div><div class="line">1485773743123,1466</div><div class="line">1485773744123,1178</div><div class="line">1485773745123,1873</div><div class="line">1485773746123,1108</div><div class="line">1485773747123,1331</div><div class="line">1485773748123,1944</div><div class="line">1485773749123,1760</div><div class="line">1485773750123,1255</div><div class="line">1485773751123,1717</div><div class="line">1485773752123,1597</div><div class="line">1485773753123,1301</div><div class="line">1485773754123,1445</div><div class="line">1485773755123,1950</div><div class="line">1485773756123,1552</div><div class="line">1485773757123,1277</div><div class="line">1485773758123,1619</div><div class="line">1485773759123,1801</div><div class="line">1485773760123,1218</div><div class="line">1485773761123,1372</div><div class="line">1485773762123,1254</div><div class="line">1485773763123,1494</div><div class="line">1485773764123,1916</div><div class="line">1485773765123,1949</div><div class="line">1485773766123,1277</div><div class="line">1485773767123,1009</div><div class="line">1485773768123,1423</div><div class="line">1485773769123,1015</div><div class="line">1485773770123,1300</div><div class="line">1485773771123,1476</div><div class="line">1485773772123,1697</div><div class="line">1485773773123,1424</div><div class="line">1485773774123,1530</div><div class="line">1485773775123,1359</div><div class="line">1485773776123,1275</div><div class="line">1485773777123,1108</div><div class="line">1485773778123,1509</div><div class="line">1485773779123,1368</div><div class="line">1485773780123,1872</div><div class="line">1485773781123,1846</div><div class="line">1485773782123,1374</div><div class="line">1485773783123,1726</div><div class="line">1485773784123,1482</div><div class="line">1485773785123,1668</div><div class="line">1485773786123,1887</div><div class="line">1485773787123,1308</div><div class="line">1485773788123,1307</div><div class="line">1485773789123,1452</div><div class="line">1485773790123,1482</div><div class="line">1485773791123,1893</div><div class="line">1485773792123,1804</div><div class="line">1485773793123,1012</div><div class="line">1485773794123,1445</div><div class="line">1485773795123,1282</div><div class="line">1485773796123,1978</div><div class="line">1485773797123,1247</div><div class="line">1485773798123,1045</div><div class="line">1485773799123,1415</div><div class="line">1485773800123,1350</div><div class="line">1485773801123,1373</div><div class="line">1485773802123,1792</div><div class="line">1485773803123,1190</div><div class="line">1485773804123,1678</div><div class="line">1485773805123,1087</div><div class="line">1485773806123,1612</div><div class="line">1485773807123,1706</div><div class="line">1485773808123,1262</div><div class="line">1485773809123,1472</div><div class="line">1485773810123,1695</div><div class="line">1485773811123,1055</div><div class="line">1485773733123,1155</div><div class="line">1485773734123,1766</div><div class="line">1485773735123,1893</div><div class="line">1485773736123,1886</div><div class="line">1485773737123,1607</div><div class="line">1485773738123,1322</div><div class="line">1485773739123,1102</div><div class="line">1485773740123,1533</div><div class="line">1485773741123,1418</div><div class="line">1485773742123,1216</div><div class="line">1485773743123,1470</div><div class="line">1485773744123,1183</div><div class="line">1485773745123,1880</div><div class="line">1485773746123,1112</div><div class="line">1485773747123,1336</div><div class="line">1485773748123,1950</div><div class="line">1485773749123,1766</div><div class="line">1485773750123,1258</div><div class="line">1485773751123,1725</div><div class="line">1485773752123,1601</div></pre></td></tr></table></figure></p>
<h1 id="数据预览"><a href="#数据预览" class="headerlink" title="数据预览"></a>数据预览</h1><p>我们先用 matplotlib 库对样本数据进行绘图，对整体数据有个概览。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">dataset = pandas.read_csv(<span class="string">'http-request.csv'</span>, usecols=[<span class="number">1</span>], engine=<span class="string">'python'</span>)</div><div class="line">plt.plot(dataset)</div><div class="line">plt.show()</div></pre></td></tr></table></figure></p>
<p>运行示例代码前，请先保存上文样本数据到与示例代码相同的目录下，命名为“http-request.csv”。<br>我们通过 <a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a> 库对数据进行加载，这里只选取 CSV 文件内容的第二列数据。数据绘图如下：<br><img src="/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/demo-data.png" alt="demo-data.png" title=""></p>
<h1 id="LSTM-学习预测"><a href="#LSTM-学习预测" class="headerlink" title="LSTM 学习预测"></a>LSTM 学习预测</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># LSTM DEMO</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</div><div class="line"><span class="comment"># convert an array of values into a dataset matrix</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(dataset, look_back=<span class="number">1</span>)</span>:</span></div><div class="line">	dataX, dataY = [], []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)-look_back<span class="number">-1</span>):</div><div class="line">		a = dataset[i:(i+look_back), <span class="number">0</span>]</div><div class="line">		dataX.append(a)</div><div class="line">		dataY.append(dataset[i + look_back, <span class="number">0</span>])</div><div class="line">	<span class="keyword">return</span> numpy.array(dataX), numpy.array(dataY)</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">numpy.random.seed(<span class="number">7</span>)</div><div class="line"><span class="comment"># load the dataset</span></div><div class="line">dataframe = pandas.read_csv(<span class="string">'http-request.csv'</span>, usecols=[<span class="number">1</span>], engine=<span class="string">'python'</span>)</div><div class="line">dataset = dataframe.values</div><div class="line">dataset = dataset.astype(<span class="string">'float32'</span>)</div><div class="line"><span class="comment"># normalize the dataset</span></div><div class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</div><div class="line">dataset = scaler.fit_transform(dataset)</div><div class="line"><span class="comment"># split into train and test sets</span></div><div class="line">train_size = int(len(dataset) * <span class="number">0.8</span>)</div><div class="line">test_size = len(dataset) - train_size</div><div class="line">train, test = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:len(dataset),:]</div><div class="line"><span class="comment"># reshape into X=t and Y=t+1</span></div><div class="line">look_back = <span class="number">3</span></div><div class="line">trainX, trainY = create_dataset(train, look_back)</div><div class="line">testX, testY = create_dataset(test, look_back)</div><div class="line"><span class="comment"># reshape input to be [samples, time steps, features]</span></div><div class="line">trainX = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], trainX.shape[<span class="number">1</span>], <span class="number">1</span>))</div><div class="line">testX = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], testX.shape[<span class="number">1</span>], <span class="number">1</span>))</div><div class="line"><span class="comment"># create and fit the LSTM network</span></div><div class="line">model = Sequential()</div><div class="line">model.add(LSTM(<span class="number">128</span>, input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))</div><div class="line">model.add(Dense(<span class="number">1</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line">model.fit(trainX, trainY, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">2</span>)</div><div class="line"><span class="comment"># make predictions</span></div><div class="line">trainPredict = model.predict(trainX)</div><div class="line">testPredict = model.predict(testX)</div><div class="line"><span class="comment"># invert predictions</span></div><div class="line">trainPredict = scaler.inverse_transform(trainPredict)</div><div class="line">trainY = scaler.inverse_transform([trainY])</div><div class="line">testPredict = scaler.inverse_transform(testPredict)</div><div class="line">testY = scaler.inverse_transform([testY])</div><div class="line"><span class="comment"># calculate root mean squared error</span></div><div class="line">trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:,<span class="number">0</span>]))</div><div class="line">print(<span class="string">'Train Score: %.2f RMSE'</span> % (trainScore))</div><div class="line">testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:,<span class="number">0</span>]))</div><div class="line">print(<span class="string">'Test Score: %.2f RMSE'</span> % (testScore))</div><div class="line"><span class="comment"># shift train predictions for plotting</span></div><div class="line">trainPredictPlot = numpy.empty_like(dataset)</div><div class="line">trainPredictPlot[:, :] = numpy.nan</div><div class="line">trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict</div><div class="line"><span class="comment"># shift test predictions for plotting</span></div><div class="line">testPredictPlot = numpy.empty_like(dataset)</div><div class="line">testPredictPlot[:, :] = numpy.nan</div><div class="line">testPredictPlot[len(trainPredict)+(look_back*<span class="number">2</span>)+<span class="number">1</span>:len(dataset)<span class="number">-1</span>, :] = testPredict</div><div class="line"><span class="comment"># plot baseline and predictions</span></div><div class="line">plt.plot(scaler.inverse_transform(dataset))</div><div class="line">plt.plot(trainPredictPlot)</div><div class="line">plt.plot(testPredictPlot)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>接下来我们将对上例代码进行详细讲解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> math</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</div></pre></td></tr></table></figure>
<p>函数库导入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(dataset, look_back=<span class="number">1</span>)</span>:</span></div><div class="line">	dataX, dataY = [], []</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)-look_back<span class="number">-1</span>):</div><div class="line">		a = dataset[i:(i+look_back), <span class="number">0</span>]</div><div class="line">		dataX.append(a)</div><div class="line">		dataY.append(dataset[i + look_back, <span class="number">0</span>])</div><div class="line">	<span class="keyword">return</span> numpy.array(dataX), numpy.array(dataY)</div></pre></td></tr></table></figure>
<p><code>create_dataset</code>用于生成不同类型的数据集。<code>dataset</code>为传入的原始数据集，<code>look_back</code>设定的是“步次”（timesteps）的大小。<br><strong>timesteps</strong> 是 LSTM 认为每个输入数据与前多少个陆续输入的数据有联系，是 LSTM 输入数据格式中需要指定的一项。例如具有这样用段序列数据“…A<strong>BCD</strong>B<strong>CED</strong>F…”，当 timesteps 为3时，在模型预测中如果输入数据为“D”，那么之前接收的数据如果为“B”和“C”则此时的预测输出为B的概率更大，之前接收的数据如果为“C”和“E”则此时的预测输出为F的概率更大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scaler = MinMaxScaler(feature_range=(<span class="number">0</span>, <span class="number">1</span>))</div><div class="line">dataset = scaler.fit_transform(dataset)</div></pre></td></tr></table></figure>
<p>数据标准化转换（0到1）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">train_size = int(len(dataset) * <span class="number">0.8</span>)</div><div class="line">test_size = len(dataset) - train_size</div><div class="line">train, test = dataset[<span class="number">0</span>:train_size,:], dataset[train_size:len(dataset),:]</div></pre></td></tr></table></figure>
<p>划分样本数据的80%作为训练数据集，20%作为测试数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">look_back = <span class="number">3</span></div><div class="line">trainX, trainY = create_dataset(train, look_back)</div><div class="line">testX, testY = create_dataset(test, look_back)</div><div class="line"><span class="comment"># reshape input to be [samples, time steps, features]</span></div><div class="line">trainX = numpy.reshape(trainX, (trainX.shape[<span class="number">0</span>], trainX.shape[<span class="number">1</span>], <span class="number">1</span>))</div><div class="line">testX = numpy.reshape(testX, (testX.shape[<span class="number">0</span>], testX.shape[<span class="number">1</span>], <span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>转换数据格式，timesteps 大小为3，准备输入给 LSTM 模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(LSTM(<span class="number">128</span>, input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>])))</div><div class="line">model.add(Dense(<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>本部分实现的是 LSTM 模型的具体构建：输入层包含1个输入神经元，隐含层包含128个隐含神经元，输出层包含1个输出神经元。<br><code>input_shape</code>是 LSTM 构建在模型第一层时必须提供的参数，用于指定输入数据的具体定义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">trainPredict = scaler.inverse_transform(trainPredict)</div><div class="line">trainY = scaler.inverse_transform([trainY])</div><div class="line">testPredict = scaler.inverse_transform(testPredict)</div><div class="line">testY = scaler.inverse_transform([testY])</div></pre></td></tr></table></figure>
<p>将训练、测试预测数据和训练、测试目标数据从标准化的形式（0到1）转换回原先的数据形式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">trainScore = math.sqrt(mean_squared_error(trainY[<span class="number">0</span>], trainPredict[:,<span class="number">0</span>]))</div><div class="line">print(<span class="string">'Train Score: %.2f RMSE'</span> % (trainScore))</div><div class="line">testScore = math.sqrt(mean_squared_error(testY[<span class="number">0</span>], testPredict[:,<span class="number">0</span>]))</div><div class="line">print(<span class="string">'Test Score: %.2f RMSE'</span> % (testScore))</div><div class="line"><span class="comment"># shift train predictions for plotting</span></div><div class="line">trainPredictPlot = numpy.empty_like(dataset)</div><div class="line">trainPredictPlot[:, :] = numpy.nan</div><div class="line">trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict</div><div class="line"><span class="comment"># shift test predictions for plotting</span></div><div class="line">testPredictPlot = numpy.empty_like(dataset)</div><div class="line">testPredictPlot[:, :] = numpy.nan</div><div class="line">testPredictPlot[len(trainPredict)+(look_back*<span class="number">2</span>)+<span class="number">1</span>:len(dataset)<span class="number">-1</span>, :] = testPredict</div><div class="line"><span class="comment"># plot baseline and predictions</span></div><div class="line">plt.plot(scaler.inverse_transform(dataset))</div><div class="line">plt.plot(trainPredictPlot)</div><div class="line">plt.plot(testPredictPlot)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>结果输出，绘图。<br>下面是本例的运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">Epoch <span class="number">98</span>/<span class="number">100</span></div><div class="line"><span class="number">1</span>s - loss: <span class="number">0.0660</span></div><div class="line">Epoch <span class="number">99</span>/<span class="number">100</span></div><div class="line"><span class="number">1</span>s - loss: <span class="number">0.0662</span></div><div class="line">Epoch <span class="number">100</span>/<span class="number">100</span></div><div class="line"><span class="number">1</span>s - loss: <span class="number">0.0649</span></div><div class="line">Train Score: <span class="number">241.16</span> RMSE</div><div class="line">Test Score: <span class="number">276.33</span> RMSE</div></pre></td></tr></table></figure>
<img src="/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/lstm-1.png" alt="lstm-1.png" title=""> 蓝色为实际数据，绿色为对训练数据的预测，红色为对新数据的预测。可以看到本例构建的简单模型对样本数据的预测结果相对大概有20%的误差，下面我们将看一下如何构建多层的 LSTM 模型来提高预测的准确性。<br><br># LSTM 多层结构模型<br>为提高 LSTM 模型性能，同样可搭建多 LSTM 层模型：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(LSTM(<span class="number">256</span>, input_shape=(trainX.shape[<span class="number">1</span>], trainX.shape[<span class="number">2</span>]), return_sequences=<span class="keyword">True</span>))</div><div class="line"><span class="comment"># model.add(Dropout(0.2))</span></div><div class="line">model.add(LSTM(<span class="number">128</span>))</div><div class="line"><span class="comment"># model.add(Dropout(0.2))</span></div><div class="line">model.add(Dense(<span class="number">1</span>))</div><div class="line">model.compile(loss=<span class="string">'mean_squared_error'</span>, optimizer=<span class="string">'adam'</span>)</div><div class="line">model.fit(trainX, trainY, nb_epoch=<span class="number">500</span>, batch_size=<span class="number">1</span>, verbose=<span class="number">2</span>)</div></pre></td></tr></table></figure>
<p>这里需要注意的是，当多层 LSTM 组合时，前面的 LSTM 层需要将<code>return_sequences</code>参数设置为<code>True</code>，以使输出的数据形式<code>(nb_samples, timesteps, output_dim)</code>可以被后面的 LSTM 层继续接收处理。<br>下面是本例的运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Epoch <span class="number">498</span>/<span class="number">500</span></div><div class="line"><span class="number">2</span>s - loss: <span class="number">0.0085</span></div><div class="line">Epoch <span class="number">499</span>/<span class="number">500</span></div><div class="line"><span class="number">2</span>s - loss: <span class="number">0.0082</span></div><div class="line">Epoch <span class="number">500</span>/<span class="number">500</span></div><div class="line"><span class="number">2</span>s - loss: <span class="number">0.0062</span></div><div class="line">Train Score: <span class="number">88.17</span> RMSE</div><div class="line">Test Score: <span class="number">71.52</span> RMSE</div></pre></td></tr></table></figure>
<p><img src="/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/lstm-2.png" alt="lstm-2.png" title=""> 经过扩展的 LSTM 模型明显降低了数据预测的错误率，希望您可以自己也尝试继续对模型进行优化，争取获得更高的预测准确度：）</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇想您介绍了 LSTM 模型的具体构建方法和使用，我们通过一个预测模拟网络服务 HTTP 请求的示例为您演示了如何使用 LSTM 对序列数据进行预测的过程。有兴趣的话，您可以根据本篇的扩展实现对序列数据进行预测的多方面应用，如网络服务的智能动态监控，股票价格预测等等。希望本篇对您在深度学习中关于 LSTM RNN 模型的构建和使用有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" target="_blank" rel="external">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a></li>
<li><a href="http://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/" target="_blank" rel="external">Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras</a></li>
<li><a href="http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/" target="_blank" rel="external">Text Generation With LSTM Recurrent Neural Networks in Python with Keras</a></li>
<li><a href="https://keras.io/layers/recurrent/" target="_blank" rel="external">Docs » Layers » Recurrent Layers</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/01/15/deeplearning/time-series-prediction-with-LSTM-RNN/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt; &lt;br&gt;循环神经网络（RNN）是当前广泛应用的深度学习神经网络类型之一，特点是对训练数据具有记忆特性，在处理序列数据预测问题上相对优势明显。本篇将结合示例介绍 LSTM RNN 模型的具体构建和使用。在通过阅读本篇内容您将了解到：&lt;br&gt;- LSTM 网络的构建与使用；&lt;br&gt;- 序列数据预测的具体实现方法；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Keras 模型的保存与加载</title>
    <link href="http://yoursite.com/2017/01/08/deeplearning/save-and-load-keras-deep-learning-model/"/>
    <id>http://yoursite.com/2017/01/08/deeplearning/save-and-load-keras-deep-learning-model/</id>
    <published>2017-01-08T13:30:13.000Z</published>
    <updated>2017-02-02T14:14:17.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/01/08/deeplearning/save-and-load-keras-deep-learning-model/0.jpg" alt="0.jpg" title=""> <br>本篇将简要介绍深度学习模型的保存和加载，在通过阅读本篇内容您将了解到：<br>- Keras 模型及权重的保存和加载方法；<br>- 常用的不同文件保存格式；<br><a id="more"></a>
<h1 id="模型及权重的保存与加载"><a href="#模型及权重的保存与加载" class="headerlink" title="模型及权重的保存与加载"></a>模型及权重的保存与加载</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># MLP for Pima Indians Dataset serialize to JSON and HDF5</span></div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> model_from_json</div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load pima indians dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">8</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># Compile model</span></div><div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X, Y, nb_epoch=<span class="number">150</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># evaluate the model</span></div><div class="line">scores = model.evaluate(X, Y, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"%s: %.2f%%"</span> % (model.metrics_names[<span class="number">1</span>], scores[<span class="number">1</span>]*<span class="number">100</span>))</div><div class="line"></div><div class="line"><span class="comment"># serialize model to JSON</span></div><div class="line">model_json = model.to_json()</div><div class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</div><div class="line">    json_file.write(model_json)</div><div class="line"><span class="comment"># serialize weights to HDF5</span></div><div class="line">model.save_weights(<span class="string">"model.h5"</span>)</div><div class="line">print(<span class="string">"Saved model to disk"</span>)</div><div class="line"></div><div class="line"><span class="comment"># later...</span></div><div class="line"></div><div class="line"><span class="comment"># load json and create model</span></div><div class="line">json_file = open(<span class="string">'model.json'</span>, <span class="string">'r'</span>)</div><div class="line">loaded_model_json = json_file.read()</div><div class="line">json_file.close()</div><div class="line">loaded_model = model_from_json(loaded_model_json)</div><div class="line"><span class="comment"># load weights into new model</span></div><div class="line">loaded_model.load_weights(<span class="string">"model.h5"</span>)</div><div class="line">print(<span class="string">"Loaded model from disk"</span>)</div><div class="line"></div><div class="line"><span class="comment"># evaluate loaded model on test data</span></div><div class="line">loaded_model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'rmsprop'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">score = loaded_model.evaluate(X, Y, verbose=<span class="number">0</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"%s: %.2f%%"</span> % (loaded_model.metrics_names[<span class="number">1</span>], score[<span class="number">1</span>]*<span class="number">100</span>)</div></pre></td></tr></table></figure>
<p>本示例训练解决的是一个二值分类问题，使用的数据集是     <a href="http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank" rel="external">Pima Indians onset of diabetes classification dataset</a>，您可以从<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data" target="_blank" rel="external">这里</a>进行下载，文件命名为“pima-indians-diabetes.csv”保存到与本示例代码相同的目录下即可。<br>下面我们将对代码中对模型及权重进行保存与加载的操作部分进行详细介绍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># serialize model to JSON</span></div><div class="line">model_json = model.to_json()</div><div class="line"><span class="keyword">with</span> open(<span class="string">"model.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> json_file:</div><div class="line">    json_file.write(model_json)</div><div class="line"><span class="comment"># serialize weights to HDF5</span></div><div class="line">model.save_weights(<span class="string">"model.h5"</span>)</div><div class="line">print(<span class="string">"Saved model to disk"</span>)</div></pre></td></tr></table></figure>
<p><code>to_json</code>方法用于将模型的结构描述序列化为 <a href="http://www.json.org/" target="_blank" rel="external">JSON</a> 格式。本例将转换后的 JSON 字符串保存为了本地文件<code>model.json</code>，文件内容如下：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"class_name"</span>: <span class="string">"Sequential"</span>,</div><div class="line">    <span class="attr">"keras_version"</span>: <span class="string">"1.2.0"</span>,</div><div class="line">    <span class="attr">"config"</span>: [&#123;</div><div class="line">        <span class="attr">"class_name"</span>: <span class="string">"Dense"</span>,</div><div class="line">        <span class="attr">"config"</span>: &#123;</div><div class="line">            <span class="attr">"W_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"b_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"name"</span>: <span class="string">"dense_1"</span>,</div><div class="line">            <span class="attr">"output_dim"</span>: <span class="number">12</span>,</div><div class="line">            <span class="attr">"activity_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"trainable"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"init"</span>: <span class="string">"uniform"</span>,</div><div class="line">            <span class="attr">"bias"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"input_dtype"</span>: <span class="string">"float32"</span>,</div><div class="line">            <span class="attr">"input_dim"</span>: <span class="number">8</span>,</div><div class="line">            <span class="attr">"b_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"W_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"activation"</span>: <span class="string">"relu"</span>,</div><div class="line">            <span class="attr">"batch_input_shape"</span>: [<span class="literal">null</span>, <span class="number">8</span>]</div><div class="line">        &#125;</div><div class="line">    &#125;, &#123;</div><div class="line">        <span class="attr">"class_name"</span>: <span class="string">"Dense"</span>,</div><div class="line">        <span class="attr">"config"</span>: &#123;</div><div class="line">            <span class="attr">"W_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"b_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"name"</span>: <span class="string">"dense_2"</span>,</div><div class="line">            <span class="attr">"activity_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"trainable"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"init"</span>: <span class="string">"uniform"</span>,</div><div class="line">            <span class="attr">"bias"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"input_dim"</span>: <span class="number">12</span>,</div><div class="line">            <span class="attr">"b_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"W_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"activation"</span>: <span class="string">"relu"</span>,</div><div class="line">            <span class="attr">"output_dim"</span>: <span class="number">8</span></div><div class="line">        &#125;</div><div class="line">    &#125;, &#123;</div><div class="line">        <span class="attr">"class_name"</span>: <span class="string">"Dense"</span>,</div><div class="line">        <span class="attr">"config"</span>: &#123;</div><div class="line">            <span class="attr">"W_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"b_constraint"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"name"</span>: <span class="string">"dense_3"</span>,</div><div class="line">            <span class="attr">"activity_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"trainable"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"init"</span>: <span class="string">"uniform"</span>,</div><div class="line">            <span class="attr">"bias"</span>: <span class="literal">true</span>,</div><div class="line">            <span class="attr">"input_dim"</span>: <span class="number">8</span>,</div><div class="line">            <span class="attr">"b_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"W_regularizer"</span>: <span class="literal">null</span>,</div><div class="line">            <span class="attr">"activation"</span>: <span class="string">"sigmoid"</span>,</div><div class="line">            <span class="attr">"output_dim"</span>: <span class="number">1</span></div><div class="line">        &#125;</div><div class="line">    &#125;]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><code>save_weights</code>方法用于将模型当前的权重信息保存为 <a href="http://www.h5py.org/" target="_blank" rel="external">HDF5</a> 格式文件，本例保存的权重文件为<code>model.h5</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">loaded_model = model_from_json(loaded_model_json)</div><div class="line"><span class="comment"># load weights into new model</span></div><div class="line">loaded_model.load_weights(<span class="string">"model.h5"</span>)</div><div class="line">print(<span class="string">"Loaded model from disk"</span>)</div></pre></td></tr></table></figure>
<p><code>model_from_json</code>用于从输入的 JSON 格式的模型描述创建了一个新的模型。<br><code>load_weights</code>方法用于从本地权重文件<code>model.h5</code>加载模型权重。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loaded_model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'rmsprop'</span>, metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure></p>
<p>从模型文件新创建的模型需要编译之后方可使用。<br>同样 Keras 也支持对模型描述的 <a href="http://yaml.org/" target="_blank" rel="external">YAML</a> 格式保存，方法为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.to_yaml()</div></pre></td></tr></table></figure></p>
<p>相对应的加载 YAML 模型的方法为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loaded_model = model_from_yaml(loaded_model_yaml)</div></pre></td></tr></table></figure></p>
<p>其它操作与上述示例基本形同。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过本篇学习您了解了 Keras 模型及权重的保存和加载方法，这在实际应用中会为您提供极大的便利性。<br>希望本篇能帮您近一步加强对 Keras 库的了解与使用。</p>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/01/08/deeplearning/save-and-load-keras-deep-learning-model/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将简要介绍深度学习模型的保存和加载，在通过阅读本篇内容您将了解到：&lt;br&gt;- Keras 模型及权重的保存和加载方法；&lt;br&gt;- 常用的不同文件保存格式；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习超参调优技巧</title>
    <link href="http://yoursite.com/2017/01/08/deeplearning/grid-search-hyperparameters-for-deep-learning/"/>
    <id>http://yoursite.com/2017/01/08/deeplearning/grid-search-hyperparameters-for-deep-learning/</id>
    <published>2017-01-08T12:01:03.000Z</published>
    <updated>2017-02-02T14:14:29.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/01/08/deeplearning/grid-search-hyperparameters-for-deep-learning/0.jpg" alt="0.jpg" title=""> <br>深度学习模型构建好之后，通常需要根据训练测试的结果对其进一步优化。本篇将主要介绍网络模型中大量参数设置调整优化（超参调优）的具体方法，及如何在超参调优中自动选出最好的模型配置。在通过阅读本篇内容您将了解到：<br>- 模型参数调优的具体方法；<br>- Keras 与 scikit-learn 库的结合使用方法；<br>- GridSearchCV 在超参调优中的具体用法；<br>- Hyperas 库介绍；<br><a id="more"></a>
<h1 id="训练周期数（epochs）和批大小（batch-size）调优"><a href="#训练周期数（epochs）和批大小（batch-size）调优" class="headerlink" title="训练周期数（epochs）和批大小（batch_size）调优"></a>训练周期数（epochs）和批大小（batch_size）调优</h1><p>我们首先讲解训练周期数（epochs）和批大小（batch_size）的调优过程，同时会介绍一些相关辅助库的使用。<br>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the batch size and epochs</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">batch_size = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">80</span>, <span class="number">100</span>]</div><div class="line">epochs = [<span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</div><div class="line">param_grid = dict(batch_size=batch_size, nb_epoch=epochs)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<p>本示例训练解决的是一个二值分类问题，使用的数据集是     <a href="http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" target="_blank" rel="external">Pima Indians onset of diabetes classification dataset</a>，您可以从<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data" target="_blank" rel="external">这里</a>进行下载，文件命名为“pima-indians-diabetes.csv”保存到与本示例代码相同的目录下即可。<br>下面我们将对代码中的参数调优部分进行详细介绍。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model = KerasClassifier(build_fn=create_model, verbose=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<p>KerasClassifier 是 Keras 中模型封装类的一种，常用的还有像 KerasRegressor 等，主要作用是对模型及参数进行封装，以供结合相关辅助库（本例中为 scikit-learn）共同完成计算任务。<br><code>build_fn</code> 参数值为定义好的模型构建函数，同时 KerasClassifier 中也可以设置用于模型训练（fit）的相关参数，如设置<code>nb_epoch</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">10</span>)</div></pre></td></tr></table></figure>
<p>也可以在 KerasClassifier 的参数列表中直接对<code>create_model</code>函数的入参进行赋值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(dropout_rate=<span class="number">0.0</span>)</span>:</span></div><div class="line">	...</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"></div><div class="line">model = KerasClassifier(build_fn=create_model, dropout_rate=<span class="number">0.2</span>)</div><div class="line">```	</div><div class="line">需要注意的是，两处使用的参数名（dropout_rate）要相同。</div><div class="line"></div><div class="line">```python </div><div class="line">batch_size = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">40</span>, <span class="number">60</span>, <span class="number">80</span>, <span class="number">100</span>]</div><div class="line">epochs = [<span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</div><div class="line">param_grid = dict(batch_size=batch_size, nb_epoch=epochs)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div></pre></td></tr></table></figure>
<p><code>batch_size</code>和<code>epochs</code>是我们本次进行调优的两个参数，以组成字典<code>param_grid</code>的形式传给 GridSearchCV，计算时两组值会相互组合进行实际评测。<br>GridSearchCV 是常用的超参调优类，由 scikit-learn 机器学习库提供，下面是参数介绍：</p>
<ul>
<li><code>estimator</code>：评测对象，本例传入的值为上文由 KerasClassifier 封装好的模型； </li>
<li><code>param_grid</code>：超参列表，参数值类型为字典（dict）或由字典组成的列表（list）。用于设置待评测参数和对应的参数值s；</li>
<li><code>n_jobs</code>：执行线程数，<code>-1</code>：多线程，<code>1</code>：单线程。当开启多线程运行时，根据 Keras 底层计算平台的不同可能会与网络模型的训练进程产生冲突。</li>
</ul>
<p>更多关于 GridSearchCV 的参数配置可以参考<a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" target="_blank" rel="external">这里</a>。<br><code>grid_result</code>是超参调优后的评测结果，<code>best_score_</code>保存的是最有参数组合<code>best_params_</code>所对应的评测分数（准确率）。<br>本例的运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">Best: <span class="number">0.699219</span> using &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">60</span>&#125;</div><div class="line"><span class="number">0.657552</span> (<span class="number">0.021236</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">10</span>&#125;</div><div class="line"><span class="number">0.669271</span> (<span class="number">0.017566</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">10</span>&#125;</div><div class="line"><span class="number">0.630208</span> (<span class="number">0.054997</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">10</span>&#125;</div><div class="line"><span class="number">0.506510</span> (<span class="number">0.136415</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">20</span>&#125;</div><div class="line"><span class="number">0.654948</span> (<span class="number">0.013279</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">20</span>&#125;</div><div class="line"><span class="number">0.661458</span> (<span class="number">0.027126</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">20</span>&#125;</div><div class="line"><span class="number">0.619792</span> (<span class="number">0.031948</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">40</span>&#125;</div><div class="line"><span class="number">0.651042</span> (<span class="number">0.018414</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">40</span>&#125;</div><div class="line"><span class="number">0.566406</span> (<span class="number">0.161752</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">40</span>&#125;</div><div class="line"><span class="number">0.453125</span> (<span class="number">0.050126</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">60</span>&#125;</div><div class="line"><span class="number">0.555990</span> (<span class="number">0.163918</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">60</span>&#125;</div><div class="line"><span class="number">0.699219</span> (<span class="number">0.019401</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">60</span>&#125;</div><div class="line"><span class="number">0.533854</span> (<span class="number">0.033502</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">80</span>&#125;</div><div class="line"><span class="number">0.622396</span> (<span class="number">0.035277</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">80</span>&#125;</div><div class="line"><span class="number">0.660156</span> (<span class="number">0.028348</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">80</span>&#125;</div><div class="line"><span class="number">0.578125</span> (<span class="number">0.052698</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">10</span>, <span class="string">'batch_size'</span>: <span class="number">100</span>&#125;</div><div class="line"><span class="number">0.641927</span> (<span class="number">0.036272</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">50</span>, <span class="string">'batch_size'</span>: <span class="number">100</span>&#125;</div><div class="line"><span class="number">0.669271</span> (<span class="number">0.027866</span>) <span class="keyword">with</span>: &#123;<span class="string">'nb_epoch'</span>: <span class="number">100</span>, <span class="string">'batch_size'</span>: <span class="number">100</span>&#125;</div></pre></td></tr></table></figure>
<p>可以看到，对本例提供的两组参数进行评测，最优的训练组合是{‘nb_epoch’: 100, ‘batch_size’: 60}，准确率为69.92%。<br>在本例中我们讲解了模型超参调优的主要方法和操作过程，同时对<code>nb_epoch</code>和<code>batch_size</code>进行了调优评测。接下来我们将列举一些其它主要参数的调优示例。</p>
<h1 id="优化器调优"><a href="#优化器调优" class="headerlink" title="优化器调优"></a>优化器调优</h1><p>本例将演示的是对模型优化器（optimizer）对调优，通过设置不同的优化算法来评测出最适合本例模型的优化器类型。<br>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the batch size and epochs</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(optimizer=<span class="string">'adam'</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=optimizer, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">optimizer = [<span class="string">'SGD'</span>, <span class="string">'RMSprop'</span>, <span class="string">'Adagrad'</span>, <span class="string">'Adadelta'</span>, <span class="string">'Adam'</span>, <span class="string">'Adamax'</span>, <span class="string">'Nadam'</span>]</div><div class="line">param_grid = dict(optimizer=optimizer)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<p>本例的运行结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Best: <span class="number">0.713542</span> using &#123;<span class="string">'optimizer'</span>: <span class="string">'Adamax'</span>&#125;</div><div class="line"><span class="number">0.455729</span> (<span class="number">0.146518</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'SGD'</span>&#125;</div><div class="line"><span class="number">0.669271</span> (<span class="number">0.004872</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'RMSprop'</span>&#125;</div><div class="line"><span class="number">0.625000</span> (<span class="number">0.026107</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'Adagrad'</span>&#125;</div><div class="line"><span class="number">0.645833</span> (<span class="number">0.084042</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'Adadelta'</span>&#125;</div><div class="line"><span class="number">0.675781</span> (<span class="number">0.022326</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'Adam'</span>&#125;</div><div class="line"><span class="number">0.713542</span> (<span class="number">0.030647</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'Adamax'</span>&#125;</div><div class="line"><span class="number">0.654948</span> (<span class="number">0.064133</span>) <span class="keyword">with</span>: &#123;<span class="string">'optimizer'</span>: <span class="string">'Nadam'</span>&#125;</div></pre></td></tr></table></figure>
<h1 id="SGD-学习比率（rate-和动量（momentum）参数调优"><a href="#SGD-学习比率（rate-和动量（momentum）参数调优" class="headerlink" title="SGD 学习比率（rate) 和动量（momentum）参数调优"></a>SGD 学习比率（rate) 和动量（momentum）参数调优</h1><p>当优化器算法为 <a href="https://keras.io/optimizers/#sgd" target="_blank" rel="external">Stochastic Gradient Descent，SGD</a> 时，本例演示的是对学习比率（rate) 和动量（momentum）两个参数的调优。<br>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the learning rate and momentum</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(learn_rate=<span class="number">0.01</span>, momentum=<span class="number">0</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	optimizer = SGD(lr=learn_rate, momentum=momentum)</div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=optimizer, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">learn_rate = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>]</div><div class="line">momentum = [<span class="number">0.0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</div><div class="line">param_grid = dict(learn_rate=learn_rate, momentum=momentum)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<h1 id="权重初始化类型调优"><a href="#权重初始化类型调优" class="headerlink" title="权重初始化类型调优"></a>权重初始化类型调优</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the weight initialization</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(init_mode=<span class="string">'uniform'</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, init=init_mode, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">1</span>, init=init_mode, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">init_mode = [<span class="string">'uniform'</span>, <span class="string">'lecun_uniform'</span>, <span class="string">'normal'</span>, <span class="string">'zero'</span>, <span class="string">'glorot_normal'</span>, <span class="string">'glorot_uniform'</span>, <span class="string">'he_normal'</span>, <span class="string">'he_uniform'</span>]</div><div class="line">param_grid = dict(init_mode=init_mode)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<h1 id="激活函数类型调优"><a href="#激活函数类型调优" class="headerlink" title="激活函数类型调优"></a>激活函数类型调优</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the activation function</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(activation=<span class="string">'relu'</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, init=<span class="string">'uniform'</span>, activation=activation))</div><div class="line">	model.add(Dense(<span class="number">1</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">activation = [<span class="string">'softmax'</span>, <span class="string">'softplus'</span>, <span class="string">'softsign'</span>, <span class="string">'relu'</span>, <span class="string">'tanh'</span>, <span class="string">'sigmoid'</span>, <span class="string">'hard_sigmoid'</span>, <span class="string">'linear'</span>]</div><div class="line">param_grid = dict(activation=activation)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<h1 id="抽稀层节点去除比例调优"><a href="#抽稀层节点去除比例调优" class="headerlink" title="抽稀层节点去除比例调优"></a>抽稀层节点去除比例调优</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the dropout rate</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="keyword">from</span> keras.constraints <span class="keyword">import</span> maxnorm</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(dropout_rate=<span class="number">0.0</span>, weight_constraint=<span class="number">0</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'linear'</span>, W_constraint=maxnorm(weight_constraint)))</div><div class="line">	model.add(Dropout(dropout_rate))</div><div class="line">	model.add(Dense(<span class="number">1</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">weight_constraint = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</div><div class="line">dropout_rate = [<span class="number">0.0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>]</div><div class="line">param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<h1 id="隐含层神经元数量调优"><a href="#隐含层神经元数量调优" class="headerlink" title="隐含层神经元数量调优"></a>隐含层神经元数量调优</h1><p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Use scikit-learn to grid search the number of neurons</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.wrappers.scikit_learn <span class="keyword">import</span> KerasClassifier</div><div class="line"><span class="keyword">from</span> keras.constraints <span class="keyword">import</span> maxnorm</div><div class="line"><span class="comment"># Function to create model, required for KerasClassifier</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">(neurons=<span class="number">1</span>)</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(neurons, input_dim=<span class="number">8</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'linear'</span>, W_constraint=maxnorm(<span class="number">4</span>)))</div><div class="line">	model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">	model.add(Dense(<span class="number">1</span>, init=<span class="string">'uniform'</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"><span class="comment"># load dataset</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line"><span class="comment"># split into input (X) and output (Y) variables</span></div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># create model</span></div><div class="line">model = KerasClassifier(build_fn=create_model, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>, verbose=<span class="number">0</span>)</div><div class="line"><span class="comment"># define the grid search parameters</span></div><div class="line">neurons = [<span class="number">1</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>, <span class="number">30</span>]</div><div class="line">param_grid = dict(neurons=neurons)</div><div class="line">grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=<span class="number">-1</span>)</div><div class="line">grid_result = grid.fit(X, Y)</div><div class="line"><span class="comment"># summarize results</span></div><div class="line">print(<span class="string">"Best: %f using %s"</span> % (grid_result.best_score_, grid_result.best_params_))</div><div class="line">means = grid_result.cv_results_[<span class="string">'mean_test_score'</span>]</div><div class="line">stds = grid_result.cv_results_[<span class="string">'std_test_score'</span>]</div><div class="line">params = grid_result.cv_results_[<span class="string">'params'</span>]</div><div class="line"><span class="keyword">for</span> mean, stdev, param <span class="keyword">in</span> zip(means, stds, params):</div><div class="line">    print(<span class="string">"%f (%f) with: %r"</span> % (mean, stdev, param))</div></pre></td></tr></table></figure>
<h1 id="Hyperas-介绍"><a href="#Hyperas-介绍" class="headerlink" title="Hyperas 介绍"></a>Hyperas 介绍</h1><p><a href="https://github.com/maxpumperla/hyperas" target="_blank" rel="external">Hyperas</a> 是用于 Keras 超参调优的 Python 库，基于对 <a href="https://github.com/hyperopt/hyperopt" target="_blank" rel="external">hyperopt</a> 库的封装简便易用。使用 Hyperas 进行超参调优时，只需要将模型中需要调试的参数以模版（“{{ 	}}”）的形式定义即可，结下来调优工作交给 Hyperas 就好了。<br>下面是引用官方的一个例子：</p>
<pre><code class="python">from __future__ import print_function
from hyperopt import Trials, STATUS_OK, tpe
from hyperas import optim
from hyperas.distributions import choice, uniform, conditional
from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation

def data():
    '''
    Data providing function:

    This function is separated from model() so that hyperopt
    won't reload data for each evaluation run.
    '''
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    X_train = X_train.reshape(60000, 784)
    X_test = X_test.reshape(10000, 784)
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255
    nb_classes = 10
    Y_train = np_utils.to_categorical(y_train, nb_classes)
    Y_test = np_utils.to_categorical(y_test, nb_classes)
    return X_train, Y_train, X_test, Y_test


def model(X_train, Y_train, X_test, Y_test):
    '''
    Model providing function:

    Create Keras model with double curly brackets dropped-in as needed.
    Return value has to be a valid python dictionary with two customary keys:
        - loss: Specify a numeric evaluation metric to be minimized
        - status: Just use STATUS_OK and see hyperopt documentation if not feasible
    The last one is optional, though recommended, namely:
        - model: specify the model just created so that we can later use it again.
    '''
    model = Sequential()
    model.add(Dense(512, input_shape=(784,)))
    model.add(Activation('relu'))
    model.add(Dropout({{uniform(0, 1)}}))
    model.add(Dense({{choice([256, 512, 1024])}}))
    model.add(Activation({{choice(['relu', 'sigmoid'])}}))
    model.add(Dropout({{uniform(0, 1)}}))

    # If we choose 'four', add an additional fourth layer
    if conditional({{choice(['three', 'four'])}}) == 'four':
        model.add(Dense(100))
        # We can also choose between complete sets of layers
        model.add({{choice([Dropout(0.5), Activation('linear')])}})
        model.add(Activation('relu'))

    model.add(Dense(10))
    model.add(Activation('softmax'))

    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],
                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})

    model.fit(X_train, Y_train,
              batch_size={{choice([64, 128])}},
              nb_epoch=1,
              show_accuracy=True,
              verbose=2,
              validation_data=(X_test, Y_test))
    score, acc = model.evaluate(X_test, Y_test, verbose=0)
    print('Test accuracy:', acc)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model}

if __name__ == '__main__':
    best_run, best_model = optim.minimize(model=model,
                                          data=data,
                                          algo=tpe.suggest,
                                          max_evals=5,
                                          trials=Trials())
    X_train, Y_train, X_test, Y_test = data()
    print("Evalutation of best performing model:")
    print(best_model.evaluate(X_test, Y_test))
</code></pre>
<h1 id="超参调优的几点建议"><a href="#超参调优的几点建议" class="headerlink" title="超参调优的几点建议"></a>超参调优的几点建议</h1><p>超参调优的耗时一般都比较长，特别是训练数据集较大的情况下。为有效地提高调参效率以下这些建议指导可以作为您的参考：</p>
<ul>
<li>全局考虑；</li>
<li>尽可能开启并行计算（n_jobs=-1）；</li>
<li>样本由小到大：先对一小部分数据样本进行超参调优，以便快速确定整体的调优方向，再逐渐扩大样本进行细化；</li>
<li>参值由粗到细：调优参数值s先以较粗的颗粒度进行划分，当确定大的最优范围之后再逐渐细化调整；</li>
<li>具体模型具体调参，尽可能不复用之前模型的调优结果；</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过阅读本篇内容，您了解了深度学习网络模型常见参数对调优方法。之后我们介绍了几点提高超参调优效率的常用策略。<br>希望本篇对您在深度学习中关于超参调优的了解和具体操作有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" target="_blank" rel="external">How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras</a></li>
<li><a href="https://keras.io/scikit-learn-api/" target="_blank" rel="external">Wrappers for the Scikit-Learn API</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" target="_blank" rel="external">sklearn.grid_search.GridSearchCV</a></li>
<li><a href="http://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network" target="_blank" rel="external">What is batch size in neural network?</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/01/08/deeplearning/grid-search-hyperparameters-for-deep-learning/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt; &lt;br&gt;深度学习模型构建好之后，通常需要根据训练测试的结果对其进一步优化。本篇将主要介绍网络模型中大量参数设置调整优化（超参调优）的具体方法，及如何在超参调优中自动选出最好的模型配置。在通过阅读本篇内容您将了解到：&lt;br&gt;- 模型参数调优的具体方法；&lt;br&gt;- Keras 与 scikit-learn 库的结合使用方法；&lt;br&gt;- GridSearchCV 在超参调优中的具体用法；&lt;br&gt;- Hyperas 库介绍；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>CNN 实现基于 MNIST 数据集的手写识别</title>
    <link href="http://yoursite.com/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/"/>
    <id>http://yoursite.com/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/</id>
    <published>2017-01-01T13:31:45.000Z</published>
    <updated>2017-02-02T14:11:42.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/0.jpg" alt="0.jpg" title=""> <br>手写数字识别是机器学习最早实现商业应用的领域之一，本篇将讲解用 CNN 进行手写数字识别的具体方法，通过阅读本篇内容您将了解到：<br>- MNIST 数据的载入与使用；<br>- MLP 对 MNIST 进行识别的具体方法；<br>- CNN 网络的构法与基于 MNIST 进行手写识别的具体方法；<br>- 如何对 CNN 网络进行优化加强；<br><a id="more"></a>
<h1 id="数据集-MNIST-简介"><a href="#数据集-MNIST-简介" class="headerlink" title="数据集 MNIST 简介"></a>数据集 MNIST 简介</h1><p><a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">MNIST</a> 数据集是由 Yann LeCun 等前辈创建的数据集，是常用的用于机器学习手写数字识别的训练数据集。数据集中的手写数字图片来源于扫描文档（由 <a href="https://www.nist.gov/" target="_blank" rel="external">National Institute of Standards and Technology，NIST</a> 提供），后经过标准化修改处理而用于机器训练学习。其中训练集数据有60,000张图片，测试集数据有10,0000张图片。每张图片的大小为28x28，共784像素。一般通过深度学网络训练，识别结果的错误率可以降到1%左右，如果是通过大规模的深度网络训练，错误率已经可以降到0.21%<a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354" target="_blank" rel="external">（2013）</a>。<br>接下来我们将详细介绍如何用 Keras 构建您自己的 CNN 模型来实现手写数字识别。 </p>
<h1 id="MNIST-数据载入"><a href="#MNIST-数据载入" class="headerlink" title="MNIST 数据载入"></a>MNIST 数据载入</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="comment"># load (downloaded if needed) the MNIST dataset</span></div><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div></pre></td></tr></table></figure>
<p>Keras 库中内置了对 MNIST 数据集的加载方法<code>load_data()</code>，操作起来非常方便。如果未下载过该数据集，则会先自动下载，下载后的数据存储路径为：<code>~/.keras/datasets/mnist.pkl.gz</code>。<br>我们可通过下面的方法从已加载的训练数据集中打印出前4张图片：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="comment"># plot 4 images as gray scale</span></div><div class="line">plt.subplot(<span class="number">221</span>)</div><div class="line">plt.imshow(X_train[<span class="number">0</span>], cmap=plt.get_cmap(<span class="string">'gray'</span>))</div><div class="line">plt.subplot(<span class="number">222</span>)</div><div class="line">plt.imshow(X_train[<span class="number">1</span>], cmap=plt.get_cmap(<span class="string">'gray'</span>))</div><div class="line">plt.subplot(<span class="number">223</span>)</div><div class="line">plt.imshow(X_train[<span class="number">2</span>], cmap=plt.get_cmap(<span class="string">'gray'</span>))</div><div class="line">plt.subplot(<span class="number">224</span>)</div><div class="line">plt.imshow(X_train[<span class="number">3</span>], cmap=plt.get_cmap(<span class="string">'gray'</span>))</div><div class="line"><span class="comment"># show the plot</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>效果如下：<br><img src="/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/mnist-img.png" alt="mnist-img.png" title=""></p>
<h1 id="MLP-手写识别"><a href="#MLP-手写识别" class="headerlink" title="MLP 手写识别"></a>MLP 手写识别</h1><p>这里我们先采用最简单的多层感知神经网络（MLP）来完成手写识别，实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># MLP Demo for MNIST Recognition</span></div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"></div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"></div><div class="line"><span class="comment"># load data</span></div><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div><div class="line"></div><div class="line"><span class="comment"># flatten 28*28 images to a 784 vector for each image</span></div><div class="line">num_pixels = X_train.shape[<span class="number">1</span>] * X_train.shape[<span class="number">2</span>]</div><div class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], num_pixels).astype(<span class="string">'float32'</span>)</div><div class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], num_pixels).astype(<span class="string">'float32'</span>)</div><div class="line"></div><div class="line"><span class="comment"># normalize inputs from 0-255 to 0-1</span></div><div class="line">X_train = X_train / <span class="number">255</span></div><div class="line">X_test = X_test / <span class="number">255</span></div><div class="line"></div><div class="line"><span class="comment"># one hot encode outputs</span></div><div class="line">y_train = np_utils.to_categorical(y_train)</div><div class="line">y_test = np_utils.to_categorical(y_test)</div><div class="line">num_classes = y_test.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="comment"># define baseline model</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">baseline_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(num_pixels, input_dim=num_pixels, init=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(num_classes, init=<span class="string">'normal'</span>, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"></div><div class="line"><span class="comment"># build the model</span></div><div class="line">model = baseline_model()</div><div class="line"></div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">10</span>, batch_size=<span class="number">200</span>, verbose=<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment"># Final evaluation of the model</span></div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"MLP Error: %.2f%%"</span> % (<span class="number">100</span>-scores[<span class="number">1</span>]*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>接下来我们将对上面的代码进行逐步讲解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div></pre></td></tr></table></figure>
<p>倒入本例所要用到的具体 Python 库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div></pre></td></tr></table></figure>
<p>初始化 NumPy 随机数生成器，以使本例的运行结果可重复。更多关于 NumPy 随机数生成器初始化的作用和原理可以参考<a href="http://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div></pre></td></tr></table></figure>
<p>载入 MNIST 训练集合测试集数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">num_pixels = X_train.shape[<span class="number">1</span>] * X_train.shape[<span class="number">2</span>] <span class="comment"># 784, X_train.shape: (60000, 28, 28)</span></div><div class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], num_pixels).astype(<span class="string">'float32'</span>)</div><div class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], num_pixels).astype(<span class="string">'float32'</span>)</div></pre></td></tr></table></figure>
<p>因为我们的 MLP 输入层接收的数据是一维向量形式，所以我们需要将<code>X_train</code>中保存的图片数据由二维矩阵结构转换为一维向量。同时将元素的数据类型转换为<code>float32</code>型，减少内存占用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">X_train = X_train / <span class="number">255</span></div><div class="line">X_test = X_test / <span class="number">255</span></div></pre></td></tr></table></figure>
<p>这里我们做的主要是对训练数据的标准化处理，将原先的灰度像素值（0到255之间）转换为0到1之间的值。预先对训练数据做标准化处理是神经网络训练比较常用的优化方法，更有利于提高训练效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">y_train = np_utils.to_categorical(y_train) <span class="comment"># "5" in one hot format is: [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]</span></div><div class="line">y_test = np_utils.to_categorical(y_test)</div><div class="line">num_classes = y_test.shape[<span class="number">1</span>] <span class="comment"># 10</span></div></pre></td></tr></table></figure>
<p>我们这里处理是一个分类问题，对手写识别结果属于0到9中哪个数字进行判断分类。在分类问题的神经网络训练中，一般我们会先将目标输出的数据格式转换为<a href="https://en.wikipedia.org/wiki/One-hot" target="_blank" rel="external">“One-hot”</a>表示形式，也是对训练数据做标准化处理的一种方式。<code>np_utils</code>库为我们提供了有效的转换方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">baseline_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Dense(num_pixels, input_dim=num_pixels, init=<span class="string">'normal'</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(num_classes, init=<span class="string">'normal'</span>, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div></pre></td></tr></table></figure>
<p>我们将 MLP 模型的构建封装成了<code>baseline_model()</code>函数。MLP 的接收输入节点数量<code>input_dim</code>为784个，隐含层具有的神经元个数也为784个，权重初始化<code>init</code>方法为<code>normal</code>，激活函数<code>activation</code>的类型为<code>relu</code>。输出层具有10个神经元，权重初始化方法为<code>normal</code>，激活函数的类型为<code>softmax</code>。我们选择的损失函数<code>loss</code>类型为<code>categorical_crossentropy</code>，即 Logarithmic 损失函数，优化方式类型选用的是<code>adam</code>，即 ADAM 梯度下降算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">model = baseline_model()</div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">10</span>, batch_size=<span class="number">200</span>, verbose=<span class="number">2</span>)</div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"MLP Error: %.2f%%"</span> % (<span class="number">100</span>-scores[<span class="number">1</span>]*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>模型构建好之后，我们就可以对 MLP 进行训练了<code>fit</code>，在训练中我们设定的训练周期<code>nb_epoch</code>为10，每处理200<code>batch_size</code>个图片数据后进行一次网络权重更新。<code>verbose</code> 设置为2则指定在每个训练周期完成后只输出一条日志。<br>对训练后的模型进行评估时，我们使用的是测试集数据，以便更好的来验证 MLP 模型的性能。<br>下面是本模型的训练结果日志：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Train on <span class="number">60000</span> samples, validate on <span class="number">10000</span> samples</div><div class="line">Epoch <span class="number">1</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.2832</span> - acc: <span class="number">0.9188</span> - val_loss: <span class="number">0.1397</span> - val_acc: <span class="number">0.9588</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">10</span></div><div class="line"><span class="number">8</span>s - loss: <span class="number">0.1125</span> - acc: <span class="number">0.9671</span> - val_loss: <span class="number">0.0931</span> - val_acc: <span class="number">0.9721</span></div><div class="line">Epoch <span class="number">3</span>/<span class="number">10</span></div><div class="line"><span class="number">8</span>s - loss: <span class="number">0.0727</span> - acc: <span class="number">0.9791</span> - val_loss: <span class="number">0.0789</span> - val_acc: <span class="number">0.9764</span></div><div class="line">Epoch <span class="number">4</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.0512</span> - acc: <span class="number">0.9853</span> - val_loss: <span class="number">0.0739</span> - val_acc: <span class="number">0.9779</span></div><div class="line">Epoch <span class="number">5</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.0377</span> - acc: <span class="number">0.9894</span> - val_loss: <span class="number">0.0684</span> - val_acc: <span class="number">0.9786</span></div><div class="line">Epoch <span class="number">6</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.0270</span> - acc: <span class="number">0.9928</span> - val_loss: <span class="number">0.0655</span> - val_acc: <span class="number">0.9804</span></div><div class="line">Epoch <span class="number">7</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.0209</span> - acc: <span class="number">0.9946</span> - val_loss: <span class="number">0.0584</span> - val_acc: <span class="number">0.9817</span></div><div class="line">Epoch <span class="number">8</span>/<span class="number">10</span></div><div class="line"><span class="number">10</span>s - loss: <span class="number">0.0136</span> - acc: <span class="number">0.9972</span> - val_loss: <span class="number">0.0595</span> - val_acc: <span class="number">0.9812</span></div><div class="line">Epoch <span class="number">9</span>/<span class="number">10</span></div><div class="line"><span class="number">10</span>s - loss: <span class="number">0.0110</span> - acc: <span class="number">0.9977</span> - val_loss: <span class="number">0.0544</span> - val_acc: <span class="number">0.9817</span></div><div class="line">Epoch <span class="number">10</span>/<span class="number">10</span></div><div class="line"><span class="number">9</span>s - loss: <span class="number">0.0081</span> - acc: <span class="number">0.9986</span> - val_loss: <span class="number">0.0575</span> - val_acc: <span class="number">0.9825</span></div><div class="line">MLP Error: <span class="number">1.75</span>%</div></pre></td></tr></table></figure></p>
<p>根据运行环境不同计算时间会有所差异。从结果来看我们刚刚构建训练的这个 MLP 在 MNIST 测试集的手写识别上错误率为1.75%，觉得怎么样，内心无比喜悦是吗：）<br>接下来让我们看看本篇主角 CNN 的表现如何。</p>
<h1 id="CNN-手写识别"><a href="#CNN-手写识别" class="headerlink" title="CNN 手写识别"></a>CNN 手写识别</h1><p>刚刚我们使用 MLP 实现了 MNIST 的手写识别，这里我们将介绍的一下使用 CNN 实现的具体方法，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line">K.set_image_dim_ordering(<span class="string">'th'</span>)</div><div class="line"></div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"></div><div class="line"><span class="comment"># load data</span></div><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div><div class="line"><span class="comment"># reshape to be [samples][pixels][width][height]</span></div><div class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div><div class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div><div class="line"></div><div class="line"><span class="comment"># normalize inputs from 0-255 to 0-1</span></div><div class="line">X_train = X_train / <span class="number">255</span></div><div class="line">X_test = X_test / <span class="number">255</span></div><div class="line"><span class="comment"># one hot encode outputs</span></div><div class="line">y_train = np_utils.to_categorical(y_train)</div><div class="line">y_test = np_utils.to_categorical(y_test)</div><div class="line">num_classes = y_test.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">baseline_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Convolution2D(<span class="number">32</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">'valid'</span>, input_shape=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div><div class="line">	model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">	model.add(Flatten())</div><div class="line">	model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"></div><div class="line"><span class="comment"># build the model</span></div><div class="line">model = baseline_model()</div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">10</span>, batch_size=<span class="number">200</span>, verbose=<span class="number">2</span>)</div><div class="line"><span class="comment"># Final evaluation of the model</span></div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"CNN Error: %.2f%%"</span> % (<span class="number">100</span>-scores[<span class="number">1</span>]*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>接下来我们将对上面的代码进行逐步讲解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div></pre></td></tr></table></figure>
<p>倒入本例所要用到的具体 Python 库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div></pre></td></tr></table></figure>
<p>初始化 NumPy 随机数生成器，同上例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div><div class="line"><span class="comment"># reshape to be [samples][channels][rows][cols]</span></div><div class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div><div class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div></pre></td></tr></table></figure>
<p>同样在 MNIST 数据传入 CNN 模型前，我们需要先将数据的格式转换为相应要求的格式。本例将使用的 CNN 卷积层的类型是 Convolution2D，其对输入数据的格式规定如下：</p>
<ul>
<li>图片维序类型为 th 时（<code>dim_ordering=&#39;th&#39;</code>）： 输入数据格式为[samples][channels][rows][cols]；</li>
<li>图片维序类型为 tf 时（<code>dim_ordering=&#39;tf&#39;</code>）： 输入数据格式为[samples][rows][cols][channels]；</li>
</ul>
<p><code>dim_ordering</code> 参数值可以在添加 Convolution2D 层时设置，也可以由一下方式进行全局统一设置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">K.set_image_dim_ordering(<span class="string">'th'</span>)</div></pre></td></tr></table></figure></p>
<p><code>channels</code>代表图片的 RGB 通道，彩色图片为3，灰度图片为1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">X_train = X_train / <span class="number">255</span></div><div class="line">X_test = X_test / <span class="number">255</span></div><div class="line">y_train = np_utils.to_categorical(y_train)</div><div class="line">y_test = np_utils.to_categorical(y_test)</div><div class="line">num_classes = y_test.shape[<span class="number">1</span>]</div></pre></td></tr></table></figure>
<p>同上例一样，这里我们同样对输出数据做标准化处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">baseline_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Convolution2D(<span class="number">32</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">'valid'</span>, input_shape=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div><div class="line">	model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">	model.add(Flatten())</div><div class="line">	model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div></pre></td></tr></table></figure>
<p>在 CNN 模型的定义上，我们依然采用函数封装的形式，添加各层的含义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(Convolution2D(<span class="number">32</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">'valid'</span>, input_shape=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), activation=<span class="string">'relu'</span>))</div></pre></td></tr></table></figure>
<p>添加卷积层 Convolution2D：</p>
<ul>
<li><code>Convolution2D</code>：2D 卷积层;</li>
<li><code>32</code>：过滤器（filter）个数；</li>
<li><code>5, 5</code>：过滤器的行列数（row, col）；</li>
<li><code>border_mode</code>：过滤器在采集图片边缘特征是所使用的模式。<code>valid</code>：不使用0填充（Zero-padding）；<code>same</code>：使用0填充，填充大小为（过滤器大小／2）；<code>full</code>：使用0填充，填充大小为（过滤器大小 - 1）, 仅底层平台为 Theano 时支持；</li>
<li><code>input_shape</code>：输入数据维度，当添加的 Convolution2D 处在第一层时，则需要指定该参数；</li>
<li><code>activation</code>：激活函数类型；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div></pre></td></tr></table></figure>
<p>添加汇集层 MaxPooling2D，汇集方法为取最大，汇集窗口大小为2x2.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(Dropout(<span class="number">0.2</span>))</div></pre></td></tr></table></figure>
<p>添加抽稀层，节点被随机踢出的概率为<code>0.2</code>，主要作用是抑制整个网络的过拟合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(Flatten())</div></pre></td></tr></table></figure>
<p>添加“平化”层，将二维矩阵数据格式转换为一维向量格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div></pre></td></tr></table></figure>
<p>全连接神经网络添加，主要作用是对之前整套卷积结构层s输出的特征进行分类，原理同上例。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure></p>
<p>模型训练，同上例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">model = baseline_model()</div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">10</span>, batch_size=<span class="number">200</span>, verbose=<span class="number">2</span>)</div><div class="line"><span class="comment"># Final evaluation of the model</span></div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"CNN Error: %.2f%%"</span> % (<span class="number">100</span>-scores[<span class="number">1</span>]*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>模型训练及评估，同上例。<br>下面是本模型的训练结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Train on <span class="number">60000</span> samples, validate on <span class="number">10000</span> samples</div><div class="line">Epoch <span class="number">1</span>/<span class="number">10</span></div><div class="line"><span class="number">192</span>s - loss: <span class="number">0.2517</span> - acc: <span class="number">0.9282</span> - val_loss: <span class="number">0.0855</span> - val_acc: <span class="number">0.9753</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">10</span></div><div class="line"><span class="number">204</span>s - loss: <span class="number">0.0767</span> - acc: <span class="number">0.9770</span> - val_loss: <span class="number">0.0589</span> - val_acc: <span class="number">0.9802</span></div><div class="line">Epoch <span class="number">3</span>/<span class="number">10</span></div><div class="line"><span class="number">188</span>s - loss: <span class="number">0.0547</span> - acc: <span class="number">0.9833</span> - val_loss: <span class="number">0.0459</span> - val_acc: <span class="number">0.9857</span></div><div class="line">Epoch <span class="number">4</span>/<span class="number">10</span></div><div class="line"><span class="number">185</span>s - loss: <span class="number">0.0419</span> - acc: <span class="number">0.9873</span> - val_loss: <span class="number">0.0363</span> - val_acc: <span class="number">0.9883</span></div><div class="line">Epoch <span class="number">5</span>/<span class="number">10</span></div><div class="line"><span class="number">190</span>s - loss: <span class="number">0.0341</span> - acc: <span class="number">0.9897</span> - val_loss: <span class="number">0.0389</span> - val_acc: <span class="number">0.9878</span></div><div class="line">Epoch <span class="number">6</span>/<span class="number">10</span></div><div class="line"><span class="number">185</span>s - loss: <span class="number">0.0283</span> - acc: <span class="number">0.9909</span> - val_loss: <span class="number">0.0314</span> - val_acc: <span class="number">0.9903</span></div><div class="line">Epoch <span class="number">7</span>/<span class="number">10</span></div><div class="line"><span class="number">190</span>s - loss: <span class="number">0.0234</span> - acc: <span class="number">0.9926</span> - val_loss: <span class="number">0.0324</span> - val_acc: <span class="number">0.9892</span></div><div class="line">Epoch <span class="number">8</span>/<span class="number">10</span></div><div class="line"><span class="number">183</span>s - loss: <span class="number">0.0189</span> - acc: <span class="number">0.9940</span> - val_loss: <span class="number">0.0322</span> - val_acc: <span class="number">0.9905</span></div><div class="line">Epoch <span class="number">9</span>/<span class="number">10</span></div><div class="line"><span class="number">187</span>s - loss: <span class="number">0.0168</span> - acc: <span class="number">0.9945</span> - val_loss: <span class="number">0.0345</span> - val_acc: <span class="number">0.9890</span></div><div class="line">Epoch <span class="number">10</span>/<span class="number">10</span></div><div class="line"><span class="number">198</span>s - loss: <span class="number">0.0143</span> - acc: <span class="number">0.9955</span> - val_loss: <span class="number">0.0310</span> - val_acc: <span class="number">0.9902</span></div><div class="line">CNN Error: <span class="number">0.98</span>%</div></pre></td></tr></table></figure>
<p>训练用时相比上例要长一些，同时我们看到本例的测试识别错误率只有0.98%，相比上例方法的错误率（1.75%）具有明显的优势。<br>激动吗，好戏还在后面：）</p>
<h1 id="加强版-CNN-手写识别"><a href="#加强版-CNN-手写识别" class="headerlink" title="加强版 CNN 手写识别"></a>加强版 CNN 手写识别</h1><p>先上代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</div><div class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D</div><div class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</div><div class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</div><div class="line">K.set_image_dim_ordering(<span class="string">'th'</span>)</div><div class="line"></div><div class="line"><span class="comment"># fix random seed for reproducibility</span></div><div class="line">seed = <span class="number">7</span></div><div class="line">numpy.random.seed(seed)</div><div class="line"></div><div class="line"><span class="comment"># load data</span></div><div class="line">(X_train, y_train), (X_test, y_test) = mnist.load_data()</div><div class="line"><span class="comment"># reshape to be [samples][pixels][width][height]</span></div><div class="line">X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div><div class="line">X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).astype(<span class="string">'float32'</span>)</div><div class="line"></div><div class="line"><span class="comment"># normalize inputs from 0-255 to 0-1</span></div><div class="line">X_train = X_train / <span class="number">255</span></div><div class="line">X_test = X_test / <span class="number">255</span></div><div class="line"><span class="comment"># one hot encode outputs</span></div><div class="line">y_train = np_utils.to_categorical(y_train)</div><div class="line">y_test = np_utils.to_categorical(y_test)</div><div class="line">num_classes = y_test.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">larger_model</span><span class="params">()</span>:</span></div><div class="line">	<span class="comment"># create model</span></div><div class="line">	model = Sequential()</div><div class="line">	model.add(Convolution2D(<span class="number">30</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">'valid'</span>, input_shape=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div><div class="line">	model.add(Convolution2D(<span class="number">15</span>, <span class="number">3</span>, <span class="number">3</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div><div class="line">	model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">	model.add(Flatten())</div><div class="line">	model.add(Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(<span class="number">50</span>, activation=<span class="string">'relu'</span>))</div><div class="line">	model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</div><div class="line">	<span class="comment"># Compile model</span></div><div class="line">	model.compile(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line">	<span class="keyword">return</span> model</div><div class="line"></div><div class="line"><span class="comment"># build the model</span></div><div class="line">model = larger_model()</div><div class="line"><span class="comment"># Fit the model</span></div><div class="line">model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=<span class="number">10</span>, batch_size=<span class="number">200</span>, verbose=<span class="number">2</span>)</div><div class="line"><span class="comment"># Final evaluation of the model</span></div><div class="line">scores = model.evaluate(X_test, y_test, verbose=<span class="number">0</span>)</div><div class="line">print(<span class="string">"Larger CNN Error: %.2f%%"</span> % (<span class="number">100</span>-scores[<span class="number">1</span>]*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>在上例的基础上，我们这次在 CNN 模型中对卷积结构部分增添了 Convolution2D 层和 MaxPooling2D 层：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">model.add(Convolution2D(<span class="number">15</span>, <span class="number">3</span>, <span class="number">3</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</div></pre></td></tr></table></figure></p>
<p>在全连接神经网络结构中增添了一个隐含层：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.add(Dense(<span class="number">50</span>, activation=<span class="string">'relu'</span>))</div></pre></td></tr></table></figure></p>
<p>增添层s的类型我们上文已经进行了讲解，这里不在重复介绍。<br>下面是本加强版模型的训练结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">Train on <span class="number">60000</span> samples, validate on <span class="number">10000</span> samples</div><div class="line">Epoch <span class="number">1</span>/<span class="number">10</span></div><div class="line"><span class="number">209</span>s - loss: <span class="number">0.3894</span> - acc: <span class="number">0.8781</span> - val_loss: <span class="number">0.0813</span> - val_acc: <span class="number">0.9744</span></div><div class="line">Epoch <span class="number">2</span>/<span class="number">10</span></div><div class="line"><span class="number">193</span>s - loss: <span class="number">0.1012</span> - acc: <span class="number">0.9693</span> - val_loss: <span class="number">0.0516</span> - val_acc: <span class="number">0.9822</span></div><div class="line">Epoch <span class="number">3</span>/<span class="number">10</span></div><div class="line"><span class="number">200</span>s - loss: <span class="number">0.0754</span> - acc: <span class="number">0.9767</span> - val_loss: <span class="number">0.0441</span> - val_acc: <span class="number">0.9854</span></div><div class="line">Epoch <span class="number">4</span>/<span class="number">10</span></div><div class="line"><span class="number">202</span>s - loss: <span class="number">0.0620</span> - acc: <span class="number">0.9805</span> - val_loss: <span class="number">0.0370</span> - val_acc: <span class="number">0.9875</span></div><div class="line">Epoch <span class="number">5</span>/<span class="number">10</span></div><div class="line"><span class="number">204</span>s - loss: <span class="number">0.0522</span> - acc: <span class="number">0.9838</span> - val_loss: <span class="number">0.0327</span> - val_acc: <span class="number">0.9890</span></div><div class="line">Epoch <span class="number">6</span>/<span class="number">10</span></div><div class="line"><span class="number">194</span>s - loss: <span class="number">0.0463</span> - acc: <span class="number">0.9861</span> - val_loss: <span class="number">0.0310</span> - val_acc: <span class="number">0.9902</span></div><div class="line">Epoch <span class="number">7</span>/<span class="number">10</span></div><div class="line"><span class="number">200</span>s - loss: <span class="number">0.0416</span> - acc: <span class="number">0.9872</span> - val_loss: <span class="number">0.0314</span> - val_acc: <span class="number">0.9898</span></div><div class="line">Epoch <span class="number">8</span>/<span class="number">10</span></div><div class="line"><span class="number">193</span>s - loss: <span class="number">0.0390</span> - acc: <span class="number">0.9877</span> - val_loss: <span class="number">0.0282</span> - val_acc: <span class="number">0.9909</span></div><div class="line">Epoch <span class="number">9</span>/<span class="number">10</span></div><div class="line"><span class="number">197</span>s - loss: <span class="number">0.0350</span> - acc: <span class="number">0.9889</span> - val_loss: <span class="number">0.0285</span> - val_acc: <span class="number">0.9910</span></div><div class="line">Epoch <span class="number">10</span>/<span class="number">10</span></div><div class="line"><span class="number">198</span>s - loss: <span class="number">0.0318</span> - acc: <span class="number">0.9900</span> - val_loss: <span class="number">0.0308</span> - val_acc: <span class="number">0.9906</span></div><div class="line">Larger CNN Error: <span class="number">0.94</span>%</div></pre></td></tr></table></figure></p>
<p>可以看到相比之前模型的识别错误率（0.98%）这次降低到了0.94%，说明本次对网络结构的加强还是有一定的效果的：）<br>需要说明的是，在实际 CNN 应用中对网络结构的优化是必不可少的，同时卷积结构的构成也是多种多样的，如添加多个 Convolution2D 层之后再添加 MaxPooling2D 层等，目的都是为了取得一个理想的训练效果。您也不妨自己尝试优化一下本例的模型结构，看看能否取得一个更好的测试结果。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过学习本篇内容，您对基于 MNIST 的 CNN 手写数字识别的模型构建有了基本的了解和掌握，同时我们将 CNN 于 MLP 的测试结果进行的简单的对比，可以看出 CNN 在图片识别的问题处理上具有明细的优势。CNN 网络结构可以简单的理解为是由“卷积网络结构” + “MLP网络结构”而组成的。CNN 在当前的应用领域早已经不限于图片识别，随着大家不断地对 CNN 结构的优化和算法的调整，可以预测到在不远将来 CNN 真有可能将无处不在：）<br>希望本篇对您关于 CNN 网络的具体构建和应用的学习有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/" target="_blank" rel="external">Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras</a></li>
<li><a href="https://keras.io/layers/convolutional/" target="_blank" rel="external">Keras Docs » Layers » Convolutional Layers</a></li>
<li><a href="http://datascience.stackexchange.com/questions/11840/border-mode-for-convolutional-layers-in-keras" target="_blank" rel="external">border_mode for convolutional layers in keras</a></li>
<li><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html" target="_blank" rel="external">numpy.random.seed</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2017/01/01/deeplearning/handwritten-digit-recognition-using-CNN-with-keras/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt; &lt;br&gt;手写数字识别是机器学习最早实现商业应用的领域之一，本篇将讲解用 CNN 进行手写数字识别的具体方法，通过阅读本篇内容您将了解到：&lt;br&gt;- MNIST 数据的载入与使用；&lt;br&gt;- MLP 对 MNIST 进行识别的具体方法；&lt;br&gt;- CNN 网络的构法与基于 MNIST 进行手写识别的具体方法；&lt;br&gt;- 如何对 CNN 网络进行优化加强；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks（CNN）神经网络介绍</title>
    <link href="http://yoursite.com/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/"/>
    <id>http://yoursite.com/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/</id>
    <published>2016-12-18T13:15:30.000Z</published>
    <updated>2017-02-02T14:10:33.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/0.png" alt="0.png" title=""> <br>本篇将对 <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank" rel="external">Convolutional Neural Networks（CNN，ConvNet）</a>神经网络进行简要的介绍，通过阅读本篇内容您将了解到：<br>- CNN 的特点及网络构成；<br>- CNN 的功能实现原理；<br>- CNN 的一些最佳实践；<br><a id="more"></a>
<h1 id="CNN-简介"><a href="#CNN-简介" class="headerlink" title="CNN 简介"></a>CNN 简介</h1><p>CNN 是当前能强大的深度学习神经网络之一，特别是在图像识别应用上已经取得了惊人的表现。CNN 的设计原型最早起源于<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="external">LeNet5</a>，当时主要用于文本识别，后经人们不断对网络在结构和性能上的优化形成了今天我们广泛使用的 CNN。<br>CNN 在图像识别上的优势主要体现为：</p>
<ul>
<li>可以缩减计算过程中的权重（weights）数量；</li>
<li>在物体识别上能够抵轻微的扭曲，形变等干扰；</li>
<li>具有自动学习，特征归纳的特性；</li>
<li>对物体的识别不受该物体在图片中位置变动的影响；</li>
</ul>
<h1 id="CNN-网络结构"><a href="#CNN-网络结构" class="headerlink" title="CNN 网络结构"></a>CNN 网络结构</h1><p>CNN 的神经层主要有3种：</p>
<ul>
<li>卷积层（Convolutional Layer）；</li>
<li>汇集层（Pooling Layer）；</li>
<li>全连接层（Fully-Connected Layer）；</li>
</ul>
<p>在处理数据时3种神经层主要作用各不相同，下面是一个简要的 CNN 示例，对图片中可能包含的物体（dog，cat，boat，bird）进行识别判断：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/cnn-demo.png" alt="cnn-demo.png" title=""> 我们可以看到整个识别的过程是由3种神经层共同协作完成的，接下来我们将对它们进行一一介绍。</p>
<h2 id="卷积层（Convolutional-Layer）"><a href="#卷积层（Convolutional-Layer）" class="headerlink" title="卷积层（Convolutional Layer）"></a>卷积层（Convolutional Layer）</h2><p>卷积层主要包含过滤器（filter）和特征图谱（feature map）两部分，是数据流经 CNN 网络最先到达的神经层。<br>“卷积”名称源自于在该层主要进行的矩阵卷积计算<a href="https://en.wikipedia.org/wiki/Convolution" target="_blank" rel="external">（Convolution）</a>。下面我们来看一下卷积操作在图片上具体执行的过程。<br>假设我们需要处理的是一个5x5像素大小的单通道灰度图片，每个像素值只有0或1（灰度图片的每个像素值一般在0到255之间），转换为2维矩阵如下图所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/5x5.png" alt="5x5.png" title=""> 同时，我们生成另一个3x3大小矩阵：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/filter.png" alt="filter.png" title=""> 我们所称的在图片上执行的卷积操作即可简化为如下动画所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/convolution.gif" alt="convolution.gif" title=""> 橙色矩阵在绿色矩阵每次移动1像素，每移动一个新的位置即与所在绿色区域进行对应元素相乘，乘积之和作为一个新的粉色矩阵的子元素。<br>在 CNN 中我们称橙色矩阵为过滤器（filter），也有称为核（kernel）或特征检测器（feature detector）。粉色矩阵称为特征图谱（Feature Map），也有称为卷积特征（Convolved Feature）或激活图谱（Activation Map）都是一个意思。橙色矩阵在绿色矩阵每次移动的像素大小我们称为步幅（stride）。<br>同一张图片上使用不同的过滤矩阵进行卷积操作，得到的特征图谱显然也是不一样的，即提取到的特征不同。特征图谱矩阵对应输出的图片效果也是不一样的，这在图片处理软件中经常见到，更多可以参考<a href="https://docs.gimp.org/en/plug-in-convmatrix.html" target="_blank" rel="external">这里</a>。<br>CNN 在实际训练时过滤矩阵的元素值是通过学习自动调整的，使用的过滤器越多提取到的特征也就越多。<br>特征图谱矩阵的大小主要与以下因素有关：</p>
<ol>
<li>深度（Depth）：即过滤矩阵的个数，如下图所示，在处理图片时使用了3个过滤矩阵，因此生成了3个特征图谱矩阵。<img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/depth.png" alt="depth.png" title=""></li>
<li>步幅（Stride）：即过滤矩阵在图片矩阵上进行卷积操作时每次移动的像素个数。步幅越大则生成的特征图谱矩阵越小。</li>
<li>0填充（Zero-padding）：0填充指的是在图片矩阵的周围填充值为0的元素，如下图所示：<img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/zero-padding.png" alt="zero-padding.png" title=""> 
0填充的作用主要体现在：一是可以解决“整除”问题，即过滤矩阵在图片矩阵上移动时确保所有图片矩阵元素都能覆盖到，应用中可以理解为能够更好的支持处于图片边缘的物体的识别；二是便于控制特征图谱矩阵的大小；</li>
</ol>
<h2 id="汇集层（Pooling-Layer）"><a href="#汇集层（Pooling-Layer）" class="headerlink" title="汇集层（Pooling Layer）"></a>汇集层（Pooling Layer）</h2><p>汇集（Pooling）也称为空间汇集（Spatial Pooling）或二次抽样（subsampling）或降采（downsampling），主要作用是缩聚特征图谱矩阵，同时保留特征图谱矩阵内的关键信息。<br>常用方法包括：取最大（Max）, 取平均（Average）, 取加和（Sum）等。<br>以取最大汇集为例，如下图所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/max-pooling.png" alt="max-pooling.png" title=""> 我们定义的汇集窗口大小为2x2，取其中的最大值，在特征图谱矩阵上依次汇集后生成了一个新的矩阵。同样我们也可以使用取平均或取加和的方式进行汇集，但通常情况下使用取最大方法获得的效果相对更好一些。<br>需要强调的是，汇集操作是对每个特征图谱矩阵分别进行的，如下图所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/separately-pooling.png" alt="separately-pooling.png" title=""> 这里从原始图片获得了3个特征图谱矩阵，分别通过汇集操作后生成了3个新矩阵。<br>汇集操作对特征图谱矩阵进行缩聚的作用主要为：</p>
<ul>
<li>减小矩阵大小便于操作；</li>
<li>减少计算参数，控制过拟合<a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="external">（Overfitting）</a>；</li>
<li>增强物体识别的抗干扰能力，包括轻微的扭曲，变形等等。</li>
<li>对物体的识别不受该物体在图片中位置变动的影响；</li>
</ul>
<h2 id="全连接层（Fully-Connected-Layer）"><a href="#全连接层（Fully-Connected-Layer）" class="headerlink" title="全连接层（Fully-Connected Layer）"></a>全连接层（Fully-Connected Layer）</h2><p>全连接层一般采用的是通常的多层感知神经网络，主要作用是基于之前经过卷积层和汇集层提取到的特征集对所处理的图片进行分类。<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/c-p-fc.png" alt="c-p-fc.png" title=""></p>
<h2 id="一个直观的例子"><a href="#一个直观的例子" class="headerlink" title="一个直观的例子"></a>一个直观的例子</h2><p>这里我们将介绍由<a href="http://scs.ryerson.ca/~aharley/" target="_blank" rel="external">Adam Harley</a>制作的一个非常直观的 CNN 用于手写数字识别的<a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="external">例子</a>，如下图：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/cnn-mnist.png" alt="cnn-mnist.png" title=""> 该网络的输入图片大小为32x32，1024像素。<br>卷积层1具有6个过滤器，大小为5x5，步幅为1，对输入图片矩阵进行卷积操作后生成了6个特征图谱矩阵（深度为6）。<br>汇集层1紧接着分别对6个特征图谱矩阵进行取最大汇集操作，汇集窗口大小为2x2，步幅为2。<br>卷积层2具有16个过滤器，大小为5x5，步幅为1，对汇集层1继续进行卷积操作，生成16个特征图谱矩阵。<br>汇集层2分别对16个特征图谱矩阵进行取最大汇集操作，汇集窗口大小为2x2，步幅为2。<br>全连接层由3层构成：第一层包含120个神经元，第二次包含100个神经元，第三层（CNN 输出层）包含10个神经元，与所识别的10个数字相对应。输出层10个节点的亮度代表了所识别的手写数字属于该类别可能性的大小。<br>通过该例子的介绍，相信您对 CNN 的内部结构一定有了进一步的认识。<a href="http://scs.ryerson.ca/~aharley/vis/conv/" target="_blank" rel="external">这里</a>是该例子的3D版本。</p>
<h2 id="几点说明"><a href="#几点说明" class="headerlink" title="几点说明"></a>几点说明</h2><ol>
<li>这部分主要是对 CNN 构成的概要介绍，更多关于具体的技术实现细节可以参考文后的相关链接；</li>
<li>在上文的 CNN 示例图中参与的是两套卷积层和汇集层的组合，实际上组合的具体形式是不固定的，可以根据具体问题和调优效果而定，如下面的应用例子中使用的多层组合：<img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/car.png" alt="car.png" title="">
</li>
</ol>
<h1 id="CNN-功能原理浅析"><a href="#CNN-功能原理浅析" class="headerlink" title="CNN 功能原理浅析"></a>CNN 功能原理浅析</h1><p>前文我们提到了 CNN 在图片识别上有诸多的优点，包括对物体的识别不受该物体在图片中位置变动的影响，在这一部分我们将着重介绍 CNN 的功能实现原理。</p>
<h2 id="目标识别"><a href="#目标识别" class="headerlink" title="目标识别"></a>目标识别</h2><p>以下面一个简单的 CNN 模型为例：<br> 蓝色平板代表图片，绿色块和黄色块代表两层特征图谱矩阵汇集后的输出，灰色圆链区代表全连接层。<br>假设我们对图片中的人物进行识别，如下图所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/cnn-mechanism-2.png" alt="cnn-mechanism-2.png" title=""> 图片中标示的两个红色圆点代表眼睛，一个粉色圆点代表鼻子。<br>在第一个卷积层操作中，我们先对与人物相关的局部“低级”特征进行检测，使用的过滤器包括：负责检测类眼睛特征的，负责检测类鼻子特征的等等。每个过滤器的检测结果（过滤器与图片矩阵进行卷积操作后生成的特征图谱矩阵）经过汇集操作后生成绿块部分的“低级”特征输出。<br>在第二个卷积层操作中，我们加入了更多与人物相关的“高级”特征过滤器，包括：人脸特征过滤器，腿特征过滤器等等。“高级”过滤器与绿块的各矩阵进行卷积操作后，再经过汇集操作就生成了黄块部分的“高级”特征输出。<br>灰色圆链区的全连接层根据黄块部分输出的“高级”特征即可对图片中所包含人物进行识别。</p>
<h2 id="位置变动后的识别"><a href="#位置变动后的识别" class="headerlink" title="位置变动后的识别"></a>位置变动后的识别</h2><p>CNN 特点之一是对物体的识别不受该物体在图片中位置变动的影响。继续我们上面的例子，假设这次我们要识别的对象改变了在图片中的位置：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/cnn-mechanism-3.png" alt="cnn-mechanism-3.png" title=""> 重复上述从“低级”到“高级”特征提检测再到判断输出的过程，我们依然能够识别出变换了位置的目标对象！CNN 的这个特性是由其包含的3类网络层共同协作实现的。<br>CNN 采用层层归纳特征提取的方式对图片进行识别的机制与<a href="https://en.wikipedia.org/wiki/Visual_system" target="_blank" rel="external">生物视觉系统</a>的实现原理有一定的相似性，如有兴趣不妨了解一下。</p>
<h2 id="几点说明-1"><a href="#几点说明-1" class="headerlink" title="几点说明"></a>几点说明</h2><ol>
<li>为简化原理的描述，我们这里定义的“低级”特征在实际网络中已经算是很“高级”的特征了。实际网络的“低级”特征一般都是从图片中最细微的线条走向（类似边缘检测）等最基本特征开始提取的，如下图所示：<br><img src="/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/feature-map.gif" alt="feature-map.gif" title=""> 这里直观地展示了两种基本线条特征的提取过程。</li>
<li>这里我们所说的“低级”和“高级”是相对而言的，同时在实际训练中各级特征并非都是形象直观的，大多所提取的特征对我们人类而言是没有直接意义的。</li>
</ol>
<h1 id="CNN-最佳实践"><a href="#CNN-最佳实践" class="headerlink" title="CNN 最佳实践"></a>CNN 最佳实践</h1><p>现在我们已经知道了 CNN 的构造及原理，接下来我们将介绍 CNN 在实际应用的一些最佳实践：</p>
<ul>
<li>过滤器矩阵大小：处理小图片通常设置为3x3，大图片会设置为5x5或7x7;</li>
<li>步幅大小：通常设置为1。处理较大图片时会设置为2或者更大；</li>
<li>过滤器数量：通常输入层过滤器的数量相对较少，越往后的层设置的数量越多；</li>
<li>汇集层：汇集窗口通常设置为2x2；</li>
<li>数据预处理：通常会对输入数据进行标准化处理，包括图片大小和像素值；</li>
<li>抽稀（Dropout）：CNN 网络比较容易出现过拟合情况，可以在汇集层后和全连接层中适当添加抽稀层；</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇我们主要介绍了 CNN 的网络结构和主要特点，同时我们对 CNN 各层的功能及概念进行了详细的介绍。我们对 CNN 功能特性的实现原理进行了简要的的分析。在实际应用中我们介绍了一些 CNN 最佳实践以供参考。<br>希望本篇对您在深度学习中关于 CNN 的认识和了解有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_blank" rel="external">An Intuitive Explanation of Convolutional Neural Networks</a></li>
<li><a href="http://xrds.acm.org/blog/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/" target="_blank" rel="external">Convolutional Neural Networks (CNNs): An Illustrated Explanation</a></li>
<li><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">CS231n Convolutional Neural Networks for Visual Recognition, Stanford</a></li>
<li><a href="https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features" target="_blank" rel="external">How is a convolutional neural network able to learn invariant features?</a></li>
<li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="external">Gradient-Based Learning Applied to Document Recognition</a></li>
<li><a href="http://machinelearningmastery.com/crash-course-convolutional-neural-networks/" target="_blank" rel="external">Crash Course in Convolutional Neural Networks for Machine Learning</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap6.html" target="_blank" rel="external">Chapter 6 in Michael Nielsen’s open Deep Learning book</a></li>
<li><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" target="_blank" rel="external">UNDERSTANDING CONVOLUTIONAL NEURAL NETWORKS FOR NLP</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/12/18/deeplearning/convolutional-neural-networks-for-machine-learning/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将对 &lt;a href=&quot;https://en.wikipedia.org/wiki/Convolutional_neural_network&quot;&gt;Convolutional Neural Networks（CNN，ConvNet）&lt;/a&gt;神经网络进行简要的介绍，通过阅读本篇内容您将了解到：&lt;br&gt;- CNN 的特点及网络构成；&lt;br&gt;- CNN 的功能实现原理；&lt;br&gt;- CNN 的一些最佳实践；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Recurrent Neural Networks（RNN）神经网络介绍</title>
    <link href="http://yoursite.com/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/"/>
    <id>http://yoursite.com/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/</id>
    <published>2016-12-18T13:12:00.000Z</published>
    <updated>2017-02-02T14:09:32.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/0.png" alt="0.png" title=""> <br>本篇将对 <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" target="_blank" rel="external">Recurrent Neural Networks（RNN）</a>神经网络进行简要的介绍，通过阅读本篇内容您将了解到：<br>- RNN 的基本介绍和浅析；<br>- RNN 训练；<br>- LSTM RNN 网络；<br><a id="more"></a>
<h1 id="RNN-简介"><a href="#RNN-简介" class="headerlink" title="RNN 简介"></a>RNN 简介</h1><p>在深度学习中有一种处理序列数据特别有效的神经网络叫 Recurrent Neural Networks，简称 RNN，中文常称为“循环神经网络”或“（时间）递归神经网络”。<br>RNN 之所以在处理序列特征上表现突出，主要得益于其网络内部构建上的特点，主要包括循环反馈，状态记忆等。</p>
<h1 id="RNN-与序列数据处理"><a href="#RNN-与序列数据处理" class="headerlink" title="RNN 与序列数据处理"></a>RNN 与序列数据处理</h1><p>在序列数据处理中有很多有意思的应用。例如基于时间的变化量的预测：预测股价基于时间的变化量而进行投资参考，预测网络服务访问量基于时间的变化而做运维提前预警等。<br>对于这种基于单变量而变动的序列数据，如果使用经典的多层前反馈神经网络进行处理分析，一般需要先将序列数据根据定义好的时间窗口进行切分，以每份来作为神经网络的训练和预测。类似的分析方法在实践中会起到一定的作用，但人们发现有很多局限，如时间窗口的选择常常需要有对所处理的问题具有丰富经验的人来定才更有效，而这也仅是基于经验的确定。再者，假设时间窗口大小选择的是5s，那么对于1min，1h等更大范围内的数据变化分析预测的可操作性就相对差一些，反之亦然，往往会产生错误的预测或漏掉关键时间点的检测。<br>当前分析序列数据在深度学习中比较有效的是 RNN 网络，处理的问题主要可以分为以下几类：</p>
<ul>
<li>一对多：如图片描述；</li>
<li>多对一：如感情色彩分类；</li>
<li>多对多：如机器翻译；</li>
<li>同步多对多：如视频分类；</li>
</ul>
<p>随着优化技术的改进和提高，RNN 近年来也是不断地给人们带来惊喜。</p>
<h1 id="RNN-浅析"><a href="#RNN-浅析" class="headerlink" title="RNN 浅析"></a>RNN 浅析</h1><p>RNN 的结构可以简单理解为在通常的多层前反馈神经网络上增加了循环输入，以此来学习序列数据的“顺序”特性。具体实现过程可简述如下：<br>RNN 处理输入数据 X(t) 产生 Y(t) 其中包涵一个状态（state）描述 S(t):<br><img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/1.png" alt="1.png" title=""> 当处理 X(t+1) 时，同样有 S(t+1)，而此时 Y(t+1) 的产生则包涵了 S(t) 和 S(t+1) 的共同作用：<br><img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/2.png" alt="2.png" title=""> S(t)携带的是上一次处理的状态信息，所以整个 RNN 的处理流程可以示意为：<br><img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/3.png" alt="3.png" title=""><br>根据处理问题类型的不同，整个 RNN 网络的输出也可以是多样的，如：<br>一对多的图片描述问题：<img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/4.png" alt="4.png" title=""> 多对一的感情色彩分类问题：<img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/5.png" alt="5.png" title=""> 多对多的机器翻译问题：<img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/6.png" alt="6.png" title=""> </p>
<h1 id="RNN-训练问题"><a href="#RNN-训练问题" class="headerlink" title="RNN 训练问题"></a>RNN 训练问题</h1><p>多层前反馈神经网络常用有效的训练算法是 <a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external">Backpropagation</a>。在 RNN 中由于新增了循环机制，在网络训练中更多采用的是改进过的 Backpropagation 算法，如：<a href="https://en.wikipedia.org/wiki/Backpropagation_through_time" target="_blank" rel="external">Backpropagation through time（BPTT）</a>。<br>在网络结构的具体实现上有一个主要处理细节是“展开”（Unfold）：<br><img src="/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/7.png" alt="7.png" title=""> Unfold 的作用是将 RNN 的循环结构转换成了非循环结构，以便应用 Backpropagation 算法进行训练。</p>
<h1 id="LSTM-RNN-网络"><a href="#LSTM-RNN-网络" class="headerlink" title="LSTM RNN 网络"></a>LSTM RNN 网络</h1><p>在训练层数较多的 RNN 网络时，下降梯度经常会出现不稳定的情况，爆炸式增长或者消失<a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" target="_blank" rel="external">vanishing gradient problem</a>，不稳定的梯度会影响到训练的稳定性和整个网络的可靠性。<br><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank" rel="external">Long Short-Term Memory（LSTM）</a>是 RNN 网络的一种，可以有效的解决该问题，在大规模（多层）的 RNN 训练中使用比较广泛。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过阅读本篇文章，您知道了 RNN 是处理分析序列数据比较有效的一种深度学习神经网络，您对 RNN 的基本结构和特点有了一定的认识，同时本篇还介绍了 LSTM RNN 网络的相关特点。<br>希望本篇对您在深度学习中关于 RNN 的了解有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/crash-course-recurrent-neural-networks-deep-learning/" target="_blank" rel="external">Crash Course in Recurrent Neural Networks for Deep Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=EEtf4kNsk7Q" target="_blank" rel="external">什么是循环神经网络 RNN (深度学习)?</a></li>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">RECURRENT NEURAL NETWORKS TUTORIAL, PART 1 – INTRODUCTION TO RNNS</a></li>
<li><a href="https://deeplearning4j.org/lstm.html" target="_blank" rel="external">A Beginner’s Guide to Recurrent Networks and LSTMs</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM Networks</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/12/18/deeplearning/recurrent-neural-networks-for-deep-learning/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将对 &lt;a href=&quot;https://en.wikipedia.org/wiki/Recurrent_neural_network&quot;&gt;Recurrent Neural Networks（RNN）&lt;/a&gt;神经网络进行简要的介绍，通过阅读本篇内容您将了解到：&lt;br&gt;- RNN 的基本介绍和浅析；&lt;br&gt;- RNN 训练；&lt;br&gt;- LSTM RNN 网络；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习神经网络基础介绍</title>
    <link href="http://yoursite.com/2016/12/11/deeplearning/introduction-to-neural-networks/"/>
    <id>http://yoursite.com/2016/12/11/deeplearning/introduction-to-neural-networks/</id>
    <published>2016-12-11T12:57:19.000Z</published>
    <updated>2017-02-02T14:08:43.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/12/11/deeplearning/introduction-to-neural-networks/0.jpeg" alt="0.jpeg" title=""> <br>本篇将对深度学习基础神经网络的构成及相关概念进行简要介绍，通过阅读本篇内容您将了解到：<br>- 神经网络的基本组成元素；<br>- 多层感知神经网络（MLP）的构成；<br>- 反向传播算法的功能实现原理；<br>- MLP 的具体应用场景；<br><a id="more"></a>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>深度学习的理论基础是其背后的数学推导计算，深度学习神经网络是该理论的一种具体实现技术，包括权重计算，结果输出等。深度学习神经网络的实现受启发于生物大脑神经系统的研究理论（有相应专用名词的借用，但具体概念和功能实现不完全相同）。本篇将为您详细介绍深度学习神经网络的基础构成和相关常用的技术实现算法，如未特殊说明则本篇提到的“神经”相关名词均特指深度学习范畴内的概念。</p>
<h1 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h1><p>神经网络的基础计算单元是神经元（neuron），也称节点（node）或单元（unit）。如下图所示：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/single-neuron.png" alt="single-neuron.png" title=""> 神经元可以接收输入（来自其他神经元的输出或外部数据），经过计算（f()）后产生输出（输出给其它神经元或外部结果）。权重（weight，w）表示输出神经元与接收神经元之间联系的强弱，值的大小在神经网络的训练过程中会自动调整直到趋于稳定（理想目标），也是训练的主要对象。<br>上图中的神经元接收输入数据<code>X1</code>（权重为<code>w1</code>），<code>X2</code>（权重为<code>w2</code>）和大小为1的偏差（Bias）（权重为<code>b</code>），经过函数<code>f()</code>计算后产生输出<code>Y</code>。</p>
<p><strong><code>f()</code></strong>：称为激活函数（Activation Function），一般是非线性的，主要作用是为神经元的输出加入非线性特性，增强神经网络对训练数据的学习能力。实践中较常用的激活函数主要有以下几种：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/activation-functions.png" alt="activation-functions.png" title=""> </p>
<ul>
<li><strong>Sigmoid</strong>：将输入转换为0到1的输出：<br><code>σ(x) = 1 / (1 + exp(−x))</code></li>
<li><strong>tanh</strong>：将输入转换为-1到1的输出：<br><code>tanh(x) = 2σ(2x) − 1</code></li>
<li><strong>ReLU</strong>：Rectified Linear Unit 的缩写，将输入与0取最大：<br><code>f(x) = max(0, x)</code></li>
</ul>
<p><strong>偏差（Bias）</strong>：在神经元中的作用主要是为激活函数的计算增加一个常数，具体大小由训练确定。偏差的详细功能介绍可以参考<a href="http://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks" target="_blank" rel="external">这里</a>。</p>
<h1 id="前馈神经网络（Feedforward-Neural-Network）"><a href="#前馈神经网络（Feedforward-Neural-Network）" class="headerlink" title="前馈神经网络（Feedforward Neural Network）"></a>前馈神经网络（Feedforward Neural Network）</h1><p>前馈神经网络是最早出现的人工神经网络，主要结构如下图：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/feedforward-neural-network.png" alt="feedforward-neural-network.png" title=""><br>前馈神经网络主要包含3种神经元：</p>
<ul>
<li>输入神经元（输入节点）：输入神经元的作用是接收外部数据，之后传递给隐含神经元，输入神经元不对数据进行计算处理。输入神经元组成的神经层通常称为输入层（Input Layer）；</li>
<li>隐含神经元（隐含节点）：隐含神经元不与外部数据直接接触，处在输入层与输出层之间。隐含神经元将接收到的数据经过激活函数计算后会传递给输出神经元，或下一隐含层种的隐含神经元。隐含神经元所组成的神经层通常称为隐含层（Hidden Layer）。前馈神经网络中只有一个输入层和一个输出层，但可以有多个隐含层或没有隐含层。</li>
<li>输出神经元（输出节点）：输出神经元将接收的数据经过激活函数计算后输出到神经网络外部。输出神经元组成的神经层通常称为输出层（Output Layer）；<br>前馈神经网络中数据的流经方向只有一个，即输入层 -&gt; [隐含层] -&gt; 输出层。</li>
</ul>
<p>前馈神经网络在实践应用中的类型主要有两种：</p>
<ul>
<li>单层感知神经网络（Single Layer Perceptron）：没有隐含层，是最简单的一种前馈神经网络；</li>
<li>多层感知神经网络（Multi Layer Perceptron）：具有一个或多个隐含层，功能相对单层感知神经网络更强大，应用也更广泛；</li>
</ul>
<p>接下来我们将主要介绍多层感知神经网络。</p>
<h1 id="多层感知神经网络（Multi-Layer-Perceptron，MLP）"><a href="#多层感知神经网络（Multi-Layer-Perceptron，MLP）" class="headerlink" title="多层感知神经网络（Multi Layer Perceptron，MLP）"></a>多层感知神经网络（Multi Layer Perceptron，MLP）</h1><p>MLP 除了输入层和输出层外，还具有一个或多个隐含层。我们将介绍的 MLP 示例如下：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/mlp.png" alt="mlp.png" title=""> 每个连接之间均有权重，我们这里暂标3个（w0, w1, w2）。<br><strong>输入层</strong>：本例的输入层有3个神经元（节点），偏差神经元的输入值大小为1，其它两个神经元的输入值分别为X1，X2    。输入层主要负责接收数据，不对数据进行计算，所以1，X1，X2分别被传递到隐含层。<br><strong>隐含层</strong>：本例的隐含层同样有3个神经元，一个值为1的偏差神经元，两个隐含神经元。隐含神经元接收来自输入层的输出，经过激活函数计算后输出到输出层。计算过程如图中高亮所示，激活函数的入参为各节点的输入值与权重乘积的加和。<br><strong>输出层</strong>：本例的输出层有2个神经元，接收到来自隐含层的输出后，经过激活函数计算后输出结果Y1，Y2，也是整个网络本次的计算结果。激活函数的计算原理与隐含层相同（激活函数有可能不同）。</p>
<h1 id="MLP-应用"><a href="#MLP-应用" class="headerlink" title="MLP 应用"></a>MLP 应用</h1><p>给定输入数据集和目标数据集，经过训练后的 MLP 可以自动找到它们之间的联系。因此 MLP 在实践中有着广泛的应用，如分类问题，统计回归问题等。<br>我们这里举一个在分类问题中的应用，下表是一个简单的学生成绩单：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/student-marks-1.png" alt="student-marks-1.png" title=""> 前两列分别表示的是学生学习时间和期中考试成绩，最后一列表示的是期末考试是否通过（1：通过，0：未通过）。假设有一位学生的学习时间和期中考试的情况如下：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/student-marks-2.png" alt="student-marks-2.png" title=""> 那么我们如何根据已有的成绩单来判断这位学能否在期末考试中通过呢？这就是 MLP 经常处理的二值分类预测问题，经过训练学习已有的数据（成绩单）后，MLP 可以对新数据（这位学生的期末考试）做出预测判断。<br>接下来我们将详细介绍 MLP 训练学习的具体过程。</p>
<h1 id="MLP-训练算法－反向传播（Back-Propagation）介绍"><a href="#MLP-训练算法－反向传播（Back-Propagation）介绍" class="headerlink" title="MLP 训练算法－反向传播（Back-Propagation）介绍"></a>MLP 训练算法－反向传播（Back-Propagation）介绍</h1><p>MLP 的训练方法当前的通常采用的是反向传播算法<a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external">（Backward Propagation of Errors，BackProp）</a>，通俗的解释可以参考<a href="https://www.quora.com/How-do-you-explain-back-propagation-algorithm-to-a-beginner-in-neural-network/answer/Hemanth-Kumar-Mantri" target="_blank" rel="external">这里</a>，数学推导可以参考<a href="http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="external">这里</a>。我们这里将继续结合上文的应用示例对反向传播算法的功能实现原理进行简要的介绍。</p>
<h2 id="正向计算"><a href="#正向计算" class="headerlink" title="正向计算"></a>正向计算</h2><p><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/back-prop-1.png" alt="back-prop-1.png" title=""> 上图是我们这里用于学生成绩预测的一个简单的 MLP 网络结构。输入层接收的数据分别是大小为1的偏差，学生学习时间和期中考试成绩。输出层的结果是对应学生的期末考试情况，[1, 0]：通过，[0, 1]：未通过。<br>这里我们首现输入的数据是[35, 67]，训练的输出目标是[1, 0]。数据正向流经隐含层，输出层，各连接权重在初始化时是随机设置的（一般在0到1之间），各节点的具体计算过程我们在上文已经介绍过了，这里我们来重点看一下输出层数据输出时的具体处理情况。<br>我们本次计算的输入数据是[35, 67]，输出结果是[0.4, 0.6]，期望的输出目标是[1, 0]，误差为[0.6, -0.4]，我们可以看到输出结果与目标是有很大误差的，因此我们需要回过来对各连接权重做调整。<br>这里需要说明的是我们对输出结果的处理是通过 <a href="http://cs231n.github.io/linear-classify/#softmax" target="_blank" rel="external">Softmax</a> 函数完成的，更多关于 Softmax 函数的功能特点可以参考文后的资源连接。</p>
<h2 id="反向调整"><a href="#反向调整" class="headerlink" title="反向调整"></a>反向调整</h2><p><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/back-prop-2.png" alt="back-prop-2.png" title=""> 上图示意的是各权重调整过程，3个示意标示的连接权重值由原先的w1，w2，w3更新成了w4，w5，w6。权重调整后，我们再次输入[35, 67]，进行计算：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/back-prop-3.png" alt="back-prop-3.png" title=""> 这次的输出结果为[0.8, 0.2]，误差为[0.2, -0.2]，相对上一次来误差明显缩小了许多。之后我们重复上述整个过程：结果计算，误差比较，权重调整，直到误差缩小到满意的范围为止。这一权重调整的训练过程即是反向传播算法功能实现的主要原理。<br>这时如果我们要预测一位学习时间为25，期中考试成绩为70的学生在期末考试的成绩，那么只需将数据[25, 70]输入刚训练好的网络即可得出预测结果。</p>
<h1 id="来一个酷炫的例子"><a href="#来一个酷炫的例子" class="headerlink" title="来一个酷炫的例子"></a>来一个酷炫的例子</h1><p>下面是由 Adam Harley 制作的一个手写识别 MLP 实现的可视化<a href="http://scs.ryerson.ca/~aharley/vis/fc/" target="_blank" rel="external">例子</a>：<br><img src="/2016/12/11/deeplearning/introduction-to-neural-networks/mlp-demo-3d.png" alt="mlp-demo-3d.png" title=""> 这里识别对象是28x28大小的图片，共784像素，因此网络的输入层设置了784个输入神经元与各像素一一对应。网络共有两个隐含层，第一隐含层包含300个神经元，第二隐含层包含100个神经元。网络的输入层包含10个神经元，与所预测的10个数字一一对应。在输出层各节点的亮度的大小代表了预测结果属于该数字的可能性。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇主要介绍了神经网络的相关基础概念，同时对 MLP 的构成以及反向传播算法功能实现原理等进行了进一步的讲解。我们结合具体示例描述了 MLP 的具体应用场景和训练过程。关于 MLP 数学实现原理的学习您可以进一步参考下面的连接资源。<br>希望本篇对您在深度学习中关于 MLP 的认识和了解有所帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/" target="_blank" rel="external">A Quick Introduction to Neural Networks</a></li>
<li><a href="https://www.zhihu.com/question/22334626" target="_blank" rel="external">神经网络激活函数的作用解答</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0" target="_blank" rel="external">Softmax函数</a></li>
<li><a href="http://blog.csdn.net/supercally/article/details/54234115" target="_blank" rel="external">Softmax的理解与应用</a></li>
<li><a href="http://cs231n.github.io/neural-networks-1/" target="_blank" rel="external">CS231n Convolutional Neural Networks for Visual Recognition</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/index.html" target="_blank" rel="external">Neural Networks and Deep Learning</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/12/11/deeplearning/introduction-to-neural-networks/0.jpeg&quot; alt=&quot;0.jpeg&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将对深度学习基础神经网络的构成及相关概念进行简要介绍，通过阅读本篇内容您将了解到：&lt;br&gt;- 神经网络的基本组成元素；&lt;br&gt;- 多层感知神经网络（MLP）的构成；&lt;br&gt;- 反向传播算法的功能实现原理；&lt;br&gt;- MLP 的具体应用场景；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>使用 Keras 手把手介绍神经网络构建</title>
    <link href="http://yoursite.com/2016/11/27/deeplearning/develop-neural-network-model-with-keras-step-by-step/"/>
    <id>http://yoursite.com/2016/11/27/deeplearning/develop-neural-network-model-with-keras-step-by-step/</id>
    <published>2016-11-27T13:12:53.000Z</published>
    <updated>2017-02-02T14:18:50.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/11/27/deeplearning/develop-neural-network-model-with-keras-step-by-step/0.png" alt="0.png" title=""> <br>Keras 是简单易用、高效强大的神经网络库，底层计算可基于 TensorFlow 或 Theano 平台实现。本篇将详细介绍 Keras 模型构建的具体步骤。通过阅读本篇内容您将了解到：<br>- Keras 模型构建的主要步骤；<br>- Keras 神经网络搭建的一般过程；<br><a id="more"></a>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>请先配置好 Keras 的相关运行环境，方法很简单，具体请参考本教程的“Keras 简介”一章。</p>
<h1 id="Keras-模型构建概览"><a href="#Keras-模型构建概览" class="headerlink" title="Keras 模型构建概览"></a>Keras 模型构建概览</h1><p>Keras 模型构建主要包括5个步骤：定义（define），编译（compile），训练（fit），评估（evaluate），预测（prediction）。<br><img src="/2016/11/27/deeplearning/develop-neural-network-model-with-keras-step-by-step/model.png" alt="model.png" title=""> 接下来我们将对每个步骤进行详细的介绍。</p>
<h1 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">2</span>))</div></pre></td></tr></table></figure>
<p>定义模型是 Keras 构建神经网络的第一步，这里我们由<code>Sequential</code>类生成了一个实例，然后添加了一个<code>Dense</code>类型的层（layer），参数<code>2</code>表示该层神经元的数量。<br>层的添加也可以在<code>Sequential</code>实例生成时添加：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">layers = [Dense(<span class="number">2</span>)]</div><div class="line">model = Sequential(layers)</div></pre></td></tr></table></figure></p>
<p>一般层的添加顺序即是各层连接的顺序，也是数据流经模型被处理的顺序。<br>模型添加的第一层必须指定输入参数的数量，指定方式由具体模型类型而定，例如多层感知模型提供了一个<code>input_dim</code>参数来指定。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">5</span>, input_dim=<span class="number">2</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>))</div></pre></td></tr></table></figure></p>
<p>上面代码我们定义了一个简单的多层感知模型：具有2个入参的输入层，具有5个神经元的隐含层，具有1个神经元的输出层。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">5</span>, input_dim=<span class="number">2</span>))</div><div class="line">model.add(Activation(<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>))</div><div class="line">model.add(Activation(<span class="string">'sigmoid'</span>))</div></pre></td></tr></table></figure></p>
<p>这里我们在之前的基础上添加了两个<code>Activation</code>新层，你可以看到层的添加在 Keras 中操作起来是非常简便的。</p>
<h1 id="编译模型"><a href="#编译模型" class="headerlink" title="编译模型"></a>编译模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.compile(optimizer=<span class="string">'sgd'</span>, loss=<span class="string">'mse'</span>, metrics=[<span class="string">'accuracy'</span>])</div></pre></td></tr></table></figure>
<p>定义好模型之后我们需要通过编译（compile）来对学习过程进行配置，我们可以为模型的编译指定各类参数包括：优化器<code>optimizer</code>，损失函数<code>loss</code>，评估指标<code>metrics</code>。<br>编译的过程也是 Keras 将我们刚定义好的模型转化为底层平台（TensorFlow 或 Theano）结构描述过程，底层平台会负责后续的计算任务，GPU、CPU 的调度选择，分布式运行等。</p>
<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">history = model.fit(X, y, batch_size=<span class="number">10</span>, nb_epoch=<span class="number">100</span>)</div></pre></td></tr></table></figure>
<p>编译后的模型就可开始训练（fit）了，fit 的过程可以简单的理解为就是通过测试数据来确定神经元间连接权重（weight）的过程。<br>测试数据分为两部分，矩阵类型的输入数据<code>X</code>，和对应的数组类型的输出<code>y</code>数据。<br>神经网络训练通常采用的是反向传播<a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external">（Backpropagation）</a>算法，因此我们需要指定训练周期<code>nb_epoch</code>和每次计算的数据量<code>batch_size</code>。<br>训练完成后，<code>history</code> 会保存模型训练后的相关描述。</p>
<h1 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">loss, accuracy = model.evaluate(X, y)</div></pre></td></tr></table></figure>
<p>训练后的模型，我们需要对其性能进行评估，以此来确定训练效果是否达到了我们的预期。<br><code>evaluate</code>方法的参数<code>X</code>,<code>y</code>与<code>fit</code>方法的数据类型是一样的，一般会选择用测试数据进行评估。</p>
<h1 id="数据预测"><a href="#数据预测" class="headerlink" title="数据预测"></a>数据预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">predictions = model.predict(x)</div></pre></td></tr></table></figure>
<p>当模型的性能评估达到要求后，我们就可以用训练好的模型在新的数据上进行预测了。<br><code>predictions</code>是预测返回的结果，数据格式与输出层的输出格式相同。</p>
<h1 id="一个完整的示例"><a href="#一个完整的示例" class="headerlink" title="一个完整的示例"></a>一个完整的示例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 简易多层感知神经网络示例</span></div><div class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</div><div class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="comment"># 加载，预处理数据集</span></div><div class="line">dataset = numpy.loadtxt(<span class="string">"pima-indians-diabetes.csv"</span>, delimiter=<span class="string">","</span>)</div><div class="line">X = dataset[:,<span class="number">0</span>:<span class="number">8</span>]</div><div class="line">Y = dataset[:,<span class="number">8</span>]</div><div class="line"><span class="comment"># 1. 定义模型</span></div><div class="line">model = Sequential()</div><div class="line">model.add(Dense(<span class="number">12</span>, input_dim=<span class="number">8</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</div><div class="line"><span class="comment"># 2. 编译模型</span></div><div class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, optimizer=<span class="string">'adam'</span>, metrics=[<span class="string">'accuracy'</span>])</div><div class="line"><span class="comment"># 3. 训练模型</span></div><div class="line">history = model.fit(X, Y, nb_epoch=<span class="number">100</span>, batch_size=<span class="number">10</span>)</div><div class="line"><span class="comment"># 4. 评估模型</span></div><div class="line">loss, accuracy = model.evaluate(X, Y)</div><div class="line">print(<span class="string">"\nLoss: %.2f, Accuracy: %.2f%%"</span> % (loss, accuracy*<span class="number">100</span>))</div><div class="line"><span class="comment"># 5. 数据预测</span></div><div class="line">probabilities = model.predict(X)</div><div class="line">predictions = [float(round(x)) <span class="keyword">for</span> x <span class="keyword">in</span> probabilities]</div><div class="line">accuracy = numpy.mean(predictions == Y)</div><div class="line">print(<span class="string">"Prediction Accuracy: %.2f%%"</span> % (accuracy*<span class="number">100</span>))</div></pre></td></tr></table></figure>
<p>这里示例数据选用的是<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data" target="_blank" rel="external">Pima Indians Diabetes Data Set
</a>。您可以下载到示例代码文件到相同目录下。该数据集每项具有8个输入变量和一个输出变量：0或1。<br>我们定义了一个多层感知神经网络模型：输入层有8个入参，隐含层具有12个神经元，激活函数采用的是<code>relu</code>，输出层具有1个神经元，激活函数采用的是<code>sigmoid</code>。<br>模型采用的优化器和损失函数类型分别为：<code>adam</code>和<code>binary_crossentropy</code>，训练周期为100，每次数据量为10。<br>为了演示方便，我们这里模型评估和预测依然采用的是训练数据，实际应用中评估需要在单独准备的测试数据上进行，同样预测也只有在新数据上进行才有意义。<br>以下是示例运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line"><span class="number">768</span>/<span class="number">768</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.5219</span> - acc: <span class="number">0.7591</span></div><div class="line">Epoch <span class="number">99</span>/<span class="number">100</span></div><div class="line"><span class="number">768</span>/<span class="number">768</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.5250</span> - acc: <span class="number">0.7474</span></div><div class="line">Epoch <span class="number">100</span>/<span class="number">100</span></div><div class="line"><span class="number">768</span>/<span class="number">768</span> [==============================] - <span class="number">0</span>s - loss: <span class="number">0.5416</span> - acc: <span class="number">0.7331</span></div><div class="line"> <span class="number">32</span>/<span class="number">768</span> [&gt;.............................] - ETA: <span class="number">0</span>s</div><div class="line">Loss: <span class="number">0.51</span>, Accuracy: <span class="number">74.87</span>%</div><div class="line">Prediction Accuracy: <span class="number">74.87</span>%</div></pre></td></tr></table></figure></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇主要介绍了 Keras 神经网络模型构建的主要步骤及其作用。我们通过一个简单的示例向您展示了 Keras 模型构建的整个过程。<br>希望您对 Keras 库的了解和掌握通过阅读本篇后会有进一步的加强和提高。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://machinelearningmastery.com/5-step-life-cycle-neural-network-models-keras/" target="_blank" rel="external">5 Step Life-Cycle for Neural Network Models in Keras</a> </li>
<li><a href="https://keras.io/optimizers/" target="_blank" rel="external">Optimization algorithms supported by Keras</a></li>
<li><a href="https://keras.io/objectives/" target="_blank" rel="external">Loss functions supported by Keras</a></li>
<li><a href="https://en.wikipedia.org/wiki/Loss_function" target="_blank" rel="external">Loss function</a></li>
<li><a href="http://www.slideshare.net/tw_dsconf/ss-62245351" target="_blank" rel="external">一天搞懂深度学习</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/11/27/deeplearning/develop-neural-network-model-with-keras-step-by-step/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt; &lt;br&gt;Keras 是简单易用、高效强大的神经网络库，底层计算可基于 TensorFlow 或 Theano 平台实现。本篇将详细介绍 Keras 模型构建的具体步骤。通过阅读本篇内容您将了解到：&lt;br&gt;- Keras 模型构建的主要步骤；&lt;br&gt;- Keras 神经网络搭建的一般过程；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Keras 简介</title>
    <link href="http://yoursite.com/2016/11/20/deeplearning/Keras-Introduction/"/>
    <id>http://yoursite.com/2016/11/20/deeplearning/Keras-Introduction/</id>
    <published>2016-11-20T13:18:02.000Z</published>
    <updated>2017-02-02T14:18:46.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/11/20/deeplearning/Keras-Introduction/keras.jpg" alt="keras.jpg" title=""> <br>本篇将对 Keras 进行简要的介绍，通过阅读本篇内容您将了解到：<br>- Keras 简要介绍；<br>- Keras 基本概念；<br>- Keras 设计思想；<br>- Keras 安装运行；<br><a id="more"></a>
<h1 id="Keras-是什么？"><a href="#Keras-是什么？" class="headerlink" title="Keras 是什么？"></a>Keras 是什么？</h1><p><a href="https://keras.io/" target="_blank" rel="external">Keras</a> 是由纯 Python 编写的神经网络库，专注于深度学习，运行在 TensorFlow 或 Theano 之上。<br><a href="https://www.tensorflow.org/" target="_blank" rel="external">TensorFlow</a> 和 <a href="http://deeplearning.net/software/theano/" target="_blank" rel="external">Theano</a> 是当前比较流行的两大深度学习库，但是对初学者来说相对有些复杂。<br>Keras 使用简单，结构清晰，底层计算平台可基于 TensorFlow 或 Theano 之上，功能强大。<br>Keras 可运行于 Python 2.7 或 3.5 环境，完美结合于 GPU 和 CPU，基于 MIT license 发布。<br>Keras 由 Google 工程师 <a href="https://www.linkedin.com/in/fchollet" target="_blank" rel="external">François Chollet</a> 开发和维护。<br>以下是 Keras 的设计原则：</p>
<ul>
<li>模块化（Modularity）：一个模型（model）可以理解为一个独立的序列（sequence）或图，模型之间是相互独立的，可以自由组合。</li>
<li>极简主义（Minimalism）：每个模块都应该尽量的简洁。每一段代码都应该在初次阅读时都显得直观易懂。没有黑魔法，因为它将给迭代和创新带来麻烦。</li>
<li>易扩展（Extensibility）：添加新模块超级简单的容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。</li>
<li>与 Python 协作：Keras 没有单独的模型配置文件类型（作为对比，caffe有），模型由 Python 代码描述，使其更加紧凑，易调试和易扩展。</li>
</ul>
<h1 id="Keras-安装"><a href="#Keras-安装" class="headerlink" title="Keras 安装"></a>Keras 安装</h1><p>Keras 的安装使用需要 Pyhton 及 SciPy 运行环境和 TensorFlow 或 Theano 的底层平台支持。<br>以下是配置安装的具体方法：</p>
<h2 id="安装-TensorFlow-或-Theano"><a href="#安装-TensorFlow-或-Theano" class="headerlink" title="安装 TensorFlow 或 Theano"></a>安装 TensorFlow 或 Theano</h2><ul>
<li><a href="https://github.com/tensorflow/tensorflow#download-and-setup" target="_blank" rel="external">Installation instructions for TensorFlow</a> </li>
<li><a href="http://deeplearning.net/software/theano/install.html#install" target="_blank" rel="external">Installation instructions for Theano</a> </li>
</ul>
<h2 id="安装-Keras"><a href="#安装-Keras" class="headerlink" title="安装 Keras"></a>安装 Keras</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install keras</div></pre></td></tr></table></figure>
<p><a href="https://pypi.python.org/pypi" target="_blank" rel="external">这里</a>可以了解更多 PyPI 相关内容    。<br>Keras 版本查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -c &quot;import keras; print keras.__version__&quot;</div></pre></td></tr></table></figure></p>
<p>Keras 版本更新<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --upgrade keras</div></pre></td></tr></table></figure></p>
<h2 id="TensorFlow-或-Theano-底层平台选择配置"><a href="#TensorFlow-或-Theano-底层平台选择配置" class="headerlink" title="TensorFlow 或 Theano 底层平台选择配置"></a>TensorFlow 或 Theano 底层平台选择配置</h2><p>Keras 底层平台计算选择哪个，可以通过 Keras 配置文件进行设置，文件具体位置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">~/.keras/keras.json</div></pre></td></tr></table></figure></p>
<p>配置文件内容：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"image_dim_ordering"</span>: <span class="string">"tf"</span>, </div><div class="line">    <span class="attr">"epsilon"</span>: <span class="number">1e-07</span>, </div><div class="line">    <span class="attr">"floatx"</span>: <span class="string">"float32"</span>, </div><div class="line">    <span class="attr">"backend"</span>: <span class="string">"tensorflow"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>“backend” 配置项默认是 “tensorflow”，您也可以改为 “theano”，保存后当 Keras 下次运行时即可生效。</p>
<h1 id="运行-Keras-模型"><a href="#运行-Keras-模型" class="headerlink" title="运行 Keras 模型"></a>运行 Keras 模型</h1><p>Keras 的核心概念是模型（model），深度学习模型的构建运行主要包括以下几个步骤：</p>
<ul>
<li>定义模型：创建一个序列（sequence），添加层s（layers）；</li>
<li>编译模型：指定损失函数（loss function），优化器（optimizer）；</li>
<li>训练模型：载入数据进行训练；</li>
<li>模型预测：使用训练好的模型进行预测；</li>
</ul>
<p>Sequence 是主要模型之一，由层的线性栈构成，层加入的顺序即是运行计算之行的顺序。<br>当定义好 Sequence 之后，需要对模型进行编译来对学习过程进行配置，其中您可以指定损失函数和优化器等。<br>编译后的模型即可以载入数据进行训练了，通常这也是最需要计算资源的一步。<br>训练好的模型就可以拿来对新的数据做预测了！</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过本篇文章，您了解到了 Keras 是专注于深度学习简单易用的 Python 库。您对 Keras 的基本概念、设计思想、安装运行等方面有了基本的了解。<br>希望本篇对您在深度学习的学习中起到一定的帮助。</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="https://keras.io/" target="_blank" rel="external">Keras 官网</a></li>
<li><a href="https://github.com/fchollet/keras" target="_blank" rel="external">Keras Project on GitHub</a></li>
<li><a href="https://groups.google.com/forum/#!forum/keras-users" target="_blank" rel="external">Keras User Group</a></li>
<li><a href="https://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="external">Keras 中文文档</a></li>
<li><a href="https://www.manning.com/books/deep-learning-with-python" target="_blank" rel="external">Deep Learning with Python, Francois Chollet</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/11/20/deeplearning/Keras-Introduction/keras.jpg&quot; alt=&quot;keras.jpg&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将对 Keras 进行简要的介绍，通过阅读本篇内容您将了解到：&lt;br&gt;- Keras 简要介绍；&lt;br&gt;- Keras 基本概念；&lt;br&gt;- Keras 设计思想；&lt;br&gt;- Keras 安装运行；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>什么是深度学习?</title>
    <link href="http://yoursite.com/2016/11/06/deeplearning/What-is-Deep-Learning/"/>
    <id>http://yoursite.com/2016/11/06/deeplearning/What-is-Deep-Learning/</id>
    <published>2016-11-06T12:58:12.000Z</published>
    <updated>2017-02-02T14:18:05.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/11/06/deeplearning/What-is-Deep-Learning/dl-intro.png" alt="dl-intro.png" title=""> <br>本篇将对深度学习进行简要的介绍，通过阅读本篇内容您将了解到：<br>- 什么是深度学习；<br>- 深度学习研究领域的几位大牛前辈；<br>- 更多关于深度学习的详细介绍资料；<br><a id="more"></a>
<h1 id="深度学习是什么？"><a href="#深度学习是什么？" class="headerlink" title="深度学习是什么？"></a>深度学习是什么？</h1><p>深度学习（Deep Learning）是机器学习（Machine Learning）的子集。深度学习所实现的算法主要受到动物大脑神经网络的启发，常被称为人工神经网络。<br>近年来深度学习在学术界和工业界的卓越表现少不了业界专家的努力和付出，所以深度学习到底是什么，还是听听几位大牛们的见解更有味道。</p>
<h1 id="深度学习是大规模神经网络"><a href="#深度学习是大规模神经网络" class="headerlink" title="深度学习是大规模神经网络"></a>深度学习是大规模神经网络</h1><p><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/andrewng.jpg" alt="andrewng.jpg" title=""> <a href="https://en.wikipedia.org/wiki/Andrew_Ng" target="_blank" rel="external">Andrew Ng</a> 百度首席科学家，曾在 Google 创建了 Google Brain 项目，应用于众多谷歌服务当中。<br>Andrew 认为我们现在已经具备了足够多的计算资源和海量数据用于大规模神经网络训练，随着训练数据量的递增，神经网络的性能也会随之增加，这一点相比于传统的机器学习具有明显的优势。<br><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/Why-Deep-Learning-1024x742.png" alt="Why-Deep-Learning-1024x742.png" title=""> Andrew 还经常强调的是，当前我们取得的成果还多数来自“监督”学习领域，而在伴随着海量未标记数据产生的“非监督”学习领域深度学习将会带来更多可喜的表现。</p>
<h1 id="深度学习是多层级表征学习"><a href="#深度学习是多层级表征学习" class="headerlink" title="深度学习是多层级表征学习"></a>深度学习是多层级表征学习</h1><p><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/bengio-yoshua.jpg" alt="bengio-yoshua.jpg" title=""> <a href="https://en.wikipedia.org/wiki/Yoshua_Bengio" target="_blank" rel="external">Yoshua Bengio</a>，一位更专注于特征学习的大牛，他所强调的是深度学习可以对原始数据进行自动特征提取，也叫特征学习<a href="https://en.wikipedia.org/wiki/Feature_learning" target="_blank" rel="external">（feature learning）</a>。深度学习的特征学习是通过多层神经网络自动完成的，每一层神经元s会对输入数据进行特征提取并输出给后一层，后一层对传递来的各种特征（基础上）再次进行提取归纳，然后继续传递给后一层，层级数量一般视具体问题和训练调优效果而定。这种通过层级归纳的方式对所处理的原始数据往往具有很好的表征作用，相当于整个网络对所处理的数据形成了自己的概念和理解。<br><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/yannlecun.jpg" alt="yannlecun.jpg" title=""> <a href="https://en.wikipedia.org/wiki/Yann_LeCun" target="_blank" rel="external">Yann LeCun</a>，Facebook AI 研究主管，<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank" rel="external">Convolutional Neural Network (CNN)</a> 之父，对深度学习与传统的神经网络为我们做了更直观的对比和解释：<img src="/2016/11/06/deeplearning/What-is-Deep-Learning/dl01.png" alt="dl01.png" title=""> <img src="/2016/11/06/deeplearning/What-is-Deep-Learning/dl02.png" alt="dl02.png" title=""><a href="https://www.youtube.com/watch?v=Qk4SqF9FT-M" target="_blank" rel="external">Accelerating Understanding:深度学习, Intelligent Applications, and GPUs</a></p>
<h1 id="为什么叫-“Deep”-Learning"><a href="#为什么叫-“Deep”-Learning" class="headerlink" title="为什么叫 “Deep” Learning?"></a>为什么叫 “Deep” Learning?</h1><p><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/geoff-hinton.jpg" alt="geoff-hinton.jpg" title=""> <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" target="_blank" rel="external">Geoffrey Hinton </a>，人工神经网络的开拓者，反向传播算<a href="https://en.wikipedia.org/wiki/Backpropagation" target="_blank" rel="external">(Backpropagation)</a>法发明人之一，可以说是最早提到 “deep” 一词来描述他们研究的大规模神经网络的。“Deep” 简单的说就是<strong>多层级</strong>表征学习，这也是相比于传统人工神经网络最大的不同之处。那为什么 “deep” 神经网络直到近些年才表现的如此突出呢？这还要回到上文Andrew Ng提到的，一切都是“时势使然”（充足的计算资源＋海量数据）。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>深度学习是一种多层级表证学习神经网络，称 “Deep” 是因为层级多、计算量大、训练数据多、表证特征多。Deep Learning 当前广为应用的算法主要有：</p>
<ul>
<li>Multilayer Perceptron Networks（多层感知器网络）</li>
<li>Convolutional Neural Networks（卷积神经网络）</li>
<li>Long Short-Term Memory Recurrent Neural Networks（短时记忆循环神经网络）</li>
</ul>
<p>希望通过阅读这篇文章您对深度学习有了初步的了解和认识。<br><img src="/2016/11/06/deeplearning/What-is-Deep-Learning/deeplearningpioneers.jpg" alt="deeplearningpioneers.jpg" title=""> AI 大牛难得一聚 (☆▽☆)</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ul>
<li><a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" target="_blank" rel="external">Deep learning</a></li>
<li><a href="https://manning-content.s3.amazonaws.com/download/6/f28e668-01fb-4b28-b8e1-2cbf110557e5/Chollet_DLwPython_MEAP_V01_ch1.pdf" target="_blank" rel="external">Deep Learning with Python - Part 1: What is Deep Learning</a></li>
<li><a href="http://machinelearningmastery.com/what-is-deep-learning" target="_blank" rel="external">What is 深度学习?</a></li>
<li><a href="https://www.youtube.com/watch?v=n1ViNeWhC24" target="_blank" rel="external">Deep Learning, Self-Taught Learning and Unsupervised Feature Learning</a></li>
<li><a href="https://www.youtube.com/watch?v=O0VN0pGgBZM" target="_blank" rel="external">What data scientists should know about深度学习</a></li>
<li><a href="http://www.slideshare.net/ExtractConf" target="_blank" rel="external">What data scientists should know about深度学习PPT</a></li>
<li><a href="https://www.youtube.com/watch?v=W15K9PegQt0" target="_blank" rel="external">Invited Talk: Andrew Ng (Stanford University):深度学习</a></li>
<li><a href="https://www.youtube.com/watch?v=QSaZGT4-6EY" target="_blank" rel="external">Deep Learning for Building Intelligent Computer Systems</a></li>
<li><a href="https://www.youtube.com/watch?v=VhmE_UXDOGs" target="_blank" rel="external">Prof. Geoff Hinton -深度学习</a></li>
<li><a href="https://www.youtube.com/watch?v=Qk4SqF9FT-M" target="_blank" rel="external">Accelerating Understanding:深度学习, Intelligent Applications, and GPUs</a></li>
<li><a href="http://www.slideshare.net/tw_dsconf/ss-62245351" target="_blank" rel="external">一天搞懂深度学习</a></li>
<li><a href="http://www.deeplearningbook.org/" target="_blank" rel="external">Deep Learning Book</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/11/06/deeplearning/What-is-Deep-Learning/dl-intro.png&quot; alt=&quot;dl-intro.png&quot; title=&quot;&quot;&gt; &lt;br&gt;本篇将对深度学习进行简要的介绍，通过阅读本篇内容您将了解到：&lt;br&gt;- 什么是深度学习；&lt;br&gt;- 深度学习研究领域的几位大牛前辈；&lt;br&gt;- 更多关于深度学习的详细介绍资料；&lt;br&gt;
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习入门教程简介</title>
    <link href="http://yoursite.com/2016/11/06/deeplearning/deep-learning-tutorial-introduction/"/>
    <id>http://yoursite.com/2016/11/06/deeplearning/deep-learning-tutorial-introduction/</id>
    <published>2016-11-06T12:01:41.000Z</published>
    <updated>2017-02-02T15:53:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本教程主要向大家介绍深度学习的基本功能原理，及如何在实际工作中进行运用。通过阅读本教程您将学习到的具体内容包括（但不限于）以下主要几个方面：</p>
<ul>
<li>什么是深度学习；</li>
<li>深度学习网络的相关基本概念与功能原理；</li>
<li>常用的深度学习网络的具体构建和使用方法；</li>
<li>深度学习具体应用示例介绍几讲解；</li>
<li>深度学习在实践中的一些建议；<a id="more"></a>
</li>
</ul>
<h1 id="为什么会有本教程？"><a href="#为什么会有本教程？" class="headerlink" title="为什么会有本教程？"></a>为什么会有本教程？</h1><p>因为我们都爱深度学习：）</p>
<h1 id="编写规范"><a href="#编写规范" class="headerlink" title="编写规范"></a>编写规范</h1><p>教程中大部分示例讲解部分都是按代码在先文字在后的顺序进行组织的，主要是为方便提高阅读与理解效率。</p>
<h1 id="反馈"><a href="#反馈" class="headerlink" title="反馈"></a>反馈</h1><p>本教程还处在迭代当中，如果您发现笔误或讲解不够准确之处希望您能邮件反馈给我，我会及时进行纠正：）<br>Email：<span style="direction: rtl; unicode-bidi: bidi-override;">moc.liamg@609002gnauggnay</span></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本教程主要向大家介绍深度学习的基本功能原理，及如何在实际工作中进行运用。通过阅读本教程您将学习到的具体内容包括（但不限于）以下主要几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是深度学习；&lt;/li&gt;
&lt;li&gt;深度学习网络的相关基本概念与功能原理；&lt;/li&gt;
&lt;li&gt;常用的深度学习网络的具体构建和使用方法；&lt;/li&gt;
&lt;li&gt;深度学习具体应用示例介绍几讲解；&lt;/li&gt;
&lt;li&gt;深度学习在实践中的一些建议；
    
    </summary>
    
      <category term="《深度学习入门教程》" scheme="http://yoursite.com/categories/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>《黑客列传》之维基解密－Julian Paul Assange</title>
    <link href="http://yoursite.com/2016/04/03/%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B%E4%B9%8B%E7%BB%B4%E5%9F%BA%E8%A7%A3%E5%AF%86%EF%BC%8DJulian-Paul-Assange/"/>
    <id>http://yoursite.com/2016/04/03/黑客列传/《黑客列传》之维基解密－Julian-Paul-Assange/</id>
    <published>2016-04-03T06:56:50.000Z</published>
    <updated>2016-04-16T07:27:38.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/04/03/黑客列传/《黑客列传》之维基解密－Julian-Paul-Assange/0.jpg" alt="0.jpg" title="">
<p><br></p>
<blockquote>
<p>“如果你想造一艘船，不要召集大家搜集木头，不要给他们分配任务，而是要教会他们对浩瀚海洋心生憧憬。”<br>－安托万·德·圣-埃克苏佩里</p>
</blockquote>
<a id="more"></a>
<h1 id="大牛简介"><a href="#大牛简介" class="headerlink" title="大牛简介"></a>大牛简介</h1><p>朱利安·保罗·阿桑奇（Julian Paul Assange，1971年7月3日－），程序员，记者，维基解密创始人、董事、发言人。</p>
<h1 id="大牛足迹"><a href="#大牛足迹" class="headerlink" title="大牛足迹"></a>大牛足迹</h1><p>阿桑奇出生在澳大利亚昆士兰州东北海岸的汤斯维尔，童年主要在邻近的磁岛上度过。在他一岁时，母亲克里斯蒂娜与剧导演布莱特·阿桑奇结婚，小阿桑奇的姓也是从继父得来。母亲与继父运营一家巡回剧团，总是四处奔波。阿桑奇的继父在描述阿桑奇时，称他是一个“非常有洞察力的孩子”，“对是非黑白有个人的见解”，而且“总是为弱者撑腰，很反感联合起来（欺负他人）的人”。<br>1979年，他的父母离异，母亲之后嫁给了一位暴虐的音乐人，在新的家庭中阿桑奇又有了一位同母异父的弟弟。1982年，母亲再次离异，之后带着阿桑奇与他的弟弟开始了长达五年的逃离生活。在阿桑奇的童年中不知道搬过了多少次家，频繁的迁居使阿桑奇没有机会接受完整的学龄教育，他依靠自学读了大量书籍，后来也参加过函授班以及非正式地跟随一些大学教授学习。</p>
<p>逃亡中阿桑奇的母亲在一家电子产品商店的对面租了间房子，阿桑奇经常到店里的一台Commodore 64型电脑上编程。后来他母亲把这台电脑买了下来，作为礼物送给了阿桑奇。正是在这台电脑上，阿桑奇学会了如何破解常用程序。在16岁时，阿桑奇得到一个调制解调器，并以门达克斯（Mendax）的名号联上了当时还未成形的互联网，并逐渐建立了自己的声誉，被称为“能够闯进最安全网络的高级程序员”。他甚至和两名黑客组成了一个名为“跨国颠覆”的小组，曾闯入欧洲和北美的保密计算机系统。阿桑奇和他的黑客伙伴们的活动日趋活跃大胆，引起了当局的注意，澳大利亚联邦警察针对他们展开了名为“天气行动”的调查行动。</p>
<p>1991年的9月，也就是在阿桑奇20岁时，他侵入加拿大电信公司“北方电讯”设在墨尔本的主终端，然后在那里四处刺探。多年后，首席检察官在法庭上描述阿桑奇几乎不受限制地访问那个系统时说道：“他就像万能的上帝那样逛来逛去，可以随心所欲地行事”。某天深夜，阿桑奇侵入系统时发现系统管理员也在线上，便试图联系他：“我已经接管了系统”。但管理员没有搭理他，于是阿桑奇给他留了一条消息“在贵网玩的很开心。我们未作任何破坏，甚至还做了几处改进。请勿致电澳大利亚联邦警局。”系统管理员当然通知了警察。正是由于他们对北电的入侵，使“天气行动”获得了突破性的进展。联邦调查人员开始窃听电话，寻找黑客们的线路。10月29日晚上11点，警官肯·戴伊敲开了他的门，对阿桑奇说：“我想你已在等着我来了吧。”阿桑奇被控31项与黑客有关的犯罪行为。当局花了三年多时间才将此案提交给法庭。他原本可能被判处十年徒刑，最后只是支付了一小笔罚款就息事宁人了。</p>
<p>在三年的候审期间，阿桑奇还得去争取他儿子抚养权。一定程度上，这比他的黑客案更为痛苦。1991年10月，阿桑奇在被逮捕前夕，他的妻子携子离家出走。直到1999年，经过30多次听证和诉讼，阿桑奇才和妻子达成了监护权协议。法院审理完监护案件后不久，阿桑奇的头发就从黑褐色，变成为失去颜色的灰白色。结案之后的阿桑奇变得疲惫万分。他兼了数份工作，尽最大努力挣钱抚养儿子。</p>
<p>1993年，阿桑奇参与创建“萨伯比亚公共接入网络”（Suburbia Public Access Network）——澳洲最早的互联网服务提供商之一。1994年起，阿桑奇开始了自由软件的编写，并于次年完成了首个自由开源的端口扫描仪－Strobe。1996年，他为PostgreSQL计划提交了多个补丁。1997年，阿桑奇与他人合著出版了《地下：黑客与疯狂的传奇及对电子前沿的痴迷》（Underground: Tales of Hacking, Madness and Obsession on the Electronic Frontier），书中提到了自己的黑客经历。1997年起，为了给人权工作者提供一个保护敏感数据的工具，阿桑奇与人共同开发了著名的“否认加密系统”－Rubberhose。 此外，他还编写了Usenet缓存软件－NNTPCache，和网络搜索引擎命令行界面Surfraw。</p>
<p>辗转职场多年，见识了无数的人与事之后，阿桑奇逐渐意识到，人类最关键的斗争，并不是左派与右派之争或信仰与理性之争，而是个体与机构之争。他草拟出一个类似宣言的文件，标题为《阴谋即统治》，旨在应用于政治领域。他认为，当一个政权内部的沟通线路被破坏，那些阴谋家之间的信息交流便注定会缩小，而当这种交流趋近于零的时候，阴谋就会被瓦解。泄密是信息战的一个工具。这些想法不久便催生出了“维基解密”网站。2006年期间，阿桑奇把自己关在大学附近的一所房子里开始工作。网站架设在一家名为PRQse的互联网服务提供商的空间上。提交的资料会首先被送到PRQ上面的网站，然后被传到设在比利时的“维基解密”服务器，然后再传到“在法律方面比较友善的另一个国家”。 这整条渠道以及通过它所传输的资料都是加密的。系统中仍然有薄弱环节，但“它的安全性已经是远远高于任何银行网络了”。2006年12月，“维基解密”公布了它的首份文件：这是一项“秘密决定”，由索马里反政府武装“伊斯兰法院联盟”的领导人谢赫·哈桑·达赫·阿威斯签署，被从通过Tor网络传递的内容中挑了出来。这份文件的真实性始终没有得到确认，而关于“维基解密”的新闻很快取代了对解密文件本身的关注。随着“维基解密”日益引人瞩目，阿桑奇的行踪也越来越难为人掌握。他不时与朋友通过电话和互联网联络一下，但从来没有透露他的确切活动。一个朋友告诉我，“我们总是在问：’阿桑奇在哪里？’永远都难以知道他到底在哪里。就好像他刻意要隐藏起来似的。”对于想要起诉“维基解密”网站的人，阿桑奇通常不屑一顾。2008年，“维基解密”公布了山达基教(Scientology)的保密手册，教会聘请的律师要求它删除这些内容。阿桑奇对此的回应是公布山达基教的更多内部资料，并且宣布，“‘维基解密’将不会屈服于山达基教滥用法律的要求，正如‘维基解密’不曾屈服于来自瑞士银行，或俄罗斯境外干细胞中心，或前非洲当权派，或五角大楼的类似要求。”在他的网上作品里，特别在Twitter上，阿桑奇对于他所认定的敌人毫不留情。与此相反，在电视上——他的行为却异乎寻常的冷静。在演播室的灯光下，他灰白的头发，苍白的皮肤，冷静的眼睛和宽阔的前额，使他似乎像是一个骨瘦如柴的外星来客，坐火箭来到地球，向人类揭示一些隐藏的真相。他僵硬的举止和他那缓慢而低沉的男中音，都加强了这种印象。然而私下里，阿桑奇通常却是一个充满活力而又丢三落四的人。他可以长时间心无旁骛地专注于某事，但也会做出忘记预定机票，或预订机票但却忘了付款，或付款买完机票却忘了去机场之类的事情。他周围的人们似乎都愿意照顾他。他们确保他能到达该去的地方，而且在动身之前没有把自己的衣服落在烘干机里。</p>
<img src="/2016/04/03/黑客列传/《黑客列传》之维基解密－Julian-Paul-Assange/2.jpg" alt="2.jpg" title="">
<p><br></p>
<p>自从阿桑奇公布身份后，美国决定追捕这位创始人。2010年12月1日，国际刑警组织发出红色通缉令，以强奸和性骚扰罪名通缉阿桑奇·阿桑奇。这一案件起源于阿桑奇2009年8月在瑞典与两名女性的纠纷。当时，阿桑奇正在申请瑞典居留权，试图利用瑞典保护言论自由的法律保护维基解密网站。据当地媒体报道，这两名女性向检方称，其与阿桑奇的性行为最初是自愿的，但随后演变成为非自愿行为。一名女性称，在安全套破裂之后，她要求阿桑奇暂停，但这一要求被阿桑奇忽略。阿桑奇否认有任何过失，暗示这一案件是美国试图打击维基解密而实施的诬蔑手段。</p>
<p>凭借着过人的才华，阿桑奇曾做过收入颇丰的计算机安全顾问，他却始终都不满足于墨守成规的工作或学术研究。阿桑奇相信，只有通过“泄密”，才能对抗靠隐瞒真相来维持政权的政府。阿桑奇居无定所，他总是马不停蹄地往来于世界各地，全部家当便是随身携带的一袋衣物和手提电脑，旁人甚至很难从其口音中分辨出他是澳大利亚人。</p>
<p>对外界而言，“维基解密”本身也是一个充满了神秘色彩的组织，它在伦敦的几个办公室都位于地下室，没有固定的总部，其核心成员是阿桑奇和一小批志同道合的人，此外在全球各地还有800名兼职工作人员。获取信息所需的计算机也隐藏在世界各地各个角落，因此该机构也不受任何国家法律的限制。“维基解密”是阿桑奇个人思想的凝集。阿桑奇对于维基解密创办的宗旨是这样解释的：我们的目标是实现公正的社会文明，这是我们干事情背后的推动力。“透明公开”是公正社会文明的要点，但要点与目标是不可混淆的（意即：目标并非获取“透明公开”的社会文明）。话虽如此，用“透明公开”作为实现公正的途径，亦是甚佳的方法，同时还避免犯下太多错误。我们的意识形态是跨越政治的，非左，非右，其根基在于（对世界的）认知。在给出与“如何处世”、“如何从公民过渡至社会文明”、“如果影响他人”一类问题相关的忠告与观念形态之前，应当对世界上正在发生的事情有较为深刻的认知。在未充分认知这个世界之前提出的建议与观念形态，必然归属于谬解。当今世界上所有的意识形态系统，从某种程度上来讲，都是虚空、缺乏实质的。它们缺乏在认知世界时至关重要，同时在自身面对这个世界时所必需的思想成分。</p>
<p>阿桑奇称维基解密所发布的机密文件数量，超过世界上其他新闻媒体的加起来的总和。他说道：“我不是想说维基解密有多成功，而是想表示世界媒体危机重重的现状。一个五个人的团队公布了比其他媒体加起来都多的机密文件，这是（媒体业的）耻辱。”阿桑奇说自己无意损害任何一个国家的利益。因维基泄密不断地爆料使维基泄密卷入了大约100多场官司，出于自我保护目的，阿桑奇和一些支持者通信不得不使用加密手机，还要不断更换手机号，住宾馆时用化名，不是睡沙发就是睡地板，而且用现金结账，不能用信用卡。阿桑奇说，“虽然生活过得很艰辛，但自从踏上这条道路，我决心走下去，从来不后悔，也从来不妥协”。</p>
<img src="/2016/04/03/黑客列传/《黑客列传》之维基解密－Julian-Paul-Assange/1.jpg" alt="1.jpg" title="">
<p><br></p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ol>
<li>《阿桑奇自传》</li>
<li>《第五阶层》</li>
<li><a href="https://zh.wikipedia.org/wiki/%E6%9C%B1%E5%88%A9%E5%AE%89%C2%B7%E9%98%BF%E6%A1%91%E5%A5%87" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%E6%9C%B1%E5%88%A9%E5%AE%89%C2%B7%E9%98%BF%E6%A1%91%E5%A5%87</a></li>
<li><a href="http://baike.baidu.com/view/4034352.htm" target="_blank" rel="external">http://baike.baidu.com/view/4034352.htm</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/04/03/黑客列传/《黑客列传》之维基解密－Julian-Paul-Assange/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“如果你想造一艘船，不要召集大家搜集木头，不要给他们分配任务，而是要教会他们对浩瀚海洋心生憧憬。”&lt;br&gt;－安托万·德·圣-埃克苏佩里&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="《黑客列传》" scheme="http://yoursite.com/categories/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B/"/>
    
    
      <category term="黑客" scheme="http://yoursite.com/tags/%E9%BB%91%E5%AE%A2/"/>
    
      <category term="传记" scheme="http://yoursite.com/tags/%E4%BC%A0%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>《HTML5 iOS App应用开发》之推送通知（Apple Push Notifications）Ionic实现</title>
    <link href="http://yoursite.com/2016/03/20/HTML5%20iOS%20App%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E3%80%8AHTML5%20iOS%20App%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E3%80%8B%E4%B9%8B%E6%8E%A8%E9%80%81%E9%80%9A%E7%9F%A5%EF%BC%88Apple-Push-Notifications%EF%BC%89Ionic%E5%AE%9E%E7%8E%B0/"/>
    <id>http://yoursite.com/2016/03/20/HTML5 iOS App应用开发/《HTML5 iOS App应用开发》之推送通知（Apple-Push-Notifications）Ionic实现/</id>
    <published>2016-03-20T07:23:33.000Z</published>
    <updated>2016-04-04T14:08:35.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/03/20/HTML5%20iOS%20App应用开发/《HTML5%20iOS%20App应用开发》之推送通知（Apple-Push-Notifications）Ionic实现/0.png" alt="0.png" title="">
<p><br></p>
<p>本篇将介绍Ionic中推送通知功能开发实现。<br><a id="more"></a></p>
<h1 id="推送通知（Apple-Push-Notifications，APN）简介"><a href="#推送通知（Apple-Push-Notifications，APN）简介" class="headerlink" title="推送通知（Apple Push Notifications，APN）简介"></a>推送通知（Apple Push Notifications，APN）简介</h1><p>在我们使用一些App时，有些会从后台推送通知给我们，其中大多是采用APN服务实现的，APN是苹果公司提供的一项消息推送服务。<br>APN主要能实现的功能包括：<br>1.推送一条文本消息；<br>2.推送一个声音提示；<br>3.在App的桌面图标上显示数字提醒（badge）；</p>
<h1 id="Ionic推送通知开发准备"><a href="#Ionic推送通知开发准备" class="headerlink" title="Ionic推送通知开发准备"></a>Ionic推送通知开发准备</h1><p>0.苹果开发者账号；<br>1.Node.js（<a href="https://nodejs.org）；" target="_blank" rel="external">https://nodejs.org）；</a><br>2.APN模块（<a href="https://github.com/argon/node-apn）；" target="_blank" rel="external">https://github.com/argon/node-apn）；</a><br>3.PEM文件；</p>
<h1 id="Ionic推送通知开发实现"><a href="#Ionic推送通知开发实现" class="headerlink" title="Ionic推送通知开发实现"></a>Ionic推送通知开发实现</h1><p>APN功能的实现主要分两部分：<br>1.App端的通知注册及通知接收；<br>2.服务端的通知推送；</p>
<h2 id="Ionic推送通知App端开发"><a href="#Ionic推送通知App端开发" class="headerlink" title="Ionic推送通知App端开发"></a>Ionic推送通知App端开发</h2><p>Ionic应用添加APN功能的具体实现</p>
<h3 id="安装ngCordova"><a href="#安装ngCordova" class="headerlink" title="安装ngCordova"></a>安装ngCordova</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bower install ngCordova</div></pre></td></tr></table></figure>
<p>如果没有安装过bower，安装bower<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install -g bower</div></pre></td></tr></table></figure></p>
<h3 id="安装cordova推送通知插件"><a href="#安装cordova推送通知插件" class="headerlink" title="安装cordova推送通知插件"></a>安装cordova推送通知插件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cordova plugin add https://github.com/phonegap-build/PushPlugin.git</div></pre></td></tr></table></figure>
<h3 id="复制PushNotification-js文件"><a href="#复制PushNotification-js文件" class="headerlink" title="复制PushNotification.js文件"></a>复制<code>PushNotification.js</code>文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp plugins/com.phonegap.plugins.PushPlugin/www/PushNotification.js www/lib/</div></pre></td></tr></table></figure>
<p>编辑<code>www/index.html</code>文件，添加5,6行代码：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">&lt;!-- ionic/angularjs js --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">'lib/ionic/js/ionic.bundle.js'</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"> </div><div class="line"><span class="comment">&lt;!-- 推送通知 --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">'lib/ngCordova/dist/ng-cordova.min.js'</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">'lib/PushNotification.js'</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div><div class="line"> </div><div class="line"><span class="comment">&lt;!-- cordova script (this will be a 404 during development) --&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">'cordova.js'</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h3 id="添加APN功能实现代码"><a href="#添加APN功能实现代码" class="headerlink" title="添加APN功能实现代码"></a>添加APN功能实现代码</h3><p>可根据你的应用具体逻辑实现决定代码调研的位置，一般会放在<code>js/server.js</code>或<code>js/app.js</code>中,下面是以<code>js/server.js</code>中实现为例<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">angular.module(<span class="string">'starter.services'</span>, [<span class="string">'ngCordova'</span>])</div><div class="line">    .factory(<span class="string">'App'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">$rootScope, $http, $ionicPlatform, $cordovaPush</span>) </span>&#123;</div><div class="line"></div><div class="line">        $ionicPlatform.ready(<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</div><div class="line">            <span class="keyword">var</span> iosConfig = &#123;</div><div class="line">                <span class="string">'badge'</span>: <span class="literal">true</span>,</div><div class="line">                <span class="string">'sound'</span>: <span class="literal">true</span>,</div><div class="line">                <span class="string">'alert'</span>: <span class="literal">true</span>,</div><div class="line">            &#125;;</div><div class="line"></div><div class="line">            $cordovaPush.register(iosConfig).then(<span class="function"><span class="keyword">function</span> (<span class="params">result</span>) </span>&#123;</div><div class="line">            	<span class="comment">// Success</span></div><div class="line">            	<span class="comment">// 注册成功之后，返回的result是device token，是推送通知时的用户设备标识，</span></div><div class="line">            	<span class="comment">// 一般deivce token会与用户信息相关联保存到后台数据库中，</span></div><div class="line">                <span class="keyword">var</span> deviceToken = result;</div><div class="line">                <span class="built_in">console</span>.log(<span class="string">'deviceToken: '</span>,deviceToken);</div><div class="line">            	<span class="comment">//$http.post('http://server.com/', &#123;user: 'LiLei', device_token: result&#125;)</span></div><div class="line">            &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</div><div class="line">                alert(<span class="string">'Registration error: '</span> + err)</div><div class="line">            &#125;);</div><div class="line"></div><div class="line">            $rootScope.$on(<span class="string">'$cordovaPush:notificationReceived'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">event, notification</span>) </span>&#123;</div><div class="line">            	<span class="comment">//文本通知</span></div><div class="line">                <span class="keyword">if</span> (notification.alert) &#123;</div><div class="line">                    navigator.notification.alert(notification.alert);</div><div class="line">                &#125;</div><div class="line">                <span class="comment">//声音提示</span></div><div class="line">                <span class="keyword">if</span> (notification.sound) &#123;</div><div class="line">                    <span class="keyword">var</span> snd = <span class="keyword">new</span> Media(event.sound);</div><div class="line">                    snd.play();</div><div class="line">                &#125;</div><div class="line">                <span class="comment">//桌面图标数字提示</span></div><div class="line">                <span class="keyword">if</span> (notification.badge) &#123;</div><div class="line">                    $cordovaPush.setBadgeNumber(notification.badge).then(<span class="function"><span class="keyword">function</span> (<span class="params">result</span>) </span>&#123;</div><div class="line">                        <span class="comment">// Success!</span></div><div class="line">                    &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</div><div class="line">                        <span class="comment">// An error occurred. Show a message to the user</span></div><div class="line">                    &#125;);</div><div class="line">                &#125;</div><div class="line">            &#125;);</div><div class="line">        &#125;);</div><div class="line">        </div><div class="line">    &#125;);</div></pre></td></tr></table></figure></p>
<p>到这里，App端的通知注册及接收功能实现就基本已经完成了：）</p>
<h2 id="Ionic推送通知服务端开发"><a href="#Ionic推送通知服务端开发" class="headerlink" title="Ionic推送通知服务端开发"></a>Ionic推送通知服务端开发</h2><p>APN的服务端可以有多种实现方式，这里我们以Node搭建服务为例。</p>
<h3 id="搭建推送通知服务"><a href="#搭建推送通知服务" class="headerlink" title="搭建推送通知服务"></a>搭建推送通知服务</h3><p>以下是APN服务端Node实现<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> apn = <span class="built_in">require</span>(<span class="string">'apn'</span>);</div><div class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">'express'</span>);</div><div class="line"><span class="keyword">var</span> bodyParser = <span class="built_in">require</span>(<span class="string">"body-parser"</span>);</div><div class="line"><span class="keyword">var</span> app = express();</div><div class="line">app.use(bodyParser.urlencoded(&#123;<span class="attr">extended</span>: <span class="literal">false</span>&#125;));</div><div class="line"></div><div class="line">app.post(<span class="string">'/notice'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">req, res</span>) </span>&#123;</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'device_token: '</span>, req.body.device_token);</div><div class="line">    <span class="comment">//var device_token = 'your_device_token_here_for_test';  // 测试使用</span></div><div class="line">    <span class="keyword">var</span> device_token = req.body.device_token;</div><div class="line">    <span class="keyword">var</span> device = <span class="keyword">new</span> apn.Device(device_token);</div><div class="line"></div><div class="line">    <span class="keyword">var</span> note = <span class="keyword">new</span> apn.Notification();</div><div class="line">    note.badge = <span class="number">1</span>;</div><div class="line">    note.contentAvailable = <span class="number">1</span>;</div><div class="line">    note.alert = <span class="string">'Hi，这是推送通知文本信息：）'</span>;  <span class="comment">//通知文本内容</span></div><div class="line">    note.payload = &#123;<span class="string">'messageFrom'</span>: <span class="string">'AppName'</span>&#125;; <span class="comment">//通知来源</span></div><div class="line">    note.device = device;</div><div class="line"></div><div class="line">    <span class="keyword">var</span> callback = <span class="function"><span class="keyword">function</span> (<span class="params">errorNum, notification</span>) </span>&#123;</div><div class="line">        <span class="built_in">console</span>.log(<span class="string">'Error is: %s'</span>, errorNum);</div><div class="line">        <span class="built_in">console</span>.log(<span class="string">'Note '</span> + <span class="built_in">JSON</span>.stringify(notification));</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">var</span> options = &#123;</div><div class="line">        <span class="attr">gateway</span>: <span class="string">'gateway.sandbox.push.apple.com'</span>, <span class="comment">// 开发时使用的推送通知网关（developer）</span></div><div class="line">        <span class="comment">//gateway: 'gateway.push.apple.com',       // 发布时使用的推送通知网关（distribution）</span></div><div class="line">        errorCallback: callback,</div><div class="line">        <span class="attr">cert</span>: __dirname+ <span class="string">'/theDevCert.pem'</span>, <span class="comment">// 同样有developer和distribution两种</span></div><div class="line">        key: __dirname+ <span class="string">'/theDevKey.pem'</span>,   <span class="comment">// 同样有developer和distribution两种</span></div><div class="line">        passphrase: <span class="string">'the_pass_phrase_pw'</span>, <span class="comment">// </span></div><div class="line">        port: <span class="number">2195</span>,</div><div class="line">        <span class="attr">enhanced</span>: <span class="literal">true</span>,</div><div class="line">        <span class="attr">cacheLength</span>: <span class="number">100</span></div><div class="line">    &#125;</div><div class="line">    <span class="keyword">var</span> apnsConnection = <span class="keyword">new</span> apn.Connection(options);</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'Note '</span> + <span class="built_in">JSON</span>.stringify(note));</div><div class="line">    apnsConnection.sendNotification(note);</div><div class="line"></div><div class="line">    res.send(&#123;<span class="attr">result</span>: <span class="literal">true</span>&#125;);</div><div class="line">&#125;);</div><div class="line"></div><div class="line"><span class="keyword">var</span> server = app.listen(<span class="number">8080</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</div><div class="line">    <span class="keyword">var</span> host = server.address().address;</div><div class="line">    <span class="keyword">var</span> port = server.address().port;</div><div class="line">    <span class="built_in">console</span>.log(<span class="string">'Example app listening at http://%s:%s'</span>, host, port);</div><div class="line">&#125;);</div></pre></td></tr></table></figure></p>
<p>服务端推送通知功能主要由<code>apn</code>模块实现，安装如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install apn</div></pre></td></tr></table></figure></p>
<h3 id="生成PEM文件"><a href="#生成PEM文件" class="headerlink" title="生成PEM文件"></a>生成PEM文件</h3><p>PEM文件的生成详细步骤可以参考这里：<a href="https://www.raywenderlich.com/32960/apple-push-notification-services-in-ios-6-tutorial-part-1#attachment_3502" target="_blank" rel="external">https://www.raywenderlich.com/32960/apple-push-notification-services-in-ios-6-tutorial-part-1#attachment_3502</a></p>
<blockquote>
<p>提醒注意的是“开发”和“发布”需要对应生成相应的.pem文件，共4个。</p>
</blockquote>
<p>到这里，推送通知服务端功能实现就基本已经完成了：）</p>
<h2 id="Ionic推送通知功能测试"><a href="#Ionic推送通知功能测试" class="headerlink" title="Ionic推送通知功能测试"></a>Ionic推送通知功能测试</h2><p>实现APN功能需要相应的App ID更新开启Push Notifications支持。</p>
<p>以上就是推送通知功能Ionic实现的基本方法，希望对你的学习或工作开发有所帮助：）</p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><p>0.<a href="https://chriztalk.wordpress.com/2015/03/04/iphone-push-notifications-using-ionic-framework/" target="_blank" rel="external">https://chriztalk.wordpress.com/2015/03/04/iphone-push-notifications-using-ionic-framework/</a><br>1.<a href="https://www.raywenderlich.com/32960/apple-push-notification-services-in-ios-6-tutorial-part-1" target="_blank" rel="external">https://www.raywenderlich.com/32960/apple-push-notification-services-in-ios-6-tutorial-part-1</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/03/20/HTML5%20iOS%20App应用开发/《HTML5%20iOS%20App应用开发》之推送通知（Apple-Push-Notifications）Ionic实现/0.png&quot; alt=&quot;0.png&quot; title=&quot;&quot;&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;本篇将介绍Ionic中推送通知功能开发实现。&lt;br&gt;
    
    </summary>
    
      <category term="《HTML5 iOS App应用开发》" scheme="http://yoursite.com/categories/%E3%80%8AHTML5-iOS-App%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E3%80%8B/"/>
    
    
      <category term="HTML5" scheme="http://yoursite.com/tags/HTML5/"/>
    
      <category term="iOS" scheme="http://yoursite.com/tags/iOS/"/>
    
      <category term="App" scheme="http://yoursite.com/tags/App/"/>
    
      <category term="应用开发" scheme="http://yoursite.com/tags/%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/"/>
    
      <category term="Ionic" scheme="http://yoursite.com/tags/Ionic/"/>
    
      <category term="推送通知" scheme="http://yoursite.com/tags/%E6%8E%A8%E9%80%81%E9%80%9A%E7%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>《黑客列传》之互联网之子－Aaron Swartz</title>
    <link href="http://yoursite.com/2016/03/15/%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B%E4%B9%8B%E4%BA%92%E8%81%94%E7%BD%91%E4%B9%8B%E5%AD%90%EF%BC%8DAaron-Swartz/"/>
    <id>http://yoursite.com/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/</id>
    <published>2016-03-15T11:53:47.000Z</published>
    <updated>2016-04-04T14:32:58.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/profile.jpg" alt="profile.jpg" title="">
<p><br></p>
<blockquote>
<p>“你真的应该每时每刻都问自己，现在这世界有什么最重要的事是我能参与去做的？如果你没在做那最重要的事，那又是为什么？”<br>－亚伦·斯沃茨</p>
</blockquote>
<a id="more"></a>
<h1 id="大牛简介"><a href="#大牛简介" class="headerlink" title="大牛简介"></a>大牛简介</h1><p>亚伦·斯沃茨（Aaron Hillel Swartz，1986年11月8日－2013年1月11日），软件工程师、作家、政治组织者、互联网活动家、维基百科人。参与开发或制定了RSS、Markdown、知识共享（Creative Commons)、Web.py框架、Reddit，万维网联盟的资源描述框架工作组 (W3C)成员，撰写了RFC，定义了RDF及XML的网际网路媒体类型，创办了求进会（Demand Progress），协助创办了渐进社会变革活动委员会（Progressive Change Campaign Committee）。 </p>
<h1 id="大牛足迹"><a href="#大牛足迹" class="headerlink" title="大牛足迹"></a>大牛足迹</h1><p>斯沃茨出生在美国芝加哥的伊利诺伊州一个犹太家庭，他是三兄弟里面最大的。斯沃茨的爷爷经营一个广告牌制作公司，后来斯沃茨的爸爸接手发展成一个小型软件公司，因此他家里总是会有电脑。经斯沃茨回忆说那时他们镇里没什么好玩的，所以斯沃茨就经常在家玩电脑。大概是在1992年的时候，斯沃茨家接入了互联网，从那时开始斯沃茨每天大部分的时间基本都是花在了网络上－写邮件、逛讨论组、浏览网页。斯沃茨上学的地方距家大概有六英里多远，而离同学家也并不近，因此，斯沃茨基本上就是在网上交朋友。在斯沃茨12岁那年，他爸爸带上他出差去了一趟麻省理工。斯沃茨一整天都待在了Philip Greenspun教授的堂课里面，听Philip Greenspun教授讲解制作网络应用的规范原则。听完课以后，斯沃茨很激动，迫不及待地回到家尝试大干一场。他最先做了一个所有人都能编辑的线上百科全书，但可惜的是除了斯沃茨的妈妈和一些学校的朋友以外，就没人在上面写东西了。然后他做了第二件东西，就是可以聚合很多网站上面的新闻到一个网页上。这在当时是件比较难实现的事情，因为每个网站都有自己特别的格式，需要针对每一个不同的网站专门设计程序来抓取新闻。而当时正好有一帮人在计划建立一种标准格式，以期实现只需要一个工具就可以抓不同网站的新闻。很自然地斯沃茨开始了与他们的联系。作为一个小孩斯沃茨当时有大把的空余时间，主动负责的工作也越来越多，这样14岁的斯沃茨成为了RSS 1.0 开发组的一员。后来，他又和 John Gruber一起开发了Markdown。15岁时斯沃茨进入了W3C的 RDF 核心工作组，并写了RFC3870（这个文档描述了一个新的media type – “RDF/XML“，用于定义互联网上的“语义网络”）。17岁斯沃茨进入了斯坦福大学，1年半后，因为受不了教条式的教育决定退学。同年斯沃茨通过Y Combinator公司的夏季创办人计划成立Infogami软件公司，在那里，他设想了一个Wiki平台来实现他的Internet Open Library（一个开放的网络图书馆），并写了著名的web.py 开发框架。他觉得自己太年轻，还要有一个合伙人，于是Y Combinator建议他和Reddit合并，于是斯沃茨19岁的时候成了Reddit的创始人。虽然Reddit不挣钱，但是相当火。2006年10月，在斯沃茨20岁的时候，他们把Reddit卖给了康泰纳仕出版社（Condé Nast），据说挣到了百万美金。之后斯沃茨与他的公司搬到了旧金山，在康泰纳仕出版社其下的连接杂志工作。后来由于斯沃茨对公司越来越不满，2007年1月，他辞去了在出版社的职位，同年的9月，斯沃茨与好友西蒙·卡斯特森推出了一个免费的wiki技术工具－Jottit。 </p>
<p>在互联网时代，斯沃茨被支持者称为“罗宾汉”，和维基解密的阿桑奇一样，享有绿林好汉般的荣誉，或者说，他们都在用破坏性的方式做对的事情。斯沃茨从青少年时期起，就不懈地反抗网络审查，呼吁资源共享和信息交换自由。他在博客里写过，“我总是深入思考，同时希望别人也能这么做、我为理想（观念）而工作。我是个完美主义者。我不会浪费时间在那些不会有影响的事情上。我讨厌人们不把我当回事。我从自身经历中学习，我想让世界变得更美好。“斯沃茨是非常喜欢开放共享的人，不喜欢那些有CopyRight的东西，他喜欢质疑，打破常规。他在YC搞的那个Internet Open Library（互联网开放图书馆）的项目，就是想把那些没有Copyright的书籍和学术期刊放在网上让全世界的人免费查阅。他认为固体的图书馆遮蔽了知识的传播，互联网理应成为连接书籍，读者，作者，纸张与思想的最好载体，同时也非常痛恨任何一家巨型的机构独吞所有书籍的做法。他想把公共存取（Public Access）变成公共领域（Public Domain）。在他的青少年时期，他就在不懈地和一切限制信息自由交换和自由共享的做法做斗争。这是他认为的互联网精神，他同时也觉得这和美国民主自由的宪法的精神是一致的。这其中发生过这样一件事情，美国法院行政办公室有一个叫 PACER（Public Access to Court Electronic Records） 的政府服务。这个服务会把法庭记录的文件放在网上，如果你要看的话，一页要付费8美分，对这个事他非常不能理解，他觉得这些文件本来就属于公众，没有CopyRight，为什么属于公众的东西还要收费。PACER这个服务每年可以为政府带来1.2亿美金的收入。于是斯沃茨在2008年9月4日到20日，他用Perl在AWS上写了一个程序，从PACER上下载了270万的文档（2000万页，纽约时报里说他下载大约是总量的20%，但是也有人不到总量的1%）,于是FBI对他调查了两个多月，但最终没有对他起诉。</p>
<p>斯沃茨还起草了一份《开放获取游击队宣言》（Guerrilla Open Access Manifesto），下面是节选：</p>
<blockquote>
<p>信息就是能源。但就像所有能源一样，有些人只想占为己有。世界上所有的科学和文化遗产，已在书籍和期刊上发布了数个世纪，正渐渐地被少数私有的公司数字化并上锁。想要阅读那些有着最著名研究成果的论文？你必须支付给如 Reed Elsevier 这样的出版商大把钱。 </p>
<p>…… …… </p>
<p>我们要夺回信息，无论它们被存在何处，制作我们的副本并和全世界分享。我们要取到版权到期的东西并将它们归档，我们要买下秘密的资料库并将它们放到网上。我们要下载科学期刊并将它们上传到文件分享网络。我们要为游击队开放访问而战。 </p>
<p>只要全世界有足够多的我们，那就不仅是传达了一个反对知识私有化的强有力信号，我们还将让它成为过去。你愿意和我们一起吗？ </p>
<p>亚伦·斯沃茨 (Aaron Swartz) 2008 年 7 月，意大利 Eremo </p>
</blockquote>
<p>斯沃茨觉得那些对人类有价值的科学和文化遗产属于全人类，美国大学每年需要向那些出版学术期刊、论文的机构（比如 ISI，Jstor）支付许可费用，许可费用极高，他觉得这是这个时代的悲剧。2009年，他成立了进步改变运动委员会，2010年，他又创建了求进会－利用互联网来组织群众与议会和政府对话。 也正因为他不理解政府和这个时代的一些行为，促使他开始学习各种政治上的东西去寻求突破。在2010年到2011年，斯沃茨在哈佛大学Edmond J. Safra研究实验室以Lab Fellow的身份主导了“制度腐败”课题的研究，也因为这个身份，斯沃茨在MIT做访问学者的时候拥有了JSTOR访问帐号，这意味着他可以通过MIT的网络访问大量的学术期刊。于是，他把笔记本放到了地下室网络交换机的机房中，直接插上网线全天后地从JSTOR下载学术期刊，还因此导致JSTOR一度瘫痪。由于他不断变换IP和MAC地址，躲过封锁，JSTOR无计可施，被迫禁止所有MIT用户访问长达四天。JSTOR报告了警方，美国国家安全警察找到了那间楼道里的机房，然后在那间机房里安了摄像头，拍摄到了斯沃茨去换硬盘时的录像，之后斯沃茨被捕了。在斯沃茨被捕后的第三天，一个用户名为Greg Maxwell的声援者，在海盗湾上传了一个BT种子，里面包含18,592篇来自JSTOR的论文，共计32.48GB。这位声援者说：“学术论文本应该允许自由获得，但是大多数论文都被像JSTOR这样的守门员，以高额收费的形式阻止传播。”同年的7月11日，检查官以通信欺诈、计算机欺诈、非法获得信息，以及破坏被保护的电脑罪名来起诉他，若罪名成立，斯沃茨将可能面临35年的监禁。事后JSTOR发表声明表示，他们无意牵扯入此案，他们已经和斯沃茨在2011年6月就相关事务达成一致，斯沃茨归还了相关文件，他们也即时撤销了所有民事指控，随后是否控告的决定由美国政府做出。而MIT方面虽然也放弃起诉，发表了保持中立相关的说明，但这种保持中立被舆论认为是一种“坐视不理”的行为，同时也违背了MIT一贯鼓吹的黑客文化，MIT一时间声名狼藉成了千夫所指。 美国政府的检查官坚持以重罪起诉斯沃茨，当时放在他前有两条路：1）认罪，承认犯下重罪，35年的判决会变成3个月入狱+1年的居家监禁（不得使用电脑），2）不认罪，那就有可能接受35年监禁的最坏结果，而斯沃茨选择了后者。在此期间，斯沃茨还通过他的求进会网聚众反对SOPA法案（Stop Online Piracy Act，网络审查制度）和政府做斗争，最终导致了整个社会都在反对SOPA，也导致了那些议员纷纷改变自己的想法，并导致了白宫最终放弃了这个法案。而在次年9月，政府对斯沃茨进行了更为严厉的起诉，新加入了另外9条起诉，如果成立，斯沃茨最多会获刑50年外加100万美金的罚款。同样，检察官给出了优惠条件，只要斯沃茨认罪，那就只起诉他6个月的监禁，然而，斯沃茨再次拒绝。 </p>
<p>2013年1月11日上午，斯沃茨自杀了，这就是斯沃茨传奇的一生，他用生命捍卫了互联网的开放和自由。在斯沃茨的纪念网站上这样写着，“作为一个程序员和技术人员，他不是用惊人的技巧使自己富足，而是使网际网路和世界成为一个更公平，更美好的地方。”</p>
<img src="/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/2.jpg" alt="2.jpg" title="">
<p><br></p>
<p>斯沃茨的葬礼于2013年1月15日举行，万维网的发明者蒂姆·伯纳斯-李在葬礼上发表了悼词。匿名者组织（Anonymous）攻击了麻省理工学院网站并更改了首页，以示向斯沃茨致敬。</p>
<img src="/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/1.jpg" alt="1.jpg" title="">
<p><br></p>
<p>有一个叫 Jack Andraka的14岁男孩，来自巴尔的摩，因为阅读了斯沃茨推广的JSTOR免费学术论文，而想出了一种提早检测胰腺癌的方法。之后他去了约翰霍普金斯大学做继续研究。Jack说：“我之所以上了新闻，是因为我们的实验成功了，而这就是为什么斯沃茨做的事有那么重要……这个宇宙中的真理不是只有那些政策制定者曾经弄清楚过的，比如应该限速多少，它还包括那些能让你的孩子，不会因胰腺癌而死的研究。如果没有访问阅读权，那个能解决你的问题的人，可能就永远找不到答案。”</p>
<img src="/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/3.jpg" alt="3.jpg" title="">
<p><br></p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ol>
<li><a href="http://www.aaronsw.com/" target="_blank" rel="external">http://www.aaronsw.com/</a></li>
<li>纪录片－《互联网之子》</li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BA%9A%E4%BC%A6%C2%B7%E6%96%AF%E6%B2%83%E8%8C%A8" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%E4%BA%9A%E4%BC%A6%C2%B7%E6%96%AF%E6%B2%83%E8%8C%A8</a></li>
<li><a href="http://baike.baidu.com/view/7854319.htm" target="_blank" rel="external">http://baike.baidu.com/view/7854319.htm</a></li>
<li><a href="http://coolshell.cn/articles/11928.html" target="_blank" rel="external">http://coolshell.cn/articles/11928.html</a></li>
<li><a href="https://www.zhihu.com/question/20711220/answer/15950812" target="_blank" rel="external">https://www.zhihu.com/question/20711220/answer/15950812</a> </li>
<li><a href="https://www.zhihu.com/question/24928691/answer/29478342" target="_blank" rel="external">https://www.zhihu.com/question/24928691/answer/29478342</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/03/15/黑客列传/《黑客列传》之互联网之子－Aaron-Swartz/profile.jpg&quot; alt=&quot;profile.jpg&quot; title=&quot;&quot;&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“你真的应该每时每刻都问自己，现在这世界有什么最重要的事是我能参与去做的？如果你没在做那最重要的事，那又是为什么？”&lt;br&gt;－亚伦·斯沃茨&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="《黑客列传》" scheme="http://yoursite.com/categories/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B/"/>
    
    
      <category term="黑客" scheme="http://yoursite.com/tags/%E9%BB%91%E5%AE%A2/"/>
    
      <category term="传记" scheme="http://yoursite.com/tags/%E4%BC%A0%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>《黑客列传》之天才程序员－John D. Carmack II</title>
    <link href="http://yoursite.com/2016/03/12/%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B%E4%B9%8B%E5%A4%A9%E6%89%8D%E7%A8%8B%E5%BA%8F%E5%91%98%EF%BC%8DJohn-D-Carmack-II/"/>
    <id>http://yoursite.com/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/</id>
    <published>2016-03-12T07:04:40.000Z</published>
    <updated>2016-04-04T14:32:25.000Z</updated>
    
    <content type="html"><![CDATA[<img src="/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/0.jpg" alt="0.jpg" title="">
<p><br></p>
<blockquote>
<p>“现今程序员的情况好多了，只要有一台便宜的二手电脑，一张Linux光盘和一个互联网帐户，你就已经拥有了把自己提升到任何级别的编程水平所需的全部工具。”<br>“在信息时代，进入编程领域的壁垒完全不存在了。即使有也是自我强加的。如果你想着手去开发一些全新的东西，你不需要数百万美元的资本。你只需要足够的比萨和健怡可乐存在你的冰箱里，有一台便宜的PC用于工作，以及让你坚持下来的奉献精神。我们睡在地板上。我们跋山涉水。”<br>－约翰·卡马克 </p>
</blockquote>
<a id="more"></a>
<h1 id="大牛简介"><a href="#大牛简介" class="headerlink" title="大牛简介"></a>大牛简介</h1><p>约翰·D·卡马克二世（John D. Carmack II，1970年8月20日－），3D引擎之父，第一人称射击游戏之父，游戏内部命令行指令发明者、卷轴游戏背缓冲技术发明者和3D图形加速技术奠基人，发明世界第一款3D射击游戏《重返德军（Wolfenstein 3D）》，id Software的创始人之一，1999年刊登美国时代杂志评选科技领域50大影响力人物榜单第10位，2001年成为第四位进入互动艺术和科学学院名人堂的人物。 </p>
<h1 id="大牛足迹"><a href="#大牛足迹" class="headerlink" title="大牛足迹"></a>大牛足迹</h1><p>卡马克小名约迪，成长于美国堪萨斯城中心区的一个家庭。他父母工作都很勤奋，所以他们家境很好。还晋升为一家电视台的晚间新闻主播，这家电视台是密苏里州堪萨斯城最大的三家电视台之一，他们随后搬迁到了郊外的富人区。在那里，约翰有了个小弟弟，彼得。同年，约翰进了圣母玛利亚天主教小学，这是当地最好的学校之一。这个从一岁起就戴上眼镜，长着一头凌乱金发的瘦小男孩在学校里很快就显示出了与众不同。二年级的时候，只有七岁的他几乎在所有标准化测验里都得到了满分，这相当于九年级的水平。约翰还养成了一种很独特的口吃习惯：在每句话后面加上简短的类似机器人那样的嗡嗡声，就像一台计算机在处理数据一样：“12乘以12等于144……嗯嗯。”卡马克的父母在他十二岁的时候突然离婚了，他们在如何抚养孩子的事情上还闹的很紧张。茵戈觉得这给卡马克造成了无法弥补的创伤。就当卡马克开始在学校里找到点乐趣的时候，他和弟弟彼得又不得不在双亲之间来回轮换，不停地转学。卡马克不喜欢和父亲分开，更糟糕的是，当他和母亲住在一起的时候，他得自己照顾自己。 </p>
<p>尚在就读高中时，卡马克就被认为是“怪才”，他还因此被学校视为有心理问题，并停课一年。复课后，卡马克还是拿到了毕业证书，并考入了当地著名的Kansas大学。在编程方面，卡马克几乎是无师自通。大一还没读完，他编写的一些小游戏就被不少软件公司买走，他本人也成为了几家软件公司的兼职程序员，并逐渐在游戏软件领域小有名气。 </p>
<p>1990年，正值计算机技术的黄金发展时期，IBM个人电脑为整个软件业带来了前所未有的机遇。但这时的软件多以商业用途为目的，游戏软件却少人问津。当时一家名为Softdisk的软件公司找到了在读大二的卡马克，希望他加入公司，一起开发游戏软件。出于对游戏软件的热爱，他毫不犹豫的同意了对方的邀请。卡马克首先遇到的问题是如何将游戏程序移植到个人电脑上，经过一番考虑，他选择了IBM PC作为最早的游戏运行平台，游戏软件就是任天堂公司风靡全球的《超级马里奥兄弟3》。经过实验，他开发出了一种名为EGA(增强型图形适配器，3D图形加速卡的雏形)的PC显示技术，这是一种16色的显示模式。之后，他又设计出屏幕刷新技术以提高游戏图形显示的速度。不久，IBM PC的第一款2D游戏成功问世，迈出了游戏软件历史性的一步。一年后，他决定自己创业，与他人共同创办了ID Software游戏公司。在id Software公司里，卡马克和他的同事通过一部又一部血腥暴力的作品创造并不断革新着这一游戏类别。id所获得的无数荣誉应当归属于它的全体员工，而约翰·卡马克无疑是将整个公司凝聚在一起的粘合剂。雄心勃勃的卡马克当然不会停留在人人都能设计的2D游戏上，他把目标锁定在了3D游戏的研发上。如果是在几年前，他的“3D计划”可能很难实现，好在那时的计算机硬件技术已发展到了相当的水平—高分辨率显示器、大容量硬盘和内存、高速运算的CPU和图形加速卡等等，这些都是他实现梦想的绝好基础。两年后，他与另一个游戏软件天才John Romero共同开发出了全球首款3D射击游戏《德军总部3D》，这款3D游戏采用了他独创的3D游戏引擎。紧接着，他又开发出了《Doom》和《Quake》两款3D游戏。一时间，所有的电脑用户都争相购买这些游戏，人们甚至为了能玩上3D游戏而去购买昂贵的PC。不到一年的时间，仅《Doom》一款游戏就售出了几百万张拷贝，带来了上亿美元的商业利润。 </p>
<img src="/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/1.jpg" alt="1.jpg" title="">
<p><br></p>
<p>卡马克是一名技术天才，id公司出品的每一款游戏都是围绕他所编写的引擎制作而成的，卡马克不断把引擎技术推向新的高度。他为游戏业作出的第一个贡献是实现了卷轴游戏背景图像的流畅性，这一技术在1990年的《指挥官基恩》（Commander Keen）中得到了应用，此前电脑平台上的横向卷轴游戏的背景图像都很不稳定，根本无法同当时游戏机平台上的横向卷轴游戏相比。尽管这一技术在今天看来算不上什么，但它足以显示出卡马克高超的编程能力。《雷神之锤》刚刚问世的时候，3D加速卡在人们眼里还只是一个可笑的空想而已，只有卡马克对3D技术的威力深信不疑，他为《雷神之锤》制作了一个专门在Verite显卡上运行的特别版本，画面看上去非常漂亮，可惜的是Verite显卡未能在市场上站稳脚跟。随后卡马克又采用OpenGL标准为《雷神之锤》制作了一个新的版本，使所有具备3D加速能力的显卡都能以更快的速度、更高的分辨率渲染出更华丽的图像。 </p>
<p>卡马克喜欢在电脑图像领域尝试新的技术，比如他在Doom上第一次使用了二叉树分区技术，表面缓存技术则在Quake中第一次出现。还有就是后来在Doom3里面使用的“卡马克反转”（即shadow volume的z-fail方法，虽然并不是首创，但是是由他独立研究出来的） 。卡马克创造的游戏引擎被用来制作其他的第一人称射击游戏，比如《半条命》（Half-life）和《荣誉勋章》（Medal of Honor）。在2007年苹果全球开发者会议（WWDC, Apple Worldwide Developers Conference）上，Carmack宣布了id Tech 5，它实际上消除了过去对美工和设计人员的纹理内存限制，允许在像素级别上对整个游戏世界实现独特的定制设计，并提供了几乎无限的视觉真实性。”该技术可以允许”广袤的户外场景，而室内场景则具有前所未见的艺术细节。除了3D方面的成就外，约翰·卡马克还为游戏业带来了许多其它的技术革新，例如网络代码中的客户端侦测、多重纹理、便于修改和可扩展的游戏代码、游戏内部的命令行指令等等。 </p>
<p>卡马克同时也是一位积极的的开源软件的倡导者，他也再三强调反对“软件专利”，但是他一直处于势单力孤的状态。卡马克在1995年放出了德军总部3D的源代码，之后的1997年又放出了毁灭战士的代码。1996年时候，他放出了雷神之锤的源代码，Quake社区中的一名不太出名的程序员将其改写成了Linux版本，并且将修改后的游戏发给了卡马克。卡马克没有认为这是侵权行为然后付诸法律，而是要求id Software的员工们用这个补丁作为雷神之锤linux版本的基础。id Software在后来的日子里也同样公布了雷神之锤II的代码，雷神之锤III的代码也于2005年8月19日公布，这些代码的公布全遵循了GPL准则。毁灭战士的代码也使用GPL准则在1999年重新公布。2012年，卡马克将id Software工作室旗下的所有开源软件进驻了Github (<a href="https://github.com/id-Software)，开源的游戏包括著名的德军总部（Wolfenstein）3D" target="_blank" rel="external">https://github.com/id-Software)，开源的游戏包括著名的德军总部（Wolfenstein）3D</a> iOS版、重返德军总部（Return to Castle Wolfenstein）、DOOM 3（GPL许可证发布）、Quake Ⅰ/Ⅱ/Ⅲ及相关工具，以及雷神战争（Enemy Territory）等。 </p>
<p>卡马克不仅仅是一个3D图像领域的程序员，和Elon Musk、Jeff Bezos一样，也醉心于太空技术。他创建了Armadillo Aerospace公司，研究宇宙航行技术，先后参加过几届NASA举办的登月挑战赛。可惜的是，在“可复用亚轨道航空器项目”失败，无法争取到NASA的合同后，Carmack认为继续投入这项事业并不是一个明智的决定，卡马克在达拉斯QuakeCon 2013发表主题演讲后不久，他本人在台下向Arstechnica的记者证实，他决定了放弃自己投入12年精力的私人项目“可复用亚轨道航空器”，这么多年来他“不务正业”的日子业已结束。 </p>
<img src="/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/2.jpg" alt="2.jpg" title="">
<p><br></p>
<p>2013年8月7日，卡马克以首席技术官（CTO）身份加入Oculus VR公司，并在同年11月22日正式从id Software辞职以全职供职于Oculus VR。卡马克辞职的原因是id的母公司ZeniMax Media不赞成id在Oculus Rift这个平台上发展游戏。对于加盟Oculus Rift虚拟现实头盔的原因，约翰·卡马克（John Caramack）也给出了这样的回答“是三星的Gear VR让我下定决心，我要集中注意力专注在Oculus上。” 卡马克宣布加入Oculus公司的当天，Oculus官方博客发生系统宕机，就是因为“一个新成员加入导致的大规模访问行为”。 </p>
<img src="/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/3.jpg" alt="3.jpg" title="">
<p><br></p>
<p>卡马克被称作有史以来最伟大的程序员，他是比尔·盖茨心中为数不多的天才。他是图形编程领域的教父，又是地球上最勤奋的程序员。从一个穷小子到腰缠万贯，拥有20多辆豪华法拉利跑车，却仍然如同普通员工一样每每加班到深夜。从一个普通程序员到3D引擎之父，卡马克一直执著地追求着自己的理想，在不断地自我挑战中最终使那些原来认为不可能的事情变成了可能。 </p>
<h1 id="更多参考"><a href="#更多参考" class="headerlink" title="更多参考"></a>更多参考</h1><ol>
<li><a href="https://twitter.com/ID_AA_Carmack" target="_blank" rel="external">https://twitter.com/ID_AA_Carmack</a></li>
<li>《DOOM启世录》</li>
<li><a href="https://zh.wikipedia.org/wiki/%E7%B4%84%E7%BF%B0%C2%B7%E5%8D%A1%E9%A6%AC%E5%85%8B" target="_blank" rel="external">https://zh.wikipedia.org/wiki/%E7%B4%84%E7%BF%B0%C2%B7%E5%8D%A1%E9%A6%AC%E5%85%8B</a> </li>
<li><a href="http://baike.baidu.com/view/59118.htm" target="_blank" rel="external">http://baike.baidu.com/view/59118.htm</a> </li>
<li><a href="http://blog.jobbole.com/51434/" target="_blank" rel="external">http://blog.jobbole.com/51434/</a> </li>
<li><a href="https://en.wikiquote.org/wiki/John_D._Carmack" target="_blank" rel="external">https://en.wikiquote.org/wiki/John_D._Carmack</a> </li>
<li><a href="http://www.jegqin.cn/?a=url&amp;k=91193629&amp;u=aHR0cDovL3BjLmt1YWk4LmNvbS9uZXdzLzk2NjUyLmh0bWw=&amp;t=5ri45oiP55WM55qE5Lyg5aWH5Lq654mpOue6pue@sMK35Y2h6ams5YWLKEpvaG4gQ2FybWFjaylf5b!r5ZCn5ri45oiP&amp;s=57qm57!wLuWNoemprOWFiw==" target="_blank" rel="external">http://www.jegqin.cn/?a=url&amp;k=91193629&amp;u=aHR0cDovL3BjLmt1YWk4LmNvbS9uZXdzLzk2NjUyLmh0bWw=&amp;t=5ri45oiP55WM55qE5Lyg5aWH5Lq654mpOue6pue@sMK35Y2h6ams5YWLKEpvaG4gQ2FybWFjaylf5b!r5ZCn5ri45oiP&amp;s=57qm57!wLuWNoemprOWFiw==</a> </li>
<li><a href="http://www.shiziduo.com/job/jy/content-145004.html" target="_blank" rel="external">http://www.shiziduo.com/job/jy/content-145004.html</a> </li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;img src=&quot;/2016/03/12/黑客列传/《黑客列传》之天才程序员－John-D-Carmack-II/0.jpg&quot; alt=&quot;0.jpg&quot; title=&quot;&quot;&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“现今程序员的情况好多了，只要有一台便宜的二手电脑，一张Linux光盘和一个互联网帐户，你就已经拥有了把自己提升到任何级别的编程水平所需的全部工具。”&lt;br&gt;“在信息时代，进入编程领域的壁垒完全不存在了。即使有也是自我强加的。如果你想着手去开发一些全新的东西，你不需要数百万美元的资本。你只需要足够的比萨和健怡可乐存在你的冰箱里，有一台便宜的PC用于工作，以及让你坚持下来的奉献精神。我们睡在地板上。我们跋山涉水。”&lt;br&gt;－约翰·卡马克 &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="《黑客列传》" scheme="http://yoursite.com/categories/%E3%80%8A%E9%BB%91%E5%AE%A2%E5%88%97%E4%BC%A0%E3%80%8B/"/>
    
    
      <category term="黑客" scheme="http://yoursite.com/tags/%E9%BB%91%E5%AE%A2/"/>
    
      <category term="传记" scheme="http://yoursite.com/tags/%E4%BC%A0%E8%AE%B0/"/>
    
  </entry>
  
</feed>
